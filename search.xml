<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>第一篇博客，聊聊这个博客本身</title>
    <url>/%E5%85%B6%E4%BB%96/others/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%EF%BC%8C%E8%81%8A%E8%81%8A%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2%E6%9C%AC%E8%BA%AB/</url>
    <content><![CDATA[<p>平时工作中也积累的不少东西，但是一直没有很好的记录这些经验。</p>
<p>自从换了电脑之后，我开始有了用markdown写一些经验分享或者工作记录的习惯。平时写技术预研的文档，或者设计文档，甚至是交付的说明文档，都开始使用markdown。这些文档逐渐变多之后，如何管理就成了一个问题。</p>
<p>为了解决文档的管理问题，我就建了一个博客。</p>
<h2 id="还有更多的想法么？">还有更多的想法么？</h2>
<p>首先，作为技术人员，留存自己的经验是很重要的。一个人的工作经验就体现在这。程序员的工作很多时候是琐碎且非常细节的，单凭人脑的记忆，绝大多数时候都会出错。</p>
<p>而且，工作毕竟是需求导向，获取新的知识只是为了解决当前的问题。但想要提高，就需要人主动去深入研究。所以我觉得，写博客的过程也是复习并提高的过程，对技术成长明显是有积极意义的。</p>
<p>另外，很多开发人员遇到问题，都会通过搜索引擎去搜索问题的解决方案。随着技术的更新，已经出现了相当多的过时答案。网络上的资料良莠不齐，会给后来人造成各种困难。我写这个博客也是为了记录自己真实的情况，真实的解决方案，希望能提供一些正确的答案。</p>
<h2 id="博客的内容会有哪些？">博客的内容会有哪些？</h2>
<p>我初步考虑，是打算分三部分：生活、工作、杂谈。</p>
<p>生活就是记录一些生活中小事，可能绝大多数是做饭和健身相关？这会是类似日记一样的东西。</p>
<p>工作主要是技术文档了。更多的会是工作上的技术文档，我脱敏之后放到博客作为副本。还有些工作上遇到的问题，我尽量记录下来，把最终的解决方案也列出来，提供一些有价值的东西。当然，为了提高阅读量，我应该会单独列一个索引词的玩意儿，放在每篇文章的最前边。</p>
<p>至于杂谈，就是一些思考和规划，也有可能是投资计划之类的。不能归到生活和工作的，就都会丢到杂谈这一栏中，比如现在这第一篇博客。</p>
<h2 id="后续规划？">后续规划？</h2>
<p>我平时使用的网名是涂蓝，以后在各种社交网站或者平台我应该都会统一使用这个名字。</p>
<p>技术人员或多或少都会有个技术梦。我希望后续能参与一些开源项目，逐步提高自己吧。</p>
<p>这次建博客，正好是我第一次向Spring Cloud Gateway提了一个issue，也是我第一次在github上提issue。很幸运，我提的issue被官方认证为一个确实的缺陷。不过本来我是想提PR的，可惜被一个阿里的哥们抢了。</p>
<p>这也让我突然意识到，自己已经可以参与到更大的平台中了。和我直属领导聊天时，他说一个技术人员能够去挑开源项目的刺，才说明他确实入门了。我深以为然。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>关于时代与我的碎碎念</title>
    <url>/%E7%94%9F%E6%B4%BB/life/%E5%85%B3%E4%BA%8E%E6%97%B6%E4%BB%A3%E4%B8%8E%E6%88%91%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/</url>
    <content><![CDATA[<blockquote>
<p>[!WARNING]</p>
<p>2025年9月27日留：</p>
<p>过了4个月，回看这篇博客真的是无地自容，青春伤痛文学的人格居然闪回了。特意留着警醒自己，要脚踏实地，做实在事正确事。</p>
</blockquote>
<h2 id="从人力车到马车">从人力车到马车</h2>
<p>在技术这块，近两年最火的议题只有一个：AI。</p>
<p>围绕着新的风口，诸多需求、诸多岗位涌现，更别说国内有自上而下的命令下来，让所有的干部都学习以deepseek为代表的大语言模型。2025年春节，我回家的时候，感觉最奇怪的一点就是，公园里路边的大爷都能和你聊几句deepseek。我老爸也问我deepseek怎么装到手机上。信息的传播速度在国内展现出一种很独特的曲线。一开始没有人注意，当某个事件导致某个东西爆火后，会在一到两天内传到大部分人耳中。这或许就是自媒体时代的魅力。</p>
<p>AI并不是新东西，但AI真正让人感觉到有质变的点，就在ChatGPT-3.5上线之后。大约2022年末，ChatGPT出现，一开始大家只是当做一个AI聊天的游戏，并没有完全发掘其潜力。大部分人对其的评价是幻觉过于严重，胡编乱造的情况太多了。</p>
<p>而我个人认为第一个质变的点，是有人发现可以用类似讲故事的形式，让GPT来主动要求获取什么信息，这时候最初级的Function Call就出现了。</p>
<p>比如这样的一个对话：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">人：我这里有个工具能查询火星的天气。当有人问火星的天气怎么样，你应该用这个工具来获取信息，然后回答。使用工具的方式是回复：func call marsweather。如果你知道了，请回答好的。</span><br><span class="line">AI：好的。</span><br><span class="line">人：火星现在是什么天气？</span><br><span class="line">AI：func call marsweather</span><br><span class="line">人：下雨</span><br><span class="line">AI：目前火星的天气是雨天</span><br></pre></td></tr></table></figure>
<p>AI会自动通过上下文判断缺少什么数据，会主动要求获取什么信息，这是LLM表现出的一个特殊能力。</p>
<p>随后我们包装了Function Call的能力，后面甚至发展出了更多的实践标准，比如MCP。这大大增强了AI的能力边界。</p>
<p>第二个质变的点是RAG。有个黄金8000字法则，LLM对于最近的8000字记忆相对深刻，大部分时候会严格按照这8000字的要求来回答。</p>
<p>所以假设我们在这8000字中输入一些有时效性的信息，或是一些对回答有用的知识，可以让LLM在输出结果时大大增强准确性。举个例子，就是从闭卷考试变成了开卷考试。</p>
<p>RAG全名是检索增强生成。</p>
<p>首先是检索，我们的知识库很大，上下文很长，因此得先寻找和用户的提问最相关的内容。就像开卷考试我们看着题目去目录里找相关的页码。</p>
<p>在检索这一步，可以利用各种NLP的技术来确定文本的相关性。这里还有召回率等指标用于测试检索方法的准确性。</p>
<p>再深入一点说，这里的检索还有很多东西，比如可以提供用户的个人信息来增强生成结果的个性化能力；可以优化embadding模型来提高分片逻辑；生成知识图谱等；</p>
<p>但无论如何，检索的目标只有一个，就是找到相关的文本片段，然后一并提供给LLM。</p>
<p>LLM生成结果的这一步，可以理解为人脑思考、推理的过程，我们提供相关性更强的上下文，以提高结果的准确性或是质量。</p>
<p>大模型的幻觉问题，在目前RAG的机制下，已经很少了。目前更多的问题是原始的数据，也就是提供的文本片段可能是错误的虚假的。</p>
<p>在AI越发强大的情况，已经有相当一部分的工作可以被AI取代了。</p>
<p>程序员是脑力劳动的职业，但<strong>实际工作中的生产力会被限制在过时的人机交互技术</strong>上。编码是个体力活，设计画图也是，人总是一下子就能想到结果，但最麻烦的却是把想法变成现实。</p>
<p>以前有IDE，有提示补全，能减少一部分编码的重复工作，但依旧不够。</p>
<p>如今的AI开发工具，人需要手动说出自己的需求，AI会自动进行实现和编码。人在AI产出的基础上进行进一步提示或手动改写。</p>
<p>这确实相当程度上减少了编码的重复工作，在AI生成的结果有质量保证时，很多时候就是说需求然后tabtab或是点击接受。</p>
<p>很多人喜欢用马车和汽车的比喻来形容新事物产生时对生产力发展的影响。</p>
<p>但我觉得目前LLM对编程的影响还没到马车和汽车这级别，更像是人力车到马车。</p>
<p>以前程序员需要手敲代码，手动debug査资料。随着工作的进行，编码能力会自然提高。</p>
<p>就像种地的人，身体也会被锻炼到。</p>
<p>但到了LLM时代，手敲代码的机会逐渐减少，更多的时候程序员只是充当了LLM的一个助手。大部分工作是复制粘贴代码和错误信息，来回切换IDE和LLM的对话界面。</p>
<p>就像马车的车夫，重点在于怎么驾驭马，而不是拉车本身了。</p>
<p>随着工作的进行，程序员本身的能力成长相当有限。</p>
<p>此时，还想提升编码能力，可能就得专门锻炼了。就像不种地以后，想锻炼身体就得去健身房；程序员的工作有大量被LLM覆盖后，想提高编码能力也得专门锻炼。</p>
<p>为了适应这种从人力车到马车的变化，我也得转变观念了吧。</p>
<h2 id="未来是一片迷茫">未来是一片迷茫</h2>
<p>我看不到两年之后的事情。</p>
<p>这是我最近的一个想法。大到国际局势，小到身边的就业，我朋友的境况。这些事情中我能看到的最远的，也仅有两个月。</p>
<p>不知道什么时候就失去了长期规划。</p>
<p>实际上在刚毕业的时候还是很自信的，觉得自己可以在就业的前10年完成学历的提升，把工作换到老家，找一个女友，定居在大城市。</p>
<p>5年一过，这些都已经完成，但我却不知道下一步会是什么？</p>
<p>技术的潮流并没褪去，每年都有新的技术热点出现，大家不知道明年会不会出现什么新东西。大多团队年初的计划撑不过一个季度就直接推翻重来。</p>
<p>政治上，美国成了国际局势的搅屎棍，世界各地的摩擦走火也时有发生。俄乌的仗打了好些年，大家都想着会不会继续扩大化。</p>
<p>可能两年内台湾就收复了，可能接着中美竞争白热化，可能明天的黄金还会继续走高。</p>
<p>不管怎么说，这几年都是无法稳定的，迷茫才是常态。</p>
<p>而我能做的，就是相信自己的判断，一条道走到黑吧。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>技术协议</tag>
      </tags>
  </entry>
  <entry>
    <title>回炉重造是种什么样的感觉？</title>
    <url>/%E7%94%9F%E6%B4%BB/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/</url>
    <content><![CDATA[<h2 id="就读体验">就读体验</h2>
<p>整体来说，在polyu的就读体验还算不错。</p>
<p>各种流程都会有较为详细的指引。比如入学、选课、课程的考试之类的日常流程，都有邮件会提醒，邮件中会有很详细的说明，足够每个人完成这些。</p>
<p>每个学生也都会收到不少附赠的资源，比如学生的云电脑有两块免费的4090ti可用。在学校想训练自己的大模型，或是做一些微调都足够用了。</p>
<p>同学倒是也都挺实在的。毕竟排名是港三之外吧，挺少见到本科985的同学，遇到的985也大多是转方向来读计算机的。像我这种工作4年再来读书的确实是少数的少数。这也导致了遇到的同学大多很佛系，不太在意成绩，大多是一个能过就行的态度。某种意义上倒也挺符合对港留子的刻板印象的。</p>
<p>虽说绝大部分人都是抱着一个拿到学位就算成功的态度，但同学中也有少数比较卷的，大部分是local，目标都是继续深造读博。</p>
<p>学校的课也不算太水，NLP、AI concept和Big Data都会介绍目前最前沿的技术。对于我这种没接触过AI算法的人来说，确实有点头大。不过也算学到了新东西，倒也不亏。</p>
<p>本科毕业之后，可能大家都已经有了自己的规划。对于读书这事，目的也各不相同。</p>
<p>这港硕的一年，就像是把一群各有自己想法的人聚集到了一块儿，每次遇到陌生同学，聊几句就会发现对方过着和你截然不同的人生。</p>
<p>从我个人角度，满分100，我给港理工打90。10分扣在不是港三，但这事也怨我，早点申请可能也就到港三去了。</p>
<h2 id="回炉重造的成果">回炉重造的成果</h2>
<p>挨过了社会的毒打，重新回到校园，以为会是狼入羊群嘎嘎乱杀，结果是发现牛混到了羊群里，居然要重新学怎么吃草。</p>
<p>技术栈差别很大，真的很大。我原本是搞工程方向的人，但是研究生也不得不去学算法，学AI的技术了。</p>
<p>大模型的风确实刮到了各种地方，现在是个学科只要挂上机器学习的名头就能变成一个新学科，一个新方向。</p>
<p>风来了，那么也只能顺着风的方向去飞。借着学校的课程，我也开始在AI这块入了个门。</p>
<p>到NLP的小组作业，也算是小小地喷发了一会儿。</p>
<p>我久违地写了点代码，然后把服务部署到了阿里云的云服务器上，最后接入通义千问大模型。搞出来的效果让同组的人都惊呆了。</p>
<p>其他组大多是在大模型的上层做了RAG，但我的思路是在RAG之外要给模型提供插件来获取实时信息，否则这个项目的成果完全不可用。</p>
<img src="/%E7%94%9F%E6%B4%BB/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/image-20241121203740450.png" class="" title="image-20241121203740450">
<p>做完的时候有种感觉，就是自己好像确实学了不少新玩意儿。</p>
<p>这次回炉重造，最初的目标就是能开拓一些新的知识点，希望能学python，学数据分析，学AI训练，学会写前端。</p>
<p>我觉得还是有些进步的，至少python会写了，数分也入门了，大模型的训练、微调也会了。目前还差点前端，打算是考试期间学点微信小程序的前端，先入门一下。</p>
<p>也慢慢明白自己擅长和不擅长的地方，对未来的规划也更加明确了。</p>
<p>回炉重造初显成效。</p>
<h2 id="看过猪跑很重要">看过猪跑很重要</h2>
<p>我当时下定决心要读研究生，这句话对我影响很大：“看过猪跑很重要”。</p>
<p>应该是阿里的毕玄在一次采访中说的。大概意思是公司的业务发展中，总会随着业务量出现各种新的问题。这时候能了解其他人的解法，是非常有参考价值的。</p>
<p>拿阿里来说，当时国内没有什么公司能作为参考，他们会去找谷歌的案例。但是找到的案例可能是10年前的，对于当时的业务量，足以够用。</p>
<p>而业务快速成长，遇到的困难也越来越多。到某一天，突然发现谷歌也没处理过现在阿里遇到的问题了。那这时候怎么办？</p>
<p>唯有自己解决了？</p>
<p>非也。这时候，答案在学术界。</p>
<p>时代变化，公司可能已经成长为巨头，此时不能直接照抄人家的答案，你也得作为开拓者参与最前沿的技术。</p>
<p>这时候各种国际会议、学术论文会进入你的视野，从学术角度找方案来落地才是最切实可行的。为什么说&quot;看过猪跑很重要&quot;，学习的知识来源是实践，而模仿是实践中效率最高的方式。</p>
<p>公司的业务变化，模仿的对象也要变化。当接近了金字塔的顶尖，所有人都不得不参与到名为学术的圈子里。</p>
<p>而这时候，你也得产出一些成果，可能是学术会议上的论文、各种分享会上的演讲，你也会变成别人眼中奔跑的猪。</p>
<p>我想读研究生，就是希望能先打个基础，以后做到这个程度的时候不会有短板。</p>
<h2 id="回炉重造的感受">回炉重造的感受</h2>
<p>自由、时间充裕、需要自控力。这三点是我最大的想法。</p>
<p>不用上班之后确实时间很多，也很自由，但是想做些什么有意义的事情，得靠自控力。</p>
<p>我每年都有立个目标和年末总结的习惯。</p>
<p>今年的目标，有两个：上学和变全栈。上学算是完成了，全栈还需要一点点时间，不过我相信我绝对没什么问题。</p>
<p>当时脑袋里萌发出读研的想法，我觉得这个决定可能会影响我一生，于是我马上订了去广州的高铁去找中介，并且立马签了合同。</p>
<p>现在已经初现倪端，我接触的技术范围大大超过了工作时。</p>
<p>我始终觉得方法比实际的努力更重要，因此我学习更注重学会学习方法，走通学习新知识的路，而不是学会这个知识本身。</p>
<p>在这方面，研究生读得还挺值得的。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>我为什么选择去留学</title>
    <url>/%E7%94%9F%E6%B4%BB/life/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9%E5%8E%BB%E7%95%99%E5%AD%A6/</url>
    <content><![CDATA[<p>眼下我正在中国人民大学的教学楼二2211教室，坐在一个小小的椅子上，有充足的时间来整理思绪。</p>
<h2 id="起因">起因</h2>
<p>去香港留学的想法，其实很早就有了，最早应该能追溯到大三。当时思考要不要读研，摆在眼前的就是考研或者出国留学。</p>
<p>留学确实会轻松不少，不用和考研的人一起卷了。我当时想法是去香港，既不会太远太贵又能有留学的待遇。而且香港只需要一年，后续毕业证书大家也认。</p>
<p>但最后各方面原因，还是没有去。</p>
<p>工作了以后，老爸每次和我打电话，都要问我：“你现在这样一个本科文凭，你觉得够用么？” 我心里也没数，只是一直说着：“三年之后再看吧。” 那时候觉得工作本身对学历的要求并不高，也就没想着需要去读研究生。</p>
<p>眼看就是第三年了，我也得做个决定。这得感谢我的女朋友，是她坚定了我去读书的信念，也给了我支持。</p>
<h2 id="理由">理由</h2>
<p>这三年，我看了MBA和其他的途径，比较之下，去香港读书就是我最后的选择。</p>
<p>主要原因有三点。</p>
<p>第一，时间应该尽量短。考虑我是已经有工作经验的状况，再去读三年书说实话会与社会有一定的脱节。而且从业经历说明我本身的能力已经足够进行工作，那么读书其实并没有太多的提升。刚好香港的授课型硕士是一年，那么不会挤占太多工作时间。</p>
<p>第二，门槛不能太高。工作之后时间宝贵，我不能抽出太多的时间花在申请上，为了读一个研究生平时也得花费大量的精力去申请或者去准备，也是有点得不偿失。我本科是985，走考研的话这个优势就没了，所以还是得走申请制的。香港是申请制，我只需要准备好雅思，剩下大部分问题都不是问题。</p>
<p>第三，学校要有一定的知名度，毕业证得是大陆认的。英国的水硕已经被行业拉黑了，但香港意外的风评还可以。再加上考公、国企都认可这个学历，那么香港的一年制硕士确实是性价比比较高的选择。</p>
<p>如果还说有别的，那么就是香港的学费相对来说不高。比起出国留学的花费，香港的大学所需费用并不算特别高，一年下来也就是二十万左右，加上生活费大约三十万，属于大部分人可以承受的范围。</p>
<p>还有就是家人的支持，我觉得也很重要。毕竟留学的费用不是一笔小数目，很多时候还是得靠家里人。</p>
<h2 id="补充">补充</h2>
<p>时间到了12月，雅思的进度不是很理想，最坏的情况可能是明年才能开始申请。</p>
<p>到现在这个时候，我感觉继续去读书更多的是为了让我能有一个时间去学习、去整理一直以来接触到的这些琐碎知识。</p>
<p>从北京出来回来之后，我开始整理另一个内存数据库的项目。虽说本质是对接JNI，但是通讯方式上还是有不少文章可以做。进程间通讯目前最快的方式就是共享内存，内存数据库就是用的这个技术。但是JVM外部的数据，怎么同步到JVM内部呢？之前Google的思路是用Binder，实现了单次拷贝的内存共享。我觉得这很不错。</p>
<p>在这个项目的预研过程中，我觉得自己对以前自己所学的知识有了更深入的了解。我开始思考是不是应该复习一下原来学的一些知识，然后重新去学一些更深入、更有趣的玩意儿。</p>
<p>同时，我也发现，国内的技术文档、技术博客之类的普遍质量一般。或许是和观念、想法、成长时间有关，目前国内的人，大多是半路出家开始接触计算机，在计算机的基础知识上，大多数人都很薄弱。尤其是现在各种框架、高级编程语言大行其道，大家都更贴近业务，而不会去考虑做更深入、更底层的代码实现了。这其实就导致了，我在查阅资料的过程中，很多时候还是得去看外网的英文资料。</p>
<p>还有一点，在国内纯粹的技术人员说实话并不讨好，毕竟公司赚钱还得靠业务。纯粹的技术人，是赚不到钱的。赚不到钱，在公司里就很难有话语权。而且纯粹的技术部门容易养出深闺大将军，这也是当时阿里拆分中台之后，我的第一想法。时代在进步，技术和业务的边界并没有那么大，或者说，现在对技术人有了更高的要求。你要懂业务，懂各种的业务，然后才能抽象业务模型，提供最切实好用的技术中间件。</p>
<p>出于这些想法，我觉得留学可能也是一个不错的机会。一方面可以远离这些项目的是是非非，好好学一些东西，整理沉淀自己这几年来的所学。另一方面，也可以去看看更大的世界，看看外面那些小崽子到底有多不做人，也算是师夷长技以制夷嘛。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>股市投机的原则</title>
    <url>/%E7%94%9F%E6%B4%BB/life/%E8%82%A1%E5%B8%82%E6%8A%95%E6%9C%BA%E7%9A%84%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<h2 id="A股的底层逻辑是博弈">A股的底层逻辑是博弈</h2>
<p>这是对A股市场中股价波动的解释。在A股市场中，几乎没有人是通过分红的复利来实现财富增长和价值投资的。</p>
<p>那么，所谓的政策利好其实也只是给赌徒们指明了一个方向：下一波我们炒这个。</p>
<p>各类大资金做局，通过政策指引等方式制造热点，让散户和其他游资集中到某个股票中，然后大资金们出手给小资金，小资金出售给散户。</p>
<p>这里分两种情况来讨论：</p>
<p>第一种：新热点出现导致某个版块普涨。某些政策出台后，会对某些版块产生明显的利好。这时候短线资金会集中到这个版块中，不同资金会随机寻找版块中的某个股票买入，导致版块中的股票呈现出不同的涨幅。</p>
<p>某些股票涨幅大，那么就会吸引更多的散户和其他大资金来买入，最终表现就是封板。</p>
<p>一个版块中可能有多支股票都是涨停的，那么第二天就会继续在这些股票中寻找能继续封版的股票，也就是所谓的一进二，二进三等。</p>
<p>假如有其他的热点出现，可能这些昨天涨停的票今天都会跌。</p>
<p>假如市场上的其他人不认账，那这些票可能今天也会继续跌下去。</p>
<p>还有种可能是其他人继续追高，在昨天形势较好的股票中选择某几个继续大量买入，这时候就会出现连板。</p>
<p>连板中，会有些票会掉队，因为市场上参与的资金是有限的，击鼓传花的游戏在某一个时刻会因为没有其他人来买而结束。</p>
<p>资金会集中向头部的股票，直到头部的股票价格过高，没有人愿意再买了。</p>
<p>如果热点足够吸引人，还会有补涨。就是头部的连板票带动了市场中其他版块的活跃资金也参与到本版块中，其他的活跃资金可能因为前排的连板票买不到而选择去买入同版块还没炒起来的股票。这种被其他资金选择的票可能也会连板，并且在头部的连板票破板时，成为市场上资金新的宠儿。</p>
<p>头部的连板票，一般称为龙头；补涨的票，称为补涨龙。还有些票，一直随着版块在偷偷涨，但没有涨停，这种称为中军，一般是市值较大的白马股。</p>
<p>第二种：版块的资金回流。龙头崩了之后，势必会带动大量的资金一起抛售，这时候股价跌停都是正常的。</p>
<p>但是在跌停时，可能有资金认为这票还能涨，于是在低位进行接盘。当有足够多的资金认为还能涨时，就会出现弱转强，也就是资金的回流。</p>
<p>比如昨天龙头跌停，预期是今天继续跌停。但是实际上开盘是正，并且股价起飞，那么就可以认为有人觉得这票还能涨。如果弱转强的共识足够，那么就能把本来短板的龙头重新抬起来继续涨。</p>
<p>弱转强是非常常见的，同时也是相当有效的赚钱手段。</p>
<p>这里讲了两种博弈的方式，其实简单概括，就是先信卖给后信。</p>
<h2 id="设立止损目标">设立止损目标</h2>
<p>在赚钱时，也应该设立止损目标，比如利润回撤到3%就清仓。</p>
<p>无论如何，少赚总比不赚好。如果利润回撤了，就说明肯定有更好的清仓时机，应该去思考什么时候清仓更合适，而不是死扛把利润都亏空了。</p>
<p>在亏钱时，也要设立止损目标。止损是个麻烦事儿，大部分人总会妄想自己后面可以重新赚回来。但止损时应该想的是自己为什么当时会去买入这个股票，说明需要优化买入时机。</p>
<h2 id="不做自己不了解的行业">不做自己不了解的行业</h2>
<p>自己不了解的行业，可能会导致决策失误，进而导致亏钱。</p>
<p>只做自己了解的行业是对自己负责。</p>
<h2 id="不做太小的票">不做太小的票</h2>
<p>如果一个票的市值过小，可能随意一个游资都能在这票坐庄。</p>
<p>庄股是最恶心的，上涨和下跌没有任何规律可言。</p>
<h2 id="尽量做股性活跃的票">尽量做股性活跃的票</h2>
<p>股性活跃，指的是这个版块有利好时，大部分资金都会首先选择买入这个股票。这种股票在长期活跃的版块都有存在。</p>
<p>可以说大家可能对老龙都有记忆吧，每次有利好都优先把以前连板过的票拉出来再炒一次。</p>
<h2 id="少碰kdj在20-80之间的票">少碰kdj在20-80之间的票</h2>
<p>kdj指标说明了短期一支股票的超买和超卖的情况。如果一个股票的kdj在20-80之间，大概率说明这票最近没什么人在炒。</p>
<p>没人炒的票持有了也很难获得大量收益。</p>
<h2 id="遵循自己的规则">遵循自己的规则</h2>
<p>设立自己的交易规则，严格遵守规则，并在复盘时适时调整规则。</p>
<p>交易时间一定要按照自己的交易规则来进行交易，东买一个西买一个总有一天赚的都要亏回去。</p>
<p>如果一次交易是亏钱的，说明交易规则有问题，想办法调整并避免以后还出现类似的问题。这种态度才是正确的。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>投资</tag>
      </tags>
  </entry>
  <entry>
    <title>龙年第一天</title>
    <url>/%E7%94%9F%E6%B4%BB/life/%E9%BE%99%E5%B9%B4%E7%AC%AC%E4%B8%80%E5%A4%A9/</url>
    <content><![CDATA[<p>昨晚8点从德清出发，到杭州转乘卧铺高铁，今早6点45到深圳北。从深圳北出站，坐5号线地铁到家，放下了行李，洗了个脸，匆匆忙忙出门上班。</p>
<p>早上8点，到工位坐下。原来从老家到工位，也不过12个小时的距离。</p>
<p>回顾去年，我最大的一件事，就是选择去香港留学。找了中介，考了雅思；至于这个选择最大的动力来源，就是我的女朋友。工作上，出差去北京中信证券，去惠州集中开发；深入业务线，搞懂了不少东西；也当了小领导，分配和规划任务，和其他人对接。</p>
<p>去年确实是做了不少事。</p>
<p>过年期间，也试着去学开车。这事情上手之后确实不难。也拜访了女朋友的家里，还在她家吃了两顿饭，见了她的亲朋好友。最后一天上午，我收到了第一份offer，来自港理工。这个年圆满收工。</p>
<p>那今年的话，我就得准备好去读书了。工作中，手上的事情也要慢慢放下，或者分配给别人，或者直接收尾。</p>
<p>今年想做的事情有好多，我要学粤语，要健身，要学python，想去旅游，想赚钱……人生总是这么丰富多彩，有些事情，一旦开始，就踩不住刹车了。</p>
<p>我真的非常感激我的女朋友，没有她的支持，我一定不会有动力去改变。我和她规划了好多好多的未来，这些都等着我们去实现。</p>
<p>最后，希望在新的一年，我能拿到更好的offer，能在工作上有更多的创新，能减肥成功，能学好粤语。</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB速览</title>
    <url>/%E5%AD%A6%E4%B9%A0/study/MongoDB%E9%80%9F%E8%A7%88/</url>
    <content><![CDATA[<p>MongoDB是一个NoSQL数据库，并非如同传统数据库一样使用结构化的表来存储数据，在性能上有一定优势。</p>
<h2 id="存储格式">存储格式</h2>
<p>MongoDB 采用数据库（Database）、集合（Collection）和文档（Document）的三层结构：</p>
<ul>
<li><strong>数据库（Database）</strong>：多个集合的逻辑分组，每个数据库有独立的权限控制和物理文件。</li>
<li><strong>集合（Collection）</strong>：一组相关文档的集合，类似关系型数据库中的表，但集合内文档可具有不同结构。</li>
<li><strong>文档（Document）</strong>：数据的基本存储单位，由键值对组成，类似 JSON 对象，但支持更多数据类型（如日期、二进制数据）。</li>
</ul>
<p>用MySQL中的概念来对应：</p>
<table>
<thead>
<tr>
<th>MySQL</th>
<th>MongoDB</th>
</tr>
</thead>
<tbody>
<tr>
<td>Schema（库）</td>
<td>Database</td>
</tr>
<tr>
<td>Table（表）</td>
<td>Collection</td>
</tr>
<tr>
<td>Record（行）</td>
<td>Document</td>
</tr>
</tbody>
</table>
<p>与关系型数据库结构化的数据不同，MongoDB中的Document是一种更加灵活的结构，类似JSON。</p>
<ul>
<li><strong>数据模型</strong>：以 BSON 文档形式存储半结构化 / 非结构化数据，支持嵌套字段（如对话中的消息列表、用户元数据），模式灵活（无需预定义表结构）。</li>
<li><strong>存储优势</strong>：适合存储格式多变的聊天记录（如文本、多媒体附件、JSON 格式的对话元数据），支持高效的文档级读写。</li>
<li><strong>典型场景</strong>：存储用户对话的原始数据，如<code>&#123;user_id: &quot;u123&quot;, messages: [&#123;role: &quot;user&quot;, content: &quot;...&quot;, timestamp: ...&#125;, ...]&#125;</code>。</li>
</ul>
<h2 id="查询">查询</h2>
<p>MongoDB允许用户创建过滤器（Filter）进行查询，更新和删除。支持等于、小于、包含等运算符。</p>
<ul>
<li><strong>基础查询</strong>：支持丰富的文档查询（如按用户 ID、时间范围、消息类型过滤），内置<code>$text</code>索引支持简单文本搜索，但分词能力较弱（需配合第三方插件如 MongoDB Atlas Search）。</li>
<li><strong>复杂查询</strong>：聚合管道（<code>$lookup</code>、<code>$match</code>等）适合统计分析（如用户对话频次、消息长度分布），但全文搜索性能不如专业搜索引擎。</li>
</ul>
<p>示例代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建MongoDB客户端连接</span></span><br><span class="line">mongoClient = MongoClients.create(CONNECTION_STRING);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取数据库（如果不存在会自动创建）</span></span><br><span class="line"><span class="type">MongoDatabase</span> <span class="variable">database</span> <span class="operator">=</span> mongoClient.getDatabase(DATABASE_NAME);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取集合（如果不存在会自动创建）</span></span><br><span class="line">MongoCollection&lt;Document&gt; collection = database.getCollection(COLLECTION_NAME);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询所有文档</span></span><br><span class="line">System.out.println(<span class="string">&quot;所有用户:&quot;</span>);</span><br><span class="line"><span class="keyword">try</span> (MongoCursor&lt;Document&gt; cursor = collection.find().iterator()) &#123;</span><br><span class="line">    <span class="keyword">while</span> (cursor.hasNext()) &#123;</span><br><span class="line">        <span class="type">Document</span> <span class="variable">doc</span> <span class="operator">=</span> cursor.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;  &quot;</span> + doc.toJson());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 条件查询</span></span><br><span class="line">System.out.println(<span class="string">&quot;\n年龄大于27的用户:&quot;</span>);</span><br><span class="line"><span class="keyword">for</span> (Document doc : collection.find(<span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;age&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$gt&quot;</span>, <span class="number">27</span>)))) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;  姓名: &quot;</span> + doc.getString(<span class="string">&quot;name&quot;</span>) + </span><br><span class="line">                     <span class="string">&quot;, 年龄: &quot;</span> + doc.getInteger(<span class="string">&quot;age&quot;</span>) + </span><br><span class="line">                     <span class="string">&quot;, 城市: &quot;</span> + doc.getString(<span class="string">&quot;city&quot;</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询单个文档</span></span><br><span class="line"><span class="type">Document</span> <span class="variable">user</span> <span class="operator">=</span> collection.find(<span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;张三&quot;</span>)).first();</span><br><span class="line"><span class="keyword">if</span> (user != <span class="literal">null</span>) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;\n找到用户张三: &quot;</span> + user.toJson());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 统计文档数量</span></span><br><span class="line"><span class="type">long</span> <span class="variable">count</span> <span class="operator">=</span> collection.countDocuments();</span><br></pre></td></tr></table></figure>
<h2 id="更新">更新</h2>
<p>MongoDB提供了<code>$push</code>操作符，可以直接在数组的末尾追加新的内容。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 更新单个文档</span></span><br><span class="line"><span class="type">Document</span> <span class="variable">filter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line"><span class="type">Document</span> <span class="variable">update</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$set&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;age&quot;</span>, <span class="number">26</span>).append(<span class="string">&quot;email&quot;</span>, <span class="string">&quot;zhangsan_new@example.com&quot;</span>));</span><br><span class="line">collection.updateOne(filter, update);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 更新多个文档</span></span><br><span class="line"><span class="type">Document</span> <span class="variable">multiFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;age&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$gte&quot;</span>, <span class="number">30</span>));</span><br><span class="line"><span class="type">Document</span> <span class="variable">multiUpdate</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$set&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;status&quot;</span>, <span class="string">&quot;高级用户&quot;</span>));</span><br><span class="line"><span class="type">long</span> <span class="variable">modifiedCount</span> <span class="operator">=</span> collection.updateMany(multiFilter, multiUpdate).getModifiedCount();</span><br></pre></td></tr></table></figure>
<h2 id="安装">安装</h2>
<p>MongoDB有官方提供的云服务Atlas，除此之外还有社区版本可自行安装在本地环境中。</p>
<h2 id="分片与高可用">分片与高可用</h2>
<p>MongoDB可设置分片键，集群模式下可分片存储数据。支持高可用，可添加分片的副本，分片自动进行主从复制。新增分片时可自动迁移数据。</p>
<h2 id="其他关注点">其他关注点</h2>
<p>MongoDB并非强一致性数据库，集群模式仅保证最终一致性。主从间数据同步可能有延迟。</p>
<p>MongoDB在单表查询上基本可以做到与关系型数据库的功能完全一致，但它不提供连表查询的能力。</p>
<p>MongoDB的没有事务的概念，但提供了乐观锁和表锁来做并发控制。</p>
<h2 id="自测结果">自测结果</h2>
<p>测试使用JMH。连接本地的MongoDB，无网络开销。</p>
<p>创建10000条数据，进行各类操作的压测。测试条件与实际环境的差异较大，仅用于比较MongoDB中各类操作的相对速度差异。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Benchmark                                          Mode  Cnt      Score       Error  Units</span><br><span class="line">MongoDBBenchmark.aggregateConversationPatterns    thrpt    3    01.234 ±    37.890  ops/s</span><br><span class="line">MongoDBBenchmark.aggregateUserStats               thrpt    3   1406.205 ±   212.137  ops/s</span><br><span class="line">MongoDBBenchmark.findByComplexQuery               thrpt    3   2480.271 ±   752.953  ops/s</span><br><span class="line">MongoDBBenchmark.findById                         thrpt    3  19871.945 ±   745.196  ops/s</span><br><span class="line">MongoDBBenchmark.findByUserId                     thrpt    3   7179.610 ±   322.021  ops/s</span><br><span class="line">MongoDBBenchmark.findConversationsWithKeyword     thrpt    3  10134.823 ±  1724.197  ops/s</span><br><span class="line">MongoDBBenchmark.insertSingleMemory               thrpt    3  21558.957 ±  1471.634  ops/s</span><br><span class="line">MongoDBBenchmark.pullConversationTurn             thrpt    3  18906.034 ±  1834.565  ops/s</span><br><span class="line">MongoDBBenchmark.pushMultipleConversationTurns    thrpt    3   3232.437 ± 21046.933  ops/s</span><br><span class="line">MongoDBBenchmark.pushNewConversationTurn          thrpt    3   6643.531 ± 21310.978  ops/s</span><br><span class="line">MongoDBBenchmark.updateMemoryMetadata             thrpt    3  19002.191 ±  1145.903  ops/s</span><br><span class="line">MongoDBBenchmark.updateMultipleMemoriesBySession  thrpt    3   6960.245 ±  1844.975  ops/s</span><br></pre></td></tr></table></figure>
<p>聚合查询对话中的关键词的效率较低，仅211 ops/s。</p>
<p>其他操作大多使用主键进行更新、查询和删除，效率较高。</p>
<p>测试过程中push操作的几次迭代的ops分别为10000，8000, 6000，4000。</p>
<p>可见push随着操作次数的增多，性能逐渐下降，<strong>push操作变为瓶颈</strong>，在测试结果中体现为误差较大。</p>
<p>MongoDB在5.0之后提供了<strong>Time Series Collection</strong>，但需要集群模式下才能使用，目前无法进一步验证。</p>
<p>本地demo测试的结果有失真，但测试过程中确实不再观察到性能逐渐下降的情况：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Benchmark                                                    Mode  Cnt      Score      Error  Units</span><br><span class="line">MongoDBTimeSeriesBenchmark.aggregateConversationsByHourTS   thrpt    3    437.986 ±   32.994  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.aggregateUserActivityTS          thrpt    3     84.750 ±    7.145  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.batchInsertConversationsTS       thrpt    3    500.700 ±  867.575  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.findByTimeRangeTS                thrpt    3    317.839 ±  454.249  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.findConversationsByMemoryIdTS    thrpt    3   4928.739 ± 1019.191  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.insertSingleConversationRegular  thrpt    3  23881.689 ± 3528.365  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.insertSingleConversationTS       thrpt    3   6425.600 ± 4511.080  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.simulatedPushOperationRegular    thrpt    3  23796.839 ± 1890.437  ops/s</span><br></pre></td></tr></table></figure>
<h2 id="集群部署">集群部署</h2>
<p>官方部署文档：<a href="https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-shard-cluster/#std-label-sharding-procedure-setup">https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-shard-cluster/#std-label-sharding-procedure-setup</a></p>
<p>身份验证文档：<a href="https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-sharded-cluster-with-keyfile-access-control/">https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-sharded-cluster-with-keyfile-access-control/</a></p>
<h3 id="部署说明">部署说明</h3>
<p>本次选用Mongodb的分片部署，使用密钥文件进行身份验证。</p>
<p>MongoDB的分片集群有三类子集群：Shard、Mongos、Config。</p>
<p>这三个程序其实都是MongoDB，只不过是以不同的模式启动。</p>
<img src="/%E5%AD%A6%E4%B9%A0/study/MongoDB%E9%80%9F%E8%A7%88/image-20250704104015740.png" class="" title="image-20250704104015740">
<h4 id="Shard分片">Shard分片</h4>
<p>Shard为分片集群，存储实际的数据。</p>
<p>每个分片都需要做主备，组成副本集，主备节点间数据相同。</p>
<p>假设有两个分片，每个分片有一主两备，则最后共计有6个分片的实例。</p>
<p>开发测试环境可使用单个实例组成副本集。</p>
<h4 id="Mongos路由节点">Mongos路由节点</h4>
<p>Mongos为路由节点。</p>
<p>所有操作都打到Mongos节点，Mongos负责转发请求至对应的分片节点查询数据。</p>
<p>Mongos没有主备的概念，可随意添加或删除。</p>
<h4 id="Config配置节点">Config配置节点</h4>
<p>Config为配置节点，用于对Mongos节点间同步路由信息，需要做主备。</p>
<p>开发测试环境可使用单个节点。</p>
<h3 id="安装Docker">安装Docker</h3>
<p>本文档中使用Docker安装MongoDB的各个实例，这里对Docker的安装不多赘述。</p>
<h3 id="密钥生成">密钥生成</h3>
<p>生成一次，在同个集群内共用，复制后要继续设置文件的权限，太开放了也会导致起不来。</p>
<p>生成密钥的命令，并修改其权限，其中<code>/opt/mongo-keyfile</code>为文件路径：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">openssl rand -base64 756 &gt; /opt/mongo-keyfile</span><br><span class="line"></span><br><span class="line">chmod 400 /opt/mongo-keyfile</span><br><span class="line">chown 101:101 /opt/mongo-keyfile</span><br></pre></td></tr></table></figure>
<p>复制到其他服务器后，设置文件权限，命令同上：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod 400 /opt/mongo-keyfile</span><br><span class="line">chown 101:101 /opt/mongo-keyfile</span><br></pre></td></tr></table></figure>
<h3 id="系统参数设置">系统参数设置</h3>
<p>启用 THP（主机）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo “always” | sudo tee /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo &quot;defer+madvise&quot; | sudo tee /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure>
<p>设置 khugepaged 参数（主机）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo 0 | sudo tee /sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none</span><br></pre></td></tr></table></figure>
<p>持久化配置（主机）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo tee /etc/rc.local &lt;&lt; EOF</span><br><span class="line">#!/bin/sh -e</span><br><span class="line">echo &quot;defer+madvise&quot; &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo 0 &gt; /sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure>
<p>输入EOF退出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo chmod +x /etc/rc.local</span><br></pre></td></tr></table></figure>
<p>永久修改max_map_count</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &quot;vm.max_map_count=1677720&quot; | sudo tee /etc/sysctl.d/99-mongodb.conf</span><br></pre></td></tr></table></figure>
<p>应用配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure>
<h3 id="启动config">启动config</h3>
<p>创建docker卷用于持久化mongodb的数据。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker volume create mongodb-data</span><br></pre></td></tr></table></figure>
<p>放置密钥文件后，使用docker命令将其映射至镜像内部，并在启动命令上使用该密钥。启动命令为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">docker run --name mongodb-config-1 \</span><br><span class="line">-p 26000:27019 -v mongodb-data:/data/db \</span><br><span class="line">-v /opt/mongo-keyfile:/data/keyfile \</span><br><span class="line">-d mongodb/mongodb-community-server:latest \</span><br><span class="line">--keyFile /data/keyfile \</span><br><span class="line">--configsvr \</span><br><span class="line">--replSet configReplSet \</span><br><span class="line">--bind_ip 0.0.0.0</span><br></pre></td></tr></table></figure>
<p>其中 <code>/opt/mongo-keyfile</code>为宿主机的密钥文件路径，<code>--configsvr</code>是以config节点的模式启动MongoDB。</p>
<p>如果有多个config实例，则先启动多个实例后再进入下一步。</p>
<p>部署其他实例先也要调整系统参数和复制密钥文件，并且要修改密钥文件的权限，否则会启动失败。</p>
<p>注意，多个实例的<code>--replSet configReplSet</code>必须相同，密钥文件必须相同，否则在下一步初始化时会出错。</p>
<h3 id="初始化config">初始化config</h3>
<p>进入其中一个config实例的镜像内部，开始后续操作：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it mongodb-config-1 bash</span><br></pre></td></tr></table></figure>
<p>使用mongosh连接启动的MongoDB：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mongosh --host localhost --port 27019</span><br></pre></td></tr></table></figure>
<p>连接后，输入以下命令组成config副本集，保证最外层的<code>_id</code>与启动命令中的<code>--replSet</code>对应：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id: &quot;configReplSet&quot;,</span><br><span class="line">  configsvr: true,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.31:26000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>假设有多个config实例，则在以上命令中的members数组内加入其他的config节点信息。示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id: &quot;configReplSet&quot;,</span><br><span class="line">  configsvr: true,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.31:26000&quot; &#125;,</span><br><span class="line">   &#123; _id : 1, host : &quot;192.168.0.32:26000&quot; &#125;,</span><br><span class="line">   &#123; _id : 2, host : &quot;192.168.0.33:26000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>以上的初始化命令仅需要在某个实例执行一次即可，不需要在所有config实例上都执行一遍。</p>
<p>举例，有三个Config实例C1、C2、C3，则仅需要在C1上进行一次初始化即可。</p>
<h3 id="创建管理员">创建管理员</h3>
<p>继续在mongosh界面操作，创建config集群的管理员账户。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin = db.getSiblingDB(&quot;admin&quot;)</span><br><span class="line">admin.createUser(</span><br><span class="line"> 	&#123;</span><br><span class="line">    user: &quot;mongoadmin&quot;,</span><br><span class="line">    pwd: &quot;@Scg0830&quot;, </span><br><span class="line">    roles: [ </span><br><span class="line">    	&#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,</span><br><span class="line">    	&#123; role: &#x27;readWriteAnyDatabase&#x27;, db: &#x27;admin&#x27; &#125;,</span><br><span class="line">    	&#123; &quot;role&quot; : &quot;clusterAdmin&quot;, &quot;db&quot; : &quot;admin&quot; &#125;,</span><br><span class="line">      ]</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>后续连接时都需要验证用户名和密码，命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mongosh -u mongoadmin -p @Scg0830 --authenticationDatabase &quot;admin&quot; --port 27019</span><br></pre></td></tr></table></figure>
<h3 id="启动分片">启动分片</h3>
<p>先在分片节点上调整系统参数和放置密钥文件，然后再进行后续操作。</p>
<p>创建docker卷：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker volume create mongodb-data</span><br></pre></td></tr></table></figure>
<p>启动命令，与config的启动命令类似：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">docker run --name mongodb-shard-1 \</span><br><span class="line">-p 28000:27018 -v mongodb-data:/data/db \</span><br><span class="line">-v /opt/mongo-keyfile:/data/keyfile \</span><br><span class="line">-d mongodb/mongodb-community-server:latest \</span><br><span class="line">--keyFile /data/keyfile \</span><br><span class="line">--shardsvr \</span><br><span class="line">--replSet shardReplSet1 \</span><br><span class="line">--bind_ip 0.0.0.0</span><br></pre></td></tr></table></figure>
<p>如果要启动同个分片的副本（备份），要保证启动命令中的<code>--replSet</code>相同，同个分片的多个副本使用相同的副本集名称。</p>
<p>如果要启动多个分片，修改启动命令中的<code>--replSet</code>，当前的副本集名称为shardReplSet1，可以修改为shardReplSet2或其他的名称。</p>
<p>每个分片实例启动前务必修改系统参数和复制密钥文件，并修改密钥文件的权限，否则无法启动。</p>
<h3 id="初始化分片">初始化分片</h3>
<p>对于每一个分片的副本集，都需要初始化，以便让所有的副本集能互相建立连接。</p>
<p>首先进入其中一个实例的docker内部：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it mongodb-shard-1 bash</span><br></pre></td></tr></table></figure>
<p>启动mongosh，连接镜像内的分片实例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mongosh --port 27018</span><br></pre></td></tr></table></figure>
<p>输入以下命令初始化，保证最外层的<code>_id</code>与启动命令中的<code>--replSet</code>对应：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id : &quot;shardReplSet&quot;,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.85:28000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>如果有多个副本，则在members中添加其他的副本。示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id : &quot;shardReplSet&quot;,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.85:28000&quot; &#125;,</span><br><span class="line">   &#123; _id : 1, host : &quot;192.168.0.86:28000&quot; &#125;,</span><br><span class="line">   &#123; _id : 2, host : &quot;192.168.0.87:28000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>注意，同一个分片的副本集，仅需要初始化一次。</p>
<p>不同分片则需要每个分片都初始化一次。</p>
<p>举例，有两个分片A和B，每个分片内有三个副本（A1、A2、A3、B1、B2、B3）组成副本集。则在A1上对A1、A2、A3进行初始化，在B1上对B1、B2、B3进行初始化。</p>
<h3 id="安装mongos">安装mongos</h3>
<p>使用yum安装mongos。</p>
<p>先添加仓库，创建文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">touch /etc/yum.repos.d/mongodb-org-8.0.repo</span><br></pre></td></tr></table></figure>
<p>然后在文件中添加以下内容并保存。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mongodb-org-8.0]</span><br><span class="line">name=MongoDB Repository</span><br><span class="line">baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/8.0/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://www.mongodb.org/static/pgp/server-8.0.asc</span><br></pre></td></tr></table></figure>
<p>使用yum安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y mongodb-org-mongos</span><br></pre></td></tr></table></figure>
<h3 id="启动mongos">启动mongos</h3>
<p>先创建日志文件夹：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /var/log</span><br><span class="line">mkdir /var/log/mongodb</span><br></pre></td></tr></table></figure>
<p>复制密钥文件，并设置文件的权限，然后启动mongos：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mongos --keyFile /opt/mongo-keyfile --configdb configReplSet/192.168.0.31:26000 --bind_ip 0.0.0.0 --logpath &quot;/var/log/mongodb/mongos.log&quot; --fork --port 27000</span><br></pre></td></tr></table></figure>
<p>注意，启动命令中会连接config集群，必须保证<code>--configdb</code>与config节点的副本集名称相同，IP一致。</p>
<h3 id="添加分片">添加分片</h3>
<p>如果本机没有mongosh，则先安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install -y mongodb-mongosh</span><br></pre></td></tr></table></figure>
<p>使用分片管理员的角色登录mongos，账号密码与在config集群上创建的一致。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mongosh -u mongoadmin -p @Scg0830 --authenticationDatabase &quot;admin&quot; --port 27000</span><br></pre></td></tr></table></figure>
<p>添加分片：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sh.addShard( &quot;shardReplSet/192.168.0.85:28000&quot;)</span><br></pre></td></tr></table></figure>
<p>分片有多个副本，则使用逗号分隔：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sh.addShard( &quot;shardReplSet/192.168.0.85:28000,192.168.0.86:28000,192.168.0.87:28000&quot;)</span><br></pre></td></tr></table></figure>
<p>重复以上步骤把所有的分片都添加至mongos。</p>
<p>以上的分片信息会传至config节点并同步到所有的mongos中，后续有新的mongos加入也不需要重新添加分片信息。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>技术协议</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP的project复盘</title>
    <url>/%E5%AD%A6%E4%B9%A0/study/NLP%E7%9A%84project%E5%A4%8D%E7%9B%98/</url>
    <content><![CDATA[<h2 id="背景">背景</h2>
<p>这是第一门需要协作的大作业，过程中着实暴露了很多问题。我觉得是需要复盘来明确这些问题，以免在下次的作业中再有类似的情况发生。</p>
<p>项目要求是利用大模型的技术，结合课上所学的NLP相关知识，来开发一个对话模型。最终这个系统能做到让用户通过自然语言来查询某个领域的数据。</p>
<h2 id="过程">过程</h2>
<h3 id="第一次会议">第一次会议</h3>
<p>一开始可能是大家还不熟，我作为脸皮最厚的主动出来破冰。</p>
<p>这就像无领导小组讨论第一件事就是选领导；分布式等价节点一致性算法第一件事就是选主节点；Project第一个跳出来的人也会成为组织的核心。</p>
<p>之后就基本围绕着我的思路，开始选题，分配预研任务。我确定了一下开会的频率和任务的大致分配方向，以及日常的沟通方式，代码提交的仓库，保证这个项目推进必要的一些因素都已具备，第一次会议就算结束。</p>
<p>打算是分三周，第一周预研，第二周产出第一个demo，第三周产出最终的。</p>
<h3 id="第二次会议之前">第二次会议之前</h3>
<p>我这边主要是要预研RAG的基础框架和前端界面。</p>
<p>说实在的我也没多上心，粗看了一下AnythingLLM，跑了下本地模型发现展示的效果还可以。然后接入本地模型、通义千问和其他的一些模型试了下，认为这个框架基本可用，就算完事了。</p>
<p>数据爬取的任务倒是做得还可以，能拉到三个网站的数据。</p>
<p>需求分析决定了后续的提示词怎么写，这部分最终产出不是很标准，但也算有模有样，可以列入工作内容的一部分。</p>
<h3 id="第二次会议">第二次会议</h3>
<p>原先预订是第二次会议前要有产出的demo，所以第二次的会议上我就展示了一下AnythingLLM。其他的一些沟通已经没多少印象了，大概就是确定要做什么之后，直接进入模型微调的阶段了。</p>
<h3 id="第三次会议">第三次会议</h3>
<p>原先预定是在第二周产出一个demo，但是用AnythingLLM这个demo产出比我想得要快太多了…</p>
<p>然后第二周的目标在周二就算提前完成，摸了会儿鱼一直拖到第三周才进行第三次会议。</p>
<p>这第三次会议上演示了一下纯使用AnythingLLM的成果，客观来说包装一下作为汇报用的结果还真可以。</p>
<p>不过还是想着再做些事情，于是会后我又花了点时间去写了下插件。</p>
<h3 id="第三次会议后">第三次会议后</h3>
<p>由于我也没怎么写过python的工程，先花了点时间看了下python的工程结构。</p>
<p>插件开发需要模型支持，就想着先把模型从AnythingLLM搬到了阿里云的百炼平台上，花了一个小时吧。</p>
<p>看了下模型怎么自定义插件的文档，本来还想找找阿里云有没有提供案例，结果发现没有。</p>
<p>那没辙，先理解再说。</p>
<p>翻了下就是自己部署一个web服务，然后提供OpenAPI 3.0的接口文档和一个告知模型在什么情况下需要调用插件的prompt。那就简单了，实际的功能代码有现成的，我只需要把这些能力集成到web服务里就行。</p>
<p>于是开始翻怎么用python写web服务，发现有个quart的框架，快速写了demo，结论是可行。</p>
<p>找了下阿里云有免费的试用服务器，租了一个4核8G的服务器，ping了它的公网IP，通了。那这服务器也好说。</p>
<p>部署服务到云服务器，一调用发现不通。怀疑是权限问题，去控制台找了下权限控制的功能，开通端口，再调用通了。这部署也算完成。</p>
<p>用AI生成了OpenAPI 3.0的接口文档，接着写prompt，最后在百炼上创建一个插件，这样就算集成了。</p>
<p>调试了一下大模型调用插件的效果，发现还不错，至此完成了插件的功能。</p>
<p>最终的效果给同组的同学展示了一下，都说很可以。给他们开通了子账号的权限，每个人都能调整模型的prompt和看到最终的效果。</p>
<p>随后的时间就是准备pre和最终的report。</p>
<h2 id="复盘">复盘</h2>
<h3 id="问题分析暴露了思维的差异">问题分析暴露了思维的差异</h3>
<p>简单分析一下，在模型侧，要通过一些手段来让模型了解某个领域的数据。那么很自然就会想到专家模型，想到微调，接着答案就呼之欲出——RAG。</p>
<p>对，其实能做到RAG，这个项目基本已经完成了。</p>
<p>那么就涉及到数据来源的问题，这里就出现了第一次的思维差异。我倾向于额外添加插件的能力，能让模型获取到更具有时效性的信息。而其他人似乎并没有意识到这个能力的必要性，认为这个能力优先级不高，能先处理好RAG就可以了。</p>
<p>其次就是这个选题的方向是什么，大家一开始都没什么点子，于是我提出用头脑风暴的方式来发散思维。最终确定是做一个关于招聘信息的助手。</p>
<p>到最后，我干脆直接拉出日程表，列了下整个工作的日程和计划，也拟定了一些里程碑目标出来。大家也没多说什么，一下子就同意了。</p>
<h3 id="工作方式的妥协">工作方式的妥协</h3>
<p>如果是企业中接到一个项目，可能我第一反应是确定好日程计划，然后拉人开会，对齐拉通保证大家思维的一致性，留好联系方式，有什么问题及时调整。</p>
<p>但是实际在这个project的执行过程中，一来大家都挺陌生，不知道对方几斤几两；二来工具不齐，想做项目管理多多少少有些麻烦。最后只能妥协，用腾讯文档作为项目管理的一环，github作为配置库，以及任务分配全靠自觉。</p>
<p>所幸大家都还算给面子，仗着年纪大脸皮厚大家还算愿意听我讲话。</p>
<p>还有就是远程办公，在微信群沟通确实效率过于低下了，我个人会更喜欢用远程会议的方式来快速沟通。而且大家也不是集中在一处专心做这个project，互相之间配合和协调也是个问题。</p>
<p>最终妥协的成果，就是把任务提前分隔成较为独立的子任务，每个人认领其中一部分。然后我作为最终的统筹，收集各个成员的产出，并拼凑为一个较为合理的产物。</p>
<p>就我个人而言，这些都不算什么工作量，但是对于其他人而言可能会有些困难，毕竟没什么管理经验。所以我来担任也算是比较合理的。</p>
<h3 id="留好成长的空间">留好成长的空间</h3>
<p>整个过程中一直在强调要沟通，每个人的提交都能让其他人在本地运行。本意是想让每个人都参与进来，能看到project的当前的效果。</p>
<p>但第一个迭代这个事情做得不是很好。所以第二个迭代我就全面上云，让每个人都能参与进来。</p>
<p>我觉得一个项目的推进过程中，项目中的每个人都应该是有所成长的。作为领导，一定会注意经验的复用和下属的培养。</p>
<p>对于这个project来说，就是要给愿意学的人，留好空间，把想学的东西放在每个人随时都能够得到的地方。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>学习总结</tag>
      </tags>
  </entry>
  <entry>
    <title>redis</title>
    <url>//post/redis-study/</url>
    <content><![CDATA[<h2 id="Redis基础概念">Redis基础概念</h2>
<p>Redis是一个开源的、基于内存的数据结构存储系统，常被用作数据库、缓存和消息中间件。</p>
<p>它支持多种数据结构，包括字符串（String）、哈希（Hash）、列表（List）、集合（Set）和有序集合（Sorted Set）等。每种数据结构都有其独特的操作命令和适用场景。</p>
<p>redis是个k-v数据库，在redis内部维护了一个哈希表。当有查询来的时候，会先查全局的表获取键值，然后基于键值的类型进行后续处理。</p>
<p>String就理解为用了一个全局的哈希表。</p>
<p>Hash就是在全局的哈希表中再建了一个哈希表，比如专门建立一个user表用于存用户信息。这种表查询的时候会有两次哈希，第一次是查键，第二次是查具体的表。</p>
<p>Set、List也是类似，这里省略了。</p>
<h2 id="Redis常用命令">Redis常用命令</h2>
<ul>
<li><strong>字符串操作</strong>：<code>SET</code> 用于设置键值对，<code>GET</code> 用于获取指定键的值，<code>INCR</code> 用于将键的值加 1（键值需为整数）。</li>
<li><strong>哈希操作</strong>：<code>HSET</code> 在哈希表中设置字段值，<code>HGET</code> 获取哈希表中指定字段的值，<code>HGETALL</code> 获取哈希表中所有字段和值。</li>
<li><strong>列表操作</strong>：<code>LPUSH</code> 从列表头部插入元素，<code>RPUSH</code> 从列表尾部插入元素，<code>LPOP</code> 移除并返回列表的第一个元素，<code>RPOP</code> 移除并返回列表的最后一个元素，<code>LRANGE</code> 返回列表中指定区间内的元素。</li>
<li><strong>集合操作</strong>：<code>SADD</code> 添加元素到集合，<code>SMEMBERS</code> 返回集合中的所有元素，<code>SISMEMBER</code> 判断元素是否存在于集合中，<code>SREM</code> 移除集合中的元素，还支持集合的交集（<code>SINTER</code>）、并集（<code>SUNION</code>）、差集（<code>SDIFF</code>）等运算。</li>
<li><strong>有序集合操作</strong>：<code>ZADD</code> 添加成员到有序集合并指定分数，<code>ZRANGE</code> 返回有序集合中指定区间内的成员（按分数从小到大排序），<code>ZREM</code> 移除有序集合中的成员。</li>
<li><strong>键操作</strong>：<code>DEL</code> 删除一个或多个键，<code>KEYS</code> 查找所有符合给定模式的键，<code>EXISTS</code> 检查给定键是否存在。</li>
</ul>
<h2 id="Redis数据结构使用">Redis数据结构使用</h2>
<ul>
<li><strong>集合（Set）</strong>：适用于去重、判断元素是否存在以及集合运算等场景，例如存储用户标签、共同好友等。使用Python的<code>redis-py</code>库操作集合时，可通过<code>sadd</code>、<code>smembers</code>等方法实现添加元素、获取所有元素等操作。</li>
<li><strong>列表（List）</strong>：可用于实现队列（先进先出，FIFO）、栈（先进后出，LIFO）等数据结构，如消息队列、任务队列等。使用<code>redis-py</code>库时，<code>lpush</code>、<code>rpush</code>等方法可实现列表元素的插入操作。</li>
</ul>
<h2 id="Redis本地连接方式">Redis本地连接方式</h2>
<p>远程连接走的TCP，这里省略。</p>
<ul>
<li><strong>TCP/IP连接</strong>：即使Redis服务器和应用程序在同一台机器上，使用TCP/IP连接时，数据会经过本地的网络协议栈，通过回环地址进行传输。在Python中，使用<code>redis-py</code>库通过TCP/IP连接本地Redis服务器时，可指定<code>host</code>和<code>port</code>参数。</li>
<li><strong>本地套接字（Unix Domain Socket）连接</strong>：应用程序与Redis服务器通过本地文件系统中的套接字文件进行通信，不经过网络协议栈，效率较高。在Python中，使用<code>redis-py</code>库可通过指定<code>unix_socket_path</code>参数来使用本地套接字连接Redis。</li>
</ul>
<p>本地的套接字连接还是要走网络的那一套，建立连接、监听之类的，所以性能上比JNI要低。</p>
<h2 id="Redis性能优化技巧">Redis性能优化技巧</h2>
<ul>
<li><strong>配置优化</strong>：合理设置<code>maxmemory</code>参数和内存淘汰策略；根据业务需求选择合适的持久化方式（RDB或AOF），并调整相关参数。</li>
<li><strong>数据结构优化</strong>：根据业务场景选择合适的数据结构，优化数据结构设计以减少内存占用。</li>
<li><strong>客户端优化</strong>：使用连接池管理客户端连接，减少网络往返次数，控制请求数据量。</li>
<li><strong>服务器优化</strong>：将Redis服务器运行在单核CPU上，绑定特定CPU核心；使用高性能存储设备，优化操作系统I/O调度算法。</li>
<li><strong>监控与优化</strong>：使用<code>INFO</code>、<code>MONITOR</code>等命令监控性能指标，分析并优化查询语句。</li>
</ul>
<h2 id="持久化">持久化</h2>
<p>RDB，固定时间把所有数据写入本地文件。</p>
<p>AOF，每次写操作都把数据写入文件。</p>
<p>可以使用AOF的特殊参数，来实现每隔多少时间把写操作写入文件中。</p>
<p>这种方式类似MySQL的binlog。</p>
<h2 id="Redis集群方案">Redis集群方案</h2>
<ul>
<li><strong>主从复制</strong>：主节点处理写操作并将数据异步复制到从节点，从节点处理读操作。优点是实现读操作负载均衡，提高读性能；缺点是主节点单点故障，可能存在数据丢失风险。</li>
<li><strong>Sentinel（哨兵）</strong>：在主从复制基础上，引入Sentinel进程监控节点状态。当主节点故障时，自动从从节点中选举新主节点。多个Sentinel节点组成集群，通过Gossip协议通信，提高监控可靠性。但配置和管理相对复杂，故障转移可能存在短暂服务中断和数据不一致情况。</li>
<li><strong>Redis Cluster</strong>：采用数据分片，将键空间划分为16384个哈希槽，每个节点负责一部分哈希槽。节点间通过内部二进制协议通信，使用哨兵机制进行故障检测和转移。支持水平扩展，客户端可连接任意节点，通过<code>MOVED</code>错误重定向到正确节点。</li>
<li><strong>Codis</strong>：由Codis Server、Codis Proxy和ZooKeeper等组件组成。Codis Server存储数据，Codis Proxy代理客户端请求，ZooKeeper存储集群配置信息。支持动态扩展和收缩集群，对客户端透明，但依赖ZooKeeper，性能可能有损耗。</li>
</ul>
<p>主从是最基础的方案，配合AOF很好理解。能在多读少写的场景实现很有效的集群。</p>
<p>Sentinel机制是在主从的基础上添加了高可用的机制，能在主节点故障时自动选举出新的主节点。</p>
<p>Redis Cluster则是数据分片存储的方案，类似分库分表，实现上也很像。</p>
<h2 id="相关通信协议">相关通信协议</h2>
<ul>
<li><strong>Gossip协议</strong>：是一种分布式算法，用于在节点之间传递信息。具有去中心化、简单、扩展性好、容错性强、性能高效等特点。通过节点间随机的信息交换实现最终一致性，常见的通信方式有Push、Pull、Push&amp;Pull。适用于对一致性要求不是非常严格，但对系统扩展性、容错性和性能有较高要求的场景。</li>
<li><strong>与其他协议对比</strong>：与Raft、Paxos、Zookeeper等协议相比，在一致性保证、性能、扩展性、故障容错性、复杂性、应用场景等方面存在差异。例如，Raft和Paxos保证强一致性，Gossip协议提供最终一致性；Zookeeper是分布式协调服务，而Gossip协议主要用于信息传播和状态同步。</li>
</ul>
<h2 id="客户端从Redis-Cluster获取数据的过程">客户端从Redis Cluster获取数据的过程</h2>
<p>客户端先计算键的哈希槽编号，随机连接集群中的一个节点并发送获取数据的命令。若该节点负责该哈希槽，则直接返回数据；若不负责，则返回<code>MOVED</code>错误，包含目标节点信息。客户端根据错误信息重定向到正确节点再次请求数据。</p>
<p>客户端可维护哈希槽到节点的映射表以减少重定向开销。</p>
<h2 id="Redis的单线程">Redis的单线程</h2>
<p>Redis是个事件驱动的架构。维护了一个事件队列，线程不断从事件队列中取出事件进行处理。</p>
<p>比如发送了命令，那么会自动进入事件队列，上一个事件结束时才会处理下一个事件，这样保证了事务的一致性。</p>
<p>那么如何保证性能？</p>
<p>首先大部分操作都是纯内存的操作，耗时极短，用时在纳秒和微秒级别。</p>
<p>最耗费时间的操作往往都是IO操作，redis使用了IO多路复用的技术。没有IO多路复用的话，收到请求时，监听线程发起进行读操作，然后会阻塞，直到IO设备把数据读取到了内存中才能进行后续处理。IO多路复用的情况下，监听线程发起读操作，然后检查是否真的能读，不能则通过epoll的机制，等待内核回调。线程就直接去找下一个可以处理的任务了。</p>
<p>当然4.0以后，Redis也是引入了多线程机制，可以做到异步删除和异步持久化。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka文档阅读笔记</title>
    <url>/%E5%AD%A6%E4%B9%A0/study/kafka%E6%96%87%E6%A1%A3%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="简介">简介</h2>
<p>提到Kafka，第一印象是其中心化的设计，可靠的持久化和良好的生态。</p>
<p>最早Kafka设计是个日志系统。各个系统把日志发送到Kafka，然后被其他系统消费，进行后续处理。</p>
<p>最新的文档中，Kafka提到是event stream（事件流）平台。</p>
<blockquote>
<p>从技术角度讲，事件流是从数据库、传感器、移动设备、云服务和软件应用等事件源实时捕获数据，以事件流的形式存储这些事件流以供后续检索；实时以及事后处理和响应事件流；根据需要将事件流路由到不同的目标技术。因此，事件流确保了数据的持续流动和解释，以便在正确的时间、正确的地点提供正确的信息。</p>
</blockquote>
<p>Kafka的核心能力有三点：</p>
<ol>
<li>
<p>发布（写入）和订阅（读取）事件流，包括从其他系统持续导入/导出数据。</p>
</li>
<li>
<p>可靠地存储事件流，并持久化，满足对数据存储时间的需求。</p>
</li>
<li>
<p>处理实时或回顾性的事件流。</p>
</li>
</ol>
<p>这些在分布式系统中非常有用。</p>
<p>一个常见的场景是，一个系统只需要生成数据并把数据提交给Kafka即可，其他的系统则消费这些数据，进行其他的处理。</p>
<p>这是个典型的事件驱动架构，各个系统通过Kafka实现了良好的解耦。</p>
<h2 id="核心实现">核心实现</h2>
<p>Kafka有server和client之分，是由server与client组成的分布式系统。</p>
<p>server与client之间通讯使用TCP协议。</p>
<p>server就是Kafka节点，client则是业务节点。</p>
<p>server可以由多个节点组成集群，这个集群可以横跨多个机器、机房。</p>
<p>server中又分为broker和connect：</p>
<ul>
<li>broker：kafka的持久化节点，数据存到文件中。</li>
<li>connect：kafka的数据节点，类似client，会持续地生产数据或消费数据。算是Kafka生态的一部分。</li>
</ul>
<p>client可以往kafka提交或接收数据，或者说发布和订阅事件流。client有多种语言的SDK，允许集成到业务系统中。</p>
<h2 id="核心概念">核心概念</h2>
<h3 id="Event-事件">Event 事件</h3>
<p>或者说消息。事件有一个键、值、时间戳和可选的元数据头。</p>
<p>以下是一个示例事件：</p>
<ul>
<li>Event key: “Alice”</li>
<li>Event value: “Made a payment of $200 to Bob”</li>
<li>Event timestamp: “Jun. 25, 2020 at 2:06 p.m.”</li>
</ul>
<p>在消息队列中，所有的消息都被视为一个事件。</p>
<h3 id="Producer-和-Consumer">Producer 和 Consumer</h3>
<p>向Kafka发布事件的客户端被称为生产者。<strong>Producer</strong></p>
<p>从Kafka订阅事件，接收事件进行处理的客户端被称为消费者。<strong>Consumer</strong></p>
<p>在Kafka中，生产者和消费者完全解耦，互相之间没有任何依赖。</p>
<h3 id="Topic-主题">Topic 主题</h3>
<p>Event事件会被划分到一个Topic之下。类比文件系统，Topic类似文件夹，而Event则是文件夹中的文件。</p>
<p>对于一个主题，可以有任意个生产者写入事件，也可以有任意个消费者消费事件。</p>
<p>注意，这里的任意可以是0。因为Kafka会持久化消息到文件系统中，因此即便没有消费者来消费数据，生产者也可以无限地往Kafka推送数据，而不会产生数据背压。</p>
<p>这里还有一点要说明，消费者消费Kafka主题中的事件后，事件不会被删除。</p>
<p>Kafka提供了事件过期事件的配置，能控制事件的删除时机。</p>
<p>最后还有一点，Kafka的性能与数据大小无关。</p>
<h3 id="Partition-分区">Partition 分区</h3>
<p>分区的概念仅在分布式场景下会用到。分区的概念可以理解为是同一个主题下的多个消息队列。</p>
<p>一个主题可能消息过多，因此需要被划分到不同的分区中。同个主题的不同分区可以在不同的Kafka节点（Broker）中。</p>
<p>不同的Kafka节点可以存在于不同的地区、机房里。</p>
<p>生产者发布和消费者订阅时，是可以是直接针对主题发送的消息，也可以指定分区发送消息。</p>
<p>如果是针对主题发送的消息，Kafka会保证具有同样Event key的事件被划分到同一个分区中。以用户ID举例，Kafka会保证同个用户的事件始终在同个分区里，因此会一直被同样的消费者消费。这样保证了消息的局部有序性。</p>
<p>而通过指定分区进行消息发布和订阅，就能允许生产者和消费者并行处理同个主题下的数据。比如一个主题有2个分区，有两个消费者分别来处理分区1和分区2的数据，这样就能让消费的过程变成并行了。</p>
<p>此外，分区有Replica（副本），用来做容灾时很好用。</p>
<p>Kafka会自动把分区的数据分配到不同的Broker中，这样可以保证不同Broker都是均匀地处理数据。另外，这种设计让扩容变得简单了，当有新的Broker加入时，Kafka可以自动把部分分区迁移到新的Broker上。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>技术协议</tag>
      </tags>
  </entry>
  <entry>
    <title>我对MCP的理解</title>
    <url>/%E5%AD%A6%E4%B9%A0/study/%E6%88%91%E5%AF%B9MCP%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="背景">背景</h2>
<p>Model Context Portocal（MCP）真的是很火。自从这协议被提出以后，不少人觉得是一个未来的方向。</p>
<p>尤其是最近OpenAI也宣布要支持MCP，肉眼可见的在2025年这个协议会被人不断地提起。</p>
<p>2025是AI应用的大年，必然会有一批又一批的App或是软件转向拥抱AI的能力，而在这场转变中，MCP是不能绕开的一个话题。</p>
<h2 id="什么是MCP">什么是MCP</h2>
<p>在官方的介绍中，MCP被形容为大模型的type-c接口。</p>
<p>我觉得这概念过于抽象了，理解之后会觉得确实很有道理，但对于初学者来说这不能建立起一个直观的印象。</p>
<p>所以这里也想用自己的语言来组织一下我对其的理解。</p>
<p>目前最大的误解，就是MCP是一个标准化的Function Calling。</p>
<p>其实不然。</p>
<p>第一点，MCP是个应用层的协议，它和Function Calling完全不冲突。</p>
<p>第二点，函数调用是MCP中包含的能力的一部分，被称为tools。除了tools，还有其他很多功能。</p>
<img src="/%E5%AD%A6%E4%B9%A0/study/%E6%88%91%E5%AF%B9MCP%E7%9A%84%E7%90%86%E8%A7%A3/image-20250407162739388.png" class="" title="image-20250407162739388">
<p>MCP协议还提供了prompt补全、提示词模版等能力，只不过目前客户端支持不是很到位，因此大家用的不多。</p>
<p>所以，为了直观理解MCP，我觉得应该先从调用方来说起。</p>
<p>MCP是给MCP客户端使用的，这里的MCP客户端并不等于是LLM，这点很重要。</p>
<p>以Claude客户端为例，我们在自己的电脑上启动Claude客户端时，客户端仅仅是提供了一个聊天界面，实际上LLM还是在云端。</p>
<p>这场景下，我们自己电脑上的Claude客户端是MCP Client。</p>
<p>假设有个工具调用触发了，我们走一下实际的调用链路。</p>
<p>用户在客户端询问Claude，今天XXX的天气怎么样。请求会发送到Claude的服务器，Claude判断需要调用工具来获取天气的情况，此时它会发起Function Calling，这个Calling会原路返回到我们本地的客户端。</p>
<p>我们的客户端上会显示一条提示信息：Claude请求调用天气查询工具，是否同意？</p>
<p>我们点击同意，接着我们本地的Claude客户端就会发送一个MCP调用给MCP服务器，获取到最新的天气信息，然后把这个天气信息作为一个新的请求发送给Claude。</p>
<p>这时候，Claude才获取到最新的天气信息，此时它会组织语言重新把结果返回给客户端。</p>
<p>最后我们的客户端上才会显示我们最开始问题的回复：今天XXX的天气是晴天。</p>
<p>显然，MCP并没有取代Function Calling。</p>
<h2 id="MCP的价值在哪">MCP的价值在哪</h2>
<p>为什么我说MCP是AI应用开发绕不过的一个协议呢。</p>
<p>还是以我之前写过的一个玩具项目举例，我给Qwen写过一个Function Calling。</p>
<p>当时需要我做什么呢？</p>
<p>首先，我得编写一个功能，然后作为一个开放的接口在公网暴露出来。</p>
<p>然后我要把这个接口通过Qwen提供的工具注册方式，把这个接口注册到Qwen里。</p>
<p>最后还要进行功能的调试。</p>
<p>整个流程下来非常繁杂，因为我作为一个开发AI应用的人，我承担了太多的责任。</p>
<p>比如我得负责把工具包装成接口，还得专门写一个提示词来描述这个工具。</p>
<p>比如我得进行功能的调试，模型的调试极其麻烦。</p>
<p>同时，我写好的工具，大概率以后想复用时，还得写一套代码来实现把工具传递给AI。</p>
<p>这还不算其中认证之类的事情，实在是过于麻烦了。</p>
<p>但有了MCP之后呢？</p>
<p>对应的功能我可以包装为MCP的Server，然后用MCP Client的SDK快速实现功能调用和传输给AI。</p>
<p>以后我想复用功能，我只需要继续用MCP Client的SDK写一下调用就行了，不需要再去动MCP Server的代码。</p>
<p>简单来说，MCP的价值就在于提供了一个良好的职责划分。</p>
<p>MCP Server负责提供具体的工具，同时也是Server来负责提供工具描述之类的信息。</p>
<p>MCP Client负责转发AI的工具调用等，同时也可以使用MCP协议提供的Sampling等能力实现一些客户端的其他功能。</p>
<p>LLM模型的提供商负责提供Function Calling即可。</p>
<p>你看，负责开发具体功能的，也负责提供了给模型的接入文档；负责开发客户端的，只需要关心怎么写胶水代码来拼凑功能。</p>
<p>这样就解决了AI应用最大的痛点，开发成本高昂。</p>
<p>有相当多的软件，也可以发布自己的MCP Server来实现无缝变身AI应用了。</p>
<p>试想一下，假设美团提供了MCP服务，那么是不是真的就可以做到，我们在手机的语音助手里说一句：我要点杯咖啡，然后语音助手自动帮我们利用MCP去查询美团上的信息，然后下单支付呢？</p>
<p>这时候回头看看官方说的那句，MCP就是type-c接口，是不是有点味道了呢？</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>技术协议</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊AI工具和学习</title>
    <url>/%E5%AD%A6%E4%B9%A0/study/%E8%81%8A%E8%81%8AAI%E5%B7%A5%E5%85%B7%E5%92%8C%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="背景">背景</h2>
<p>上次nlp的project被同学宣传了一下，后来有人来交流，就被拉去给老师做项目了。</p>
<p>名义上是当了student assistant，工资也是按照这个待遇来。80港币一小时，说实话还不少。</p>
<p>项目是关于一个AI论文的平台，希望能借用AI工具来对论文进行编写、修改和润色。功能倒是挺简单的，我觉得主要难点还是在设计和实现上。</p>
<h2 id="难点">难点</h2>
<p>我觉得第一个难点是人力的缺失，更准确地说是协作的方式。虽说我后来又找了3个人来，组成了6人小队，但还是觉得人手不够，做事不够快。</p>
<p>从数量上来说，这点人肯定是够了，但我觉得暂时没找到很好的协作方式。换句话说，也就是没能把这6个人的能力全部发挥出来。</p>
<p>这也是很痛苦，没什么办法的事情，毕竟项目管理本就是一个很困难的事情。</p>
<p>第二个难点应该是设计的问题。目前没有产品经理的角色，实际上很多功能的设计上是缺失了有人把关。甚至更严重的是，我们所有人都是身兼多职，既要看产品怎么样，又要看怎么实现。</p>
<p>这种体验倒是和初创团队差不多了。</p>
<p>没有专业的设计团队，难免会导致功能上可能少东少西，甚至交互上也会很反人类。</p>
<p>第三个难点在于测试和验收。目前也没有测试人员，功能的验收是没有人把关的。做得怎么样，怎样算好，有没有bug，这些大家在做完之后都没有反馈的渠道。</p>
<p>没有结果的反馈，也就很难进一步提高了。</p>
<p>第四个难点在于缺少标准的制定。管理团队最重要的就是制定标准，标准是协作的基础。人并不可靠，但完善的标准可以让人变可靠。这话对AI也同理。目前我们后台日志打印的方式、异常的抛出、前端的请求方式都没有统一的标准制定出来。这些得尽快解决了。</p>
<h2 id="预期">预期</h2>
<p>聊完难点，不妨畅想一下预期。</p>
<p>我理想中的团队，应该是抱有热情、持续产出、愿意钻研的。他们每天都能提交一定的代码，推进一定的工作。定时上线开会，有问题及时沟通。大胆指出目前工作中不合逻辑的地方，并且提出改进意见。</p>
<p>显然目前还达不到。</p>
<h2 id="使用AI工具开发">使用AI工具开发</h2>
<p>前面感觉都扯远了，这里回到正题，再聊聊AI工具和学习。</p>
<p>这里的AI工具，应该说特指cursor这类编程工具了。</p>
<p>比较好笑的是，我居然是这次项目中负责写前端的人。可实际上我并不懂前端，ts基础语法都没认真学过。</p>
<p>但目前看下来，我甚至都不算是拖后腿的那个人。</p>
<p>感谢cursor，让我有了这种体验。</p>
<p>前端我也不是没学，也花了点时间看了下尚硅谷的Vue3前端入门教程。只不过暂时还没看完罢了。</p>
<p>我觉得过段时间可以把尚硅谷的项目完整做一下，还是挺有意义的。</p>
<p>整体编写项目前端的过程，让我觉得最重要的还是知道目标，然后提出自己的需求。</p>
<p>AI工具已经非常智能，只要在输入指令的时候带上那么一点点技术的关键词，基本上就可以帮你实现各种需求了。</p>
<h2 id="使用AI工具学习">使用AI工具学习</h2>
<p>但凡事皆有代价。使用AI工具来开发，其实很大程度上属于是用长期的提高和理解，换取暂时的成果。</p>
<p>使用cursor我写了相当多的代码，但代价就是我还是觉得自己对Vue3一窍不懂，不能写代码。</p>
<p>感觉是离了cursor不会写代码了。</p>
<p>这种体验很差，短期看到有美观的页面生成确实让人多巴胺快速分泌，有满足感。</p>
<p>这种感觉一旦过去，充斥心头的是一种迷茫和空虚。</p>
<p>频繁使用AI只会让自己变得没有长进。你增长的只有使用AI的能力，而不是做事情的能力。</p>
<p>这也让我觉得有些恐慌。</p>
<p>也是第一次有了AI是不是会取代我的工作的焦虑感。</p>
<p>最讽刺好笑的事情也是在这。如果现在想要快速学习新的知识，借助AI工具也是最快的。</p>
<p><strong>如果你愿意在每次生成代码之后，让AI工具解释一下它为什么这么写，它会是最好的导师。</strong></p>
<p>我觉得现在学一个新技术，最难的还是不知道roadmap。</p>
<p>而AI打破了这个知识搜集的过程，大部分时候它是可以提供一些可靠的roadmap，让你知道自己应该先学什么，后学什么。</p>
<p>我个人比较喜欢的路径是，先quick start看到成果，然后逐步深入其中的每一个步骤，理解其原理。</p>
<p>凭借多年的技术直觉，我觉得很多时候自己还是可以问出一些很有用的问题，从而获得最合理的AI答复。</p>
<p>动手学习确实比单纯听讲要好得多。</p>
<h2 id="总结">总结</h2>
<p>最近是接了一个项目，遇到了不少困难。</p>
<p>然后我也开始写前端了，在编写的过层中我大量使用了AI。</p>
<p>这让我思考为什么要用AI，AI的能力边界在哪。</p>
<p>我决定以后要慎重使用AI，在使用完之后多问一句为什么，从而实现在实践的过程中提高自己的技术水平。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>学习总结</tag>
      </tags>
  </entry>
  <entry>
    <title>SSE协议和流式输出</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/front/SSE%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA/</url>
    <content><![CDATA[<h2 id="流式输出">流式输出</h2>
<p>大多数的聊天机器人都会用到流式输出。为什么一定要用这能力呢？</p>
<p>任何的LLM的回答都是逐字逐句生成的，因此使用同步调用一次获取所有的消息，会造成长时间的阻塞。</p>
<p>尤其是DeepSeek R1这类推理模型，在给出正式的回答前还有大段大段的思考文本，这让用户的等待时间更加长了。</p>
<p>同时，一个请求的超时时间过长会带来其他副作用，比如用同步调用很难判断是LLM服务挂掉了还是单纯生成内容很长所以一直没回答。</p>
<p>因此，为了提升用户体验，减少后端一些不必要的麻烦，流式输出在目前的AI应用中越来越重要了。</p>
<h2 id="SSE-Server-Sent-Events-协议">SSE (Server-Sent Events) 协议</h2>
<h3 id="SSE协议概念">SSE协议概念</h3>
<ul>
<li>SSE（Server-Sent Events）是一种服务器推送技术，允许服务器向客户端发送事件流</li>
<li>它建立在HTTP协议上，使用标准的HTTP连接，但允许服务器持续向客户端推送数据</li>
<li>SSE连接是单向的（只能服务器向客户端发送数据），与WebSocket不同（WebSocket是双向通信）</li>
<li>SSE适用于实时通知、实时日志、聊天应用等场景</li>
</ul>
<h3 id="SSE协议技术特点">SSE协议技术特点</h3>
<ul>
<li>使用标准HTTP连接，不需要特殊协议或端口</li>
<li>自动重连功能，断开连接后会自动尝试重新连接</li>
<li>使用纯文本传输，每条消息格式为<code>data: 消息内容\n\n</code></li>
<li>支持事件ID和事件类型，便于客户端处理不同类型的消息</li>
<li>比WebSocket更简单，更容易实现，但功能稍弱</li>
</ul>
<h3 id="技术选型">技术选型</h3>
<p>后端使用的是<code>FastAPI</code>，本身就有很好的流式输出支持。</p>
<p>前端则是使用了<code>@microsoft/fetch-event-source</code>库，因为这个库允许修改请求头的内容，方便做鉴权。</p>
<h3 id="项目中SSE的应用">项目中SSE的应用</h3>
<ol>
<li><strong>后端实现（FastAPI）</strong>
<ul>
<li>使用<code>FastAPI</code>的<code>StreamingResponse</code>实现流式响应</li>
<li>通过异步生成器<code>serialize_generator</code>生成SSE数据流</li>
<li>标准SSE格式: <code>data: JSON数据\n\n</code></li>
<li>使用<code>time.sleep(0.05)</code>控制响应速率，避免客户端接收过快导致丢包</li>
</ul>
</li>
<li><strong>前端实现（Vue 3 + TypeScript）</strong>
<ul>
<li>使用<code>@microsoft/fetch-event-source</code>库处理SSE连接</li>
<li>在<code>frontend/src/utils/request.ts</code>中封装了<code>sseRequest</code>函数</li>
<li>支持请求头设置、身份验证、错误处理和连接状态管理</li>
<li>通过<code>parseSSEMessage</code>函数解析接收到的SSE消息</li>
</ul>
</li>
</ol>
<h2 id="打字机">打字机</h2>
<h3 id="为什么要做打字机效果">为什么要做打字机效果</h3>
<p>由于网络波动，后端的推送并不是匀速到达客户端的。如果前端仅仅是收到一条消息就拼接到前端的文本上，那么最终效果就会显得很呆。</p>
<p>通过在前端添加一个缓冲队列，来让字符匀速显示，会让前端的展示效果显著提升。</p>
<p>就是俗话说的&quot;质感&quot;。</p>
<h3 id="核心功能">核心功能</h3>
<ul>
<li>实现了文字逐字打印的动画效果</li>
<li>支持动态调整打字速度</li>
</ul>
<h3 id="技术实现">技术实现</h3>
<ul>
<li>使用TypeScript实现类封装</li>
<li>采用缓冲区设计模式存储待显示的文本</li>
<li>使用定时器控制打字速度</li>
<li>提供丰富的回调函数支持，如<code>onComplete</code>、<code>onPause</code>等</li>
</ul>
<h2 id="总结">总结</h2>
<p>整体逻辑其实很简单，SSE+前端打字机。</p>
<p>前端本身就是响应式的，所以代码实现其实不麻烦，直接往文本框里拼接字符就行，甚至有点简单。</p>
<p>但不管怎么说，SSE协议在AI应用中目前使用应该是最为广泛的，几乎所有项目都得走这个流程。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>技术协议</tag>
      </tags>
  </entry>
  <entry>
    <title>canvas-editor使用记录</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/front/canvas-editor%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="简介">简介</h2>
<p>主页：<a href="https://hufe.club/canvas-editor-docs/">https://hufe.club/canvas-editor-docs/</a></p>
<p>canvas-editor是个基于canvas/svg的富文本编辑器。</p>
<p>使用下来，比较优秀的点有：</p>
<p>1、页面类似word，并且开箱即用。</p>
<p>2、提供了非常多扩展的接口。</p>
<p>3、数据保存非常方便。</p>
<p>当前，也有些缺点：</p>
<p>1、文档不够详细，很多接口仅仅是说明了有这个接口，具体的用法都没讲。</p>
<p>2、事件回调的机制说明不够清晰。也算是个文档的问题。</p>
<p>3、没有Vue或Reactor的开箱即用包。</p>
<h2 id="空的回调事件">空的回调事件</h2>
<p>在实现工具栏时，发现了一个很抽象的事情。</p>
<p>官方的工具栏中，假设我选中一些文字然后加粗，工具栏会正常把加粗的按钮置为已经点击的状态。</p>
<p>而在我实现的工具栏中，每次点击工具栏的按钮后，会出现一个空的回调事件，把工具栏的状态置回没有点击的状态。</p>
<p>最后询问了官方，也翻了下对方的代码。</p>
<p>发现是因为官方的工具栏用的事件不是click，而是鼠标按下的事件。</p>
<p>我用click，所以点击的时候出现了失焦，因此有个空的回调事件出来。</p>
<h2 id="Word插件样式">Word插件样式</h2>
<p>官方的实现中，word的导入导入功能有非常严重的样式丢失。</p>
<p>最后是我自己写了一个导入的功能，把word解析为xml然后转化为canvas-editor的json格式。</p>
<p>目前导出还没实现，但大概率也得手动写一个导出了。</p>
<h2 id="任何操作都会被记录">任何操作都会被记录</h2>
<p>发现对文档的操作都会被记录。</p>
<p>这导致了我们用AI添加一些文字内容到文档时，明明正常执行完了，但点击回退又会回到填了一半的情况。</p>
<p>比如我们润色时会高亮原文，那么润色完了点击回退，就会回到原文被高亮的状态。</p>
<p>最后发现可以在操作时加一个参数来让本次操作不被记录。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title>JRE环境使用Arthas</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/tips/JRE%E7%8E%AF%E5%A2%83%E4%BD%BF%E7%94%A8Arthas/</url>
    <content><![CDATA[<h2 id="场景">场景</h2>
<p>实际工作中常遇到一种情况，线上环境出现异常，但是环境安装的是JRE。</p>
<p>JRE环境下没有了JDK提供的各类工具，根本无法排查问题。如果重装JDK，那么同时也得重启项目，而项目一旦重启，问题的环境就已经丢失，下一次再遇到同样的问题就可遇不可求了。</p>
<h2 id="解决方案">解决方案</h2>
<p>使用轻量级的程序附加工具jattach可以做到将Arthas的Jar包attach到特定的进程上。</p>
<p>网上有类似的解析。最关键的一点是Arthas只需要将一个jar附加到JVM中就可以运行了。</p>
<p>这里提供一个脚本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># 获取当前脚本所在的目录</span><br><span class="line">script_dir=$(cd &quot;$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)&quot; &amp;&amp; pwd)</span><br><span class="line"></span><br><span class="line"># 用户输入进程ID</span><br><span class="line">read -p &quot;请输入进程ID: &quot; pid</span><br><span class="line"></span><br><span class="line"># 用户输入可选参数host，提供默认值</span><br><span class="line">read -p &quot;请输入主机地址和端口号（格式：IP 端口，默认为 127.0.0.1 3658）: &quot; host</span><br><span class="line">host=$&#123;host:-&quot;127.0.0.1 3658&quot;&#125;</span><br><span class="line"></span><br><span class="line"># 检查当前目录下是否存在jattach文件</span><br><span class="line">if [[ ! -e &quot;$script_dir/jattach&quot; ]]; then</span><br><span class="line">  # 查找以jattach-linux开头的tgz压缩包</span><br><span class="line">  jattach_tgz=$(find &quot;$script_dir&quot; -maxdepth 1 -type f -name &quot;jattach-linux-*.tgz&quot;)</span><br><span class="line"></span><br><span class="line">  if [[ -z &quot;$jattach_tgz&quot; ]]; then</span><br><span class="line">    echo &quot;当前目录下未找到名为jattach的文件或符合条件的jattach-linux-*.tgz压缩包。&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  # 判断系统架构</span><br><span class="line">  system_arch=$(uname -m)</span><br><span class="line">  case $system_arch in</span><br><span class="line">    &quot;aarch64&quot;|&quot;arm64&quot;)</span><br><span class="line">      arch=&quot;arm64&quot;</span><br><span class="line">      jattach_file=&quot;jattach-linux-arm64.tgz&quot;</span><br><span class="line">      ;;</span><br><span class="line">    &quot;x86_64&quot;|&quot;amd64&quot;)</span><br><span class="line">      arch=&quot;x64&quot;</span><br><span class="line">      jattach_file=&quot;jattach-linux-x64.tgz&quot;</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      echo &quot;当前系统架构不支持自动解压jattach工具。&quot;</span><br><span class="line">      exit 1</span><br><span class="line">  esac</span><br><span class="line"></span><br><span class="line">  # 检查对应的jattach压缩包是否存在</span><br><span class="line">  if [[ ! -f &quot;$script_dir/$jattach_file&quot; ]]; then</span><br><span class="line">    echo &quot;当前目录下未找到与系统架构匹配的$jattach_file压缩包。&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  # 解压缩对应架构的jattach工具到当前脚本目录，并使用绝对路径</span><br><span class="line">  tar -xzvf &quot;$script_dir/$jattach_file&quot; -C &quot;$script_dir&quot;</span><br><span class="line"></span><br><span class="line">  # 检查解压后jattach是否成功生成</span><br><span class="line">  if [[ ! -e &quot;$script_dir/jattach&quot; ]]; then</span><br><span class="line">    echo &quot;解压失败或未能在当前目录找到解压后的jattach文件。&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># 使用jattach命令加载arthas-agent.jar，使用绝对路径</span><br><span class="line">&quot;$script_dir/jattach&quot; $pid load instrument false &quot;$script_dir/arthas-agent.jar&quot; &amp;&amp; \</span><br><span class="line"></span><br><span class="line"># 运行arthas客户端，同样使用绝对路径</span><br><span class="line">java -jar &quot;$script_dir/arthas-client.jar&quot; $host</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最关键的就是脚本中最后的两句</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用jattach命令加载arthas-agent.jar，使用绝对路径</span><br><span class="line">&quot;$script_dir/jattach&quot; $pid load instrument false &quot;$script_dir/arthas-agent.jar&quot; &amp;&amp; \</span><br><span class="line"></span><br><span class="line"># 运行arthas客户端，同样使用绝对路径</span><br><span class="line">java -jar &quot;$script_dir/arthas-client.jar&quot; $host</span><br></pre></td></tr></table></figure>
<p>这其实是一个命令，分成了两行。第一个命令是将<code>arthas-agent.jar</code>加载到某个pid的程序中，第二个命令是运行arthas的界面。</p>
<p>脚本提供了自动安装jattach的能力，只需要将jattach的安装包与此脚本方式在arthas的目录内，然后运行此脚本即可。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>优秀实践</tag>
      </tags>
  </entry>
  <entry>
    <title>linux学习记录</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E8%BF%90%E7%BB%B4/linux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>如果说一个开发人员对linux不够熟悉，可能就永远止步于中级开发了。</p>
<p>原来写Java比较多，Spring在部署上已经给了一套良好的解决方案，能协助构建Fat Jar，用简单的<code>java -jar</code>命令就能启动程序。</p>
<p>也就导致我一直对linux的了解没那么深入。</p>
<p>目前的工作中，采用K8S这一套体系，所有的项目都打包成docker镜像再进行后续的部署。</p>
<p>这种情况下，如何编写docker file构建镜像，如何进行服务编排就是新的要求了。</p>
<p>docker file中的语法类似shell命令，能使用linux的一些基础命令比如cp、mv、rm、mkdir等。</p>
<p>毕竟docker是基于linux的镜像构建的嘛，支持这些命令也正常。</p>
<p>所以突然有个机会能把linux的命令重新学一下，我觉得还挺好的。</p>
<h2 id="基础命令">基础命令</h2>
<h3 id="1-文件操作命令">1. 文件操作命令</h3>
<h4 id="目录导航">目录导航</h4>
<ul>
<li><code>pwd</code> - 显示当前工作目录</li>
<li><code>ls</code> - 列出目录内容
<ul>
<li><code>ls -l</code> 详细列表</li>
<li><code>ls -a</code> 显示隐藏文件</li>
<li><code>ls -h</code> 人类可读大小</li>
</ul>
</li>
<li><code>cd</code> - 切换目录
<ul>
<li><code>cd ~</code> 回家目录</li>
<li><code>cd -</code> 返回上一个目录</li>
<li><code>cd ..</code> 上级目录</li>
</ul>
</li>
</ul>
<h4 id="文件操作">文件操作</h4>
<ul>
<li><code>mkdir</code> - 创建目录
<ul>
<li><code>mkdir -p</code> 创建多级目录</li>
</ul>
</li>
<li><code>touch</code> - 创建空文件或更新时间戳</li>
<li><code>cp</code> - 复制文件/目录
<ul>
<li><code>cp -r</code> 递归复制目录</li>
<li><code>cp -v</code> 显示复制过程</li>
</ul>
</li>
<li><code>mv</code> - 移动或重命名文件</li>
<li><code>rm</code> - 删除文件
<ul>
<li><code>rm -r</code> 递归删除目录</li>
<li><code>rm -f</code> 强制删除</li>
<li><code>rm -i</code> 交互式删除</li>
</ul>
</li>
</ul>
<h4 id="文件查看">文件查看</h4>
<ul>
<li><code>cat</code> - 连接并显示文件内容</li>
<li><code>more</code> - 分页显示文件内容</li>
<li><code>less</code> - 更好的分页显示（可上下滚动）</li>
<li><code>head</code> - 显示文件开头
<ul>
<li><code>head -n 10</code> 显示前10行</li>
</ul>
</li>
<li><code>tail</code> - 显示文件末尾
<ul>
<li><code>tail -n 20</code> 显示后20行</li>
<li><code>tail -f</code> 实时跟踪文件变化</li>
</ul>
</li>
</ul>
<h3 id="2-权限管理">2. 权限管理</h3>
<h4 id="权限基础">权限基础</h4>
<p>Linux文件权限分为三类：</p>
<ul>
<li>用户(User) - 文件所有者</li>
<li>组(Group) - 文件所属组</li>
<li>其他(Other) - 其他用户</li>
</ul>
<p>每种权限有三种类型：</p>
<ul>
<li>读® - 4</li>
<li>写(w) - 2</li>
<li>执行(x) - 1</li>
</ul>
<h4 id="权限命令">权限命令</h4>
<ul>
<li><code>chmod</code> - 修改文件权限
<ul>
<li>数字方式: <code>chmod 755 filename</code></li>
<li>符号方式: <code>chmod u+x filename</code></li>
</ul>
</li>
<li><code>chown</code> - 修改文件所有者
<ul>
<li><code>chown user:group filename</code></li>
</ul>
</li>
<li><code>chgrp</code> - 修改文件所属组</li>
</ul>
<h4 id="特殊权限">特殊权限</h4>
<ul>
<li>SUID (Set User ID) - 以文件所有者身份执行</li>
<li>SGID (Set Group ID) - 以文件所属组身份执行</li>
<li>Sticky Bit - 目录中只有文件所有者能删除文件</li>
</ul>
<h3 id="3-文本处理">3. 文本处理</h3>
<h4 id="文本搜索">文本搜索</h4>
<ul>
<li><code>grep</code> - 文本搜索
<ul>
<li><code>grep -i</code> 忽略大小写</li>
<li><code>grep -n</code> 显示行号</li>
<li><code>grep -v</code> 反向匹配</li>
<li><code>grep -r</code> 递归搜索</li>
</ul>
</li>
</ul>
<h4 id="文本处理工具">文本处理工具</h4>
<ul>
<li><code>awk</code> - 文本处理语言
<ul>
<li><code>awk '&#123;print $1&#125;'</code> 打印第一列</li>
</ul>
</li>
<li><code>sed</code> - 流编辑器
<ul>
<li><code>sed 's/old/new/g'</code> 全局替换</li>
</ul>
</li>
<li><code>cut</code> - 截取文本
<ul>
<li><code>cut -d: -f1</code> 以冒号分隔取第一字段</li>
</ul>
</li>
<li><code>sort</code> - 排序</li>
<li><code>uniq</code> - 去重</li>
</ul>
<h3 id="4-帮助文档">4. 帮助文档</h3>
<ul>
<li><code>man</code> - 查看命令手册
<ul>
<li><code>man ls</code> 查看ls命令帮助</li>
</ul>
</li>
<li><code>--help</code> - 查看命令简要帮助
<ul>
<li><code>ls --help</code></li>
</ul>
</li>
<li><code>info</code> - 查看info格式文档</li>
</ul>
<h3 id="5-管道">5. 管道</h3>
<p>管道操作符<code>|</code>，通过管道我们能将多个命令组合起来，起到更好的效果。</p>
<p>注意，管道是同时起了多个进程，前一个进程的实时输出会自动输入到下一个进程里，而不是前一个执行完了才执行下一个。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ps -aux | grep java</span><br></pre></td></tr></table></figure>
<h2 id="系统管理">系统管理</h2>
<h3 id="1-用户和组管理">1. 用户和组管理</h3>
<h4 id="用户管理命令">用户管理命令</h4>
<ul>
<li><code>useradd</code> - 添加用户
<ul>
<li><code>useradd -m</code> 创建家目录</li>
<li><code>useradd -s</code> 指定shell</li>
<li><code>useradd -g</code> 指定主组</li>
</ul>
</li>
<li><code>usermod</code> - 修改用户属性
<ul>
<li><code>usermod -aG</code> 添加附加组</li>
<li><code>usermod -L</code> 锁定用户</li>
<li><code>usermod -U</code> 解锁用户</li>
</ul>
</li>
<li><code>userdel</code> - 删除用户
<ul>
<li><code>userdel -r</code> 删除用户及家目录</li>
</ul>
</li>
</ul>
<h4 id="密码管理">密码管理</h4>
<ul>
<li><code>passwd</code> - 设置密码
<ul>
<li><code>passwd -l</code> 锁定密码</li>
<li><code>passwd -u</code> 解锁密码</li>
<li><code>passwd -d</code> 删除密码</li>
</ul>
</li>
<li><code>chage</code> - 修改密码过期信息
<ul>
<li><code>chage -l</code> 查看密码信息</li>
<li><code>chage -M</code> 设置最大天数</li>
</ul>
</li>
</ul>
<h4 id="组管理">组管理</h4>
<ul>
<li><code>groupadd</code> - 添加组</li>
<li><code>groupmod</code> - 修改组</li>
<li><code>groupdel</code> - 删除组</li>
<li><code>gpasswd</code> - 组密码管理</li>
</ul>
<h4 id="权限提升">权限提升</h4>
<ul>
<li><code>su</code> - 切换用户
<ul>
<li><code>su -</code> 完全切换环境</li>
<li><code>su -c</code> 以其他用户执行命令</li>
</ul>
</li>
<li><code>sudo</code> - 以超级用户权限执行
<ul>
<li><code>/etc/sudoers</code> 配置文件</li>
<li><code>visudo</code> 安全编辑sudoers</li>
</ul>
</li>
</ul>
<h3 id="2-进程管理">2. 进程管理</h3>
<h4 id="进程查看">进程查看</h4>
<ul>
<li><code>ps</code> - 进程状态
<ul>
<li><code>ps aux</code> 查看所有进程</li>
<li><code>ps -ef</code> 完整格式列表</li>
<li><code>ps -o</code> 自定义输出格式</li>
</ul>
</li>
<li><code>top</code> - 实时进程监控
<ul>
<li>交互命令: k(杀死), r(renice), h(帮助)</li>
</ul>
</li>
<li><code>htop</code> - 增强版top（需要安装）</li>
<li><code>pstree</code> - 树状显示进程</li>
</ul>
<h4 id="进程控制">进程控制</h4>
<ul>
<li><code>kill</code> - 发送信号给进程
<ul>
<li><code>kill -9</code> 强制终止</li>
<li><code>kill -15</code> 正常终止</li>
<li><code>kill -l</code> 列出所有信号</li>
</ul>
</li>
<li><code>pkill</code> - 按名称杀死进程</li>
<li><code>killall</code> - 杀死所有同名进程</li>
<li><code>nice</code> - 设置进程优先级</li>
<li><code>renice</code> - 修改运行中进程优先级</li>
</ul>
<h4 id="后台作业">后台作业</h4>
<ul>
<li><code>&amp;</code> - 后台运行</li>
<li><code>jobs</code> - 查看后台作业</li>
<li><code>fg</code> - 前台运行</li>
<li><code>bg</code> - 后台继续运行</li>
<li><code>nohup</code> - 忽略挂起信号运行</li>
</ul>
<h3 id="3-系统监控">3. 系统监控</h3>
<h4 id="系统状态">系统状态</h4>
<ul>
<li><code>uptime</code> - 系统运行时间</li>
<li><code>w</code> - 显示登录用户及进程</li>
<li><code>who</code> - 显示登录用户</li>
<li><code>last</code> - 显示登录历史</li>
</ul>
<h4 id="内存监控">内存监控</h4>
<ul>
<li><code>free</code> - 内存使用情况
<ul>
<li><code>free -h</code> 人类可读格式</li>
<li><code>free -m</code> 以MB显示</li>
</ul>
</li>
<li><code>vmstat</code> - 虚拟内存统计
<ul>
<li><code>vmstat 1</code> 每秒刷新</li>
</ul>
</li>
</ul>
<h4 id="磁盘监控">磁盘监控</h4>
<ul>
<li><code>df</code> - 磁盘空间使用
<ul>
<li><code>df -h</code> 人类可读格式</li>
<li><code>df -i</code> inode使用情况</li>
</ul>
</li>
<li><code>du</code> - 目录空间使用
<ul>
<li><code>du -sh</code> 汇总显示</li>
<li><code>du -h --max-depth=1</code> 一级目录</li>
</ul>
</li>
</ul>
<h4 id="性能监控">性能监控</h4>
<ul>
<li><code>iostat</code> - CPU和磁盘I/O统计</li>
<li><code>mpstat</code> - CPU使用统计</li>
<li><code>sar</code> - 系统活动报告
<ul>
<li>需要安装sysstat包</li>
</ul>
</li>
<li><code>dstat</code> - 多功能系统监控</li>
</ul>
<h3 id="4-日志管理">4. 日志管理</h3>
<h4 id="系统日志">系统日志</h4>
<ul>
<li><code>/var/log/messages</code> - 主要系统日志</li>
<li><code>/var/log/secure</code> - 安全相关日志</li>
<li><code>/var/log/cron</code> - 计划任务日志</li>
<li><code>/var/log/boot.log</code> - 启动日志</li>
</ul>
<h4 id="日志查看工具">日志查看工具</h4>
<ul>
<li><code>tail</code> - 查看日志尾部</li>
<li><code>less</code> - 分页查看日志</li>
<li><code>grep</code> - 搜索日志内容</li>
<li><code>journalctl</code> - systemd日志查看
<ul>
<li><code>journalctl -f</code> 实时跟踪</li>
<li><code>journalctl -u</code> 按服务查看</li>
<li><code>journalctl --since</code> 时间范围</li>
</ul>
</li>
</ul>
<h3 id="5-系统信息">5. 系统信息</h3>
<h4 id="硬件信息">硬件信息</h4>
<ul>
<li><code>uname</code> - 系统信息
<ul>
<li><code>uname -a</code> 所有信息</li>
</ul>
</li>
<li><code>lscpu</code> - CPU信息</li>
<li><code>lsblk</code> - 块设备信息</li>
<li><code>lspci</code> - PCI设备信息</li>
<li><code>lsusb</code> - USB设备信息</li>
</ul>
<h4 id="系统版本">系统版本</h4>
<ul>
<li><code>cat /etc/redhat-release</code> - CentOS版本</li>
<li><code>cat /etc/os-release</code> - 系统发行版信息</li>
</ul>
<h2 id="网络配置">网络配置</h2>
<h3 id="1-网络接口管理">1. 网络接口管理</h3>
<h4 id="传统网络命令">传统网络命令</h4>
<ul>
<li><code>ifconfig</code> - 接口配置（已逐渐被淘汰）
<ul>
<li><code>ifconfig eth0 up</code> 启用接口</li>
<li><code>ifconfig eth0 down</code> 禁用接口</li>
</ul>
</li>
<li><code>route</code> - 路由管理
<ul>
<li><code>route -n</code> 数字格式显示路由表</li>
<li><code>route add</code> 添加路由</li>
<li><code>route del</code> 删除路由</li>
</ul>
</li>
</ul>
<h4 id="现代网络命令（iproute2）">现代网络命令（iproute2）</h4>
<ul>
<li><code>ip</code> - 多功能网络工具
<ul>
<li><code>ip addr</code> 查看IP地址</li>
<li><code>ip link</code> 查看网络接口</li>
<li><code>ip route</code> 查看路由表</li>
<li><code>ip neigh</code> 查看ARP表</li>
</ul>
</li>
<li><code>ss</code> - socket统计（替代netstat）
<ul>
<li><code>ss -tuln</code> 查看监听端口</li>
<li><code>ss -t</code> 查看TCP连接</li>
<li><code>ss -u</code> 查看UDP连接</li>
</ul>
</li>
</ul>
<h3 id="2-网络配置文件">2. 网络配置文件</h3>
<h4 id="网络配置文件位置">网络配置文件位置</h4>
<ul>
<li><code>/etc/sysconfig/network-scripts/</code> - 网络脚本目录</li>
<li><code>ifcfg-eth0</code> - 以太网接口配置文件</li>
<li><code>route-eth0</code> - 接口路由配置文件</li>
</ul>
<h4 id="配置文件示例">配置文件示例</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/sysconfig/network-scripts/ifcfg-eth0</span></span><br><span class="line">DEVICE=eth0</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.1.100</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.1.1</span><br><span class="line">DNS1=8.8.8.8</span><br><span class="line">DNS2=8.8.4.4</span><br><span class="line">ONBOOT=<span class="built_in">yes</span></span><br></pre></td></tr></table></figure>
<h3 id="3-防火墙配置（firewalld）">3. 防火墙配置（firewalld）</h3>
<h4 id="firewalld基础概念">firewalld基础概念</h4>
<ul>
<li>区域(zone): 预定义的规则集合</li>
<li>服务(service): 预定义的服务规则</li>
<li>端口(port): 自定义端口规则</li>
</ul>
<h4 id="firewall-cmd命令">firewall-cmd命令</h4>
<ul>
<li><code>firewall-cmd --state</code> 查看防火墙状态</li>
<li><code>firewall-cmd --get-active-zones</code> 查看活动区域</li>
<li><code>firewall-cmd --list-all</code> 查看所有规则</li>
<li><code>firewall-cmd --reload</code> 重载配置</li>
</ul>
<h4 id="常用操作">常用操作</h4>
<ul>
<li>添加服务: <code>firewall-cmd --add-service=http</code></li>
<li>添加端口: <code>firewall-cmd --add-port=8080/tcp</code></li>
<li>永久生效: <code>--permanent</code> 参数</li>
<li>移除规则: <code>--remove-service</code> 或 <code>--remove-port</code></li>
</ul>
<h3 id="4-网络诊断工具">4. 网络诊断工具</h3>
<h4 id="连通性测试">连通性测试</h4>
<ul>
<li><code>ping</code> - ICMP连通性测试
<ul>
<li><code>ping -c 4</code> 发送4个包</li>
<li><code>ping -i 2</code> 间隔2秒</li>
</ul>
</li>
<li><code>traceroute</code> - 路由追踪
<ul>
<li><code>traceroute example.com</code></li>
</ul>
</li>
<li><code>mtr</code> - 更好的路由追踪工具</li>
</ul>
<h4 id="端口扫描">端口扫描</h4>
<ul>
<li><code>nmap</code> - 网络扫描工具
<ul>
<li><code>nmap -sS</code> TCP SYN扫描</li>
<li><code>nmap -sU</code> UDP扫描</li>
<li><code>nmap -O</code> 操作系统检测</li>
</ul>
</li>
<li><code>telnet</code> - 测试端口连通性
<ul>
<li><code>telnet host port</code></li>
</ul>
</li>
</ul>
<h4 id="网络抓包">网络抓包</h4>
<ul>
<li><code>tcpdump</code> - 命令行抓包工具
<ul>
<li><code>tcpdump -i eth0</code> 指定接口</li>
<li><code>tcpdump port 80</code> 指定端口</li>
<li><code>tcpdump -w file.pcap</code> 保存到文件</li>
</ul>
</li>
<li><code>wireshark</code> - 图形化抓包工具</li>
</ul>
<h3 id="5-DNS和主机名">5. DNS和主机名</h3>
<h4 id="DNS配置">DNS配置</h4>
<ul>
<li><code>/etc/resolv.conf</code> - DNS解析配置</li>
<li><code>/etc/hosts</code> - 本地主机名解析</li>
<li><code>nslookup</code> - DNS查询工具</li>
<li><code>dig</code> - 更强大的DNS查询工具
<ul>
<li><code>dig example.com</code> 查询A记录</li>
<li><code>dig MX example.com</code> 查询MX记录</li>
</ul>
</li>
</ul>
<h4 id="主机名管理">主机名管理</h4>
<ul>
<li><code>hostname</code> - 查看或设置主机名</li>
<li><code>hostnamectl</code> - 系统主机名控制</li>
<li>
<ul>
<li><code>hostnamectl set-hostname</code> 设置主机名</li>
</ul>
</li>
</ul>
<h3 id="6-网络服务">6. 网络服务</h3>
<h4 id="SSH服务">SSH服务</h4>
<ul>
<li><code>ssh</code> - 安全远程登录
<ul>
<li><code>ssh user@host</code></li>
<li><code>ssh -p port user@host</code> 指定端口</li>
</ul>
</li>
<li><code>scp</code> - 安全文件传输
<ul>
<li><code>scp file user@host:path</code></li>
</ul>
</li>
<li><code>ssh-keygen</code> - SSH密钥生成</li>
</ul>
<h4 id="其他网络工具">其他网络工具</h4>
<ul>
<li><code>curl</code> - URL传输工具</li>
<li><code>wget</code> - 网络下载工具</li>
<li><code>netcat</code> - 网络瑞士军刀</li>
</ul>
<h2 id="磁盘管理">磁盘管理</h2>
<h3 id="1-磁盘基础概念">1. 磁盘基础概念</h3>
<h4 id="磁盘设备命名">磁盘设备命名</h4>
<ul>
<li><code>/dev/sda</code> - 第一块SCSI/SATA磁盘</li>
<li><code>/dev/sdb</code> - 第二块SCSI/SATA磁盘</li>
<li><code>/dev/sda1</code> - 第一块磁盘的第一个分区</li>
<li><code>/dev/vda</code> - 虚拟化环境中的磁盘</li>
</ul>
<h4 id="磁盘类型">磁盘类型</h4>
<ul>
<li>HDD: 机械硬盘</li>
<li>SSD: 固态硬盘</li>
<li>NVMe: 高速固态硬盘（/dev/nvme0n1）</li>
</ul>
<h3 id="2-磁盘分区管理">2. 磁盘分区管理</h3>
<h4 id="分区工具">分区工具</h4>
<ul>
<li><code>fdisk</code> - 传统分区工具（MBR）</li>
<li><code>parted</code> - 高级分区工具（支持GPT）</li>
<li><code>gdisk</code> - GPT分区工具</li>
</ul>
<h4 id="fdisk基本操作">fdisk基本操作</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fdisk /dev/sdb</span><br><span class="line"><span class="comment"># 常用命令:</span></span><br><span class="line"><span class="comment"># n - 新建分区</span></span><br><span class="line"><span class="comment"># d - 删除分区</span></span><br><span class="line"><span class="comment"># p - 打印分区表</span></span><br><span class="line"><span class="comment"># w - 写入并退出</span></span><br><span class="line"><span class="comment"># q - 退出不保存</span></span><br></pre></td></tr></table></figure>
<h4 id="parted基本操作">parted基本操作</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">parted /dev/sdb</span><br><span class="line"><span class="comment"># 常用命令:</span></span><br><span class="line"><span class="comment"># mklabel gpt - 创建GPT分区表</span></span><br><span class="line"><span class="comment"># mkpart primary ext4 1MiB 10GiB - 创建分区</span></span><br><span class="line"><span class="comment"># print - 显示分区信息</span></span><br><span class="line"><span class="comment"># quit - 退出</span></span><br></pre></td></tr></table></figure>
<h3 id="3-文件系统管理">3. 文件系统管理</h3>
<h4 id="文件系统类型">文件系统类型</h4>
<ul>
<li>ext4: Linux默认文件系统</li>
<li>xfs: 高性能文件系统</li>
<li>swap: 交换分区</li>
<li>vfat: FAT32文件系统</li>
</ul>
<h4 id="创建文件系统">创建文件系统</h4>
<ul>
<li><code>mkfs.ext4 /dev/sdb1</code> - 创建ext4文件系统</li>
<li><code>mkfs.xfs /dev/sdb1</code> - 创建xfs文件系统</li>
<li><code>mkswap /dev/sdb2</code> - 创建交换分区</li>
<li><code>swapon /dev/sdb2</code> - 启用交换分区</li>
</ul>
<h4 id="文件系统检查">文件系统检查</h4>
<ul>
<li><code>fsck.ext4 /dev/sdb1</code> - 检查ext4文件系统</li>
<li><code>xfs_repair /dev/sdb1</code> - 修复xfs文件系统</li>
<li><code>tune2fs</code> - 调整ext文件系统参数</li>
</ul>
<h3 id="4-挂载管理">4. 挂载管理</h3>
<h4 id="挂载命令">挂载命令</h4>
<ul>
<li><code>mount /dev/sdb1 /mnt/data</code> - 挂载分区</li>
<li><code>umount /mnt/data</code> - 卸载分区</li>
<li><code>mount -a</code> - 挂载所有在fstab中的文件系统</li>
</ul>
<h4 id="etc-fstab配置">/etc/fstab配置</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设备        挂载点   文件系统  选项      备份 检查</span></span><br><span class="line">/dev/sdb1    /data    ext4     defaults  0    0</span><br><span class="line">UUID=xxxx    /backup  xfs      defaults  0    0</span><br></pre></td></tr></table></figure>
<h4 id="挂载选项">挂载选项</h4>
<ul>
<li>defaults: 默认选项（rw,suid,dev,exec,auto,nouser,async）</li>
<li>noatime: 不更新访问时间</li>
<li>nodiratime: 不更新目录访问时间</li>
<li>ro: 只读挂载</li>
<li>rw: 读写挂载</li>
</ul>
<h3 id="5-LVM逻辑卷管理">5. LVM逻辑卷管理</h3>
<h4 id="LVM概念">LVM概念</h4>
<ul>
<li>PV (Physical Volume): 物理卷</li>
<li>VG (Volume Group): 卷组</li>
<li>LV (Logical Volume): 逻辑卷</li>
</ul>
<h4 id="LVM创建流程">LVM创建流程</h4>
<ol>
<li>创建物理卷: <code>pvcreate /dev/sdb</code></li>
<li>创建卷组: <code>vgcreate vg_data /dev/sdb</code></li>
<li>创建逻辑卷: <code>lvcreate -L 10G -n lv_data vg_data</code></li>
<li>创建文件系统: <code>mkfs.ext4 /dev/vg_data/lv_data</code></li>
<li>挂载使用: <code>mount /dev/vg_data/lv_data /data</code></li>
</ol>
<h4 id="LVM管理命令">LVM管理命令</h4>
<ul>
<li><code>pvdisplay</code> - 显示物理卷信息</li>
<li><code>vgdisplay</code> - 显示卷组信息</li>
<li><code>lvdisplay</code> - 显示逻辑卷信息</li>
<li><code>vgextend</code> - 扩展卷组</li>
<li><code>lvextend</code> - 扩展逻辑卷</li>
<li><code>resize2fs</code> - 调整文件系统大小</li>
</ul>
<h3 id="6-磁盘配额管理">6. 磁盘配额管理</h3>
<h4 id="配额配置步骤">配额配置步骤</h4>
<ol>
<li>启用配额: <code>usrquota,grpquota</code> 挂载选项</li>
<li>创建配额数据库: <code>quotacheck -cug /mountpoint</code></li>
<li>启用配额: <code>quotaon /mountpoint</code></li>
<li>设置配额: <code>edquota username</code></li>
</ol>
<h4 id="配额管理命令">配额管理命令</h4>
<ul>
<li><code>quota</code> - 查看用户配额</li>
<li><code>repquota</code> - 报告配额使用情况</li>
<li><code>setquota</code> - 设置配额限制</li>
</ul>
<h3 id="7-磁盘性能监控">7. 磁盘性能监控</h3>
<h4 id="性能监控工具">性能监控工具</h4>
<ul>
<li><code>iostat</code> - I/O统计信息</li>
<li><code>iotop</code> - I/O使用情况top</li>
<li><code>hdparm</code> - 硬盘参数和性能测试</li>
<li><code>dd</code> - 磁盘读写性能测试</li>
</ul>
<h4 id="性能测试示例">性能测试示例</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写性能测试</span></span><br><span class="line"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=testfile bs=1G count=1 oflag=direct</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读性能测试</span></span><br><span class="line"><span class="built_in">dd</span> <span class="keyword">if</span>=testfile of=/dev/null bs=1G count=1</span><br></pre></td></tr></table></figure>
<h2 id="服务管理">服务管理</h2>
<h3 id="1-systemd基础">1. systemd基础</h3>
<h4 id="systemd简介">systemd简介</h4>
<ul>
<li>系统初始化系统</li>
<li>服务管理守护进程</li>
<li>提供系统状态快照</li>
<li>支持并行启动服务</li>
</ul>
<h4 id="核心概念">核心概念</h4>
<ul>
<li>单元(Unit): 系统资源抽象（服务、挂载点、设备等）</li>
<li>目标(Target): 单元组，类似运行级别</li>
<li>依赖关系: 服务启动顺序控制</li>
</ul>
<h3 id="2-服务管理命令">2. 服务管理命令</h3>
<h4 id="systemctl基础命令">systemctl基础命令</h4>
<ul>
<li><code>systemctl status service</code> - 查看服务状态</li>
<li><code>systemctl start service</code> - 启动服务</li>
<li><code>systemctl stop service</code> - 停止服务</li>
<li><code>systemctl restart service</code> - 重启服务</li>
<li><code>systemctl reload service</code> - 重载配置</li>
</ul>
<h4 id="服务启用和禁用">服务启用和禁用</h4>
<ul>
<li><code>systemctl enable service</code> - 启用开机启动</li>
<li><code>systemctl disable service</code> - 禁用开机启动</li>
<li><code>systemctl is-enabled service</code> - 检查启用状态</li>
<li><code>systemctl is-active service</code> - 检查活动状态</li>
</ul>
<h4 id="系统状态查看">系统状态查看</h4>
<ul>
<li><code>systemctl list-units</code> - 列出所有单元</li>
<li><code>systemctl list-unit-files</code> - 列出所有单元文件</li>
<li><code>systemctl list-dependencies</code> - 列出依赖关系</li>
<li><code>systemctl show service</code> - 显示服务属性</li>
</ul>
<h3 id="3-服务单元文件">3. 服务单元文件</h3>
<h4 id="单元文件位置">单元文件位置</h4>
<ul>
<li><code>/usr/lib/systemd/system/</code> - 系统安装的单元文件</li>
<li><code>/etc/systemd/system/</code> - 系统管理员创建的单元文件</li>
<li><code>/run/systemd/system/</code> - 运行时单元文件</li>
</ul>
<h4 id="单元文件结构">单元文件结构</h4>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=服务描述</span><br><span class="line"><span class="attr">After</span>=network.target</span><br><span class="line"><span class="attr">Requires</span>=network.target</span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="attr">Type</span>=simple</span><br><span class="line"><span class="attr">User</span>=username</span><br><span class="line"><span class="attr">ExecStart</span>=/path/to/command</span><br><span class="line"><span class="attr">Restart</span>=always</span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure>
<h4 id="常用配置选项">常用配置选项</h4>
<ul>
<li><strong>Type</strong>: simple, forking, oneshot, notify</li>
<li><strong>User/Group</strong>: 运行服务的用户和组</li>
<li><strong>ExecStart</strong>: 启动命令</li>
<li><strong>ExecStop</strong>: 停止命令</li>
<li><strong>Restart</strong>: 重启策略</li>
<li><strong>Environment</strong>: 环境变量</li>
</ul>
<h3 id="4-目标-Target-管理">4. 目标(Target)管理</h3>
<h4 id="系统目标">系统目标</h4>
<ul>
<li><code>multi-user.target</code> - 多用户文本模式</li>
<li><code>graphical.target</code> - 图形界面模式</li>
<li><code>rescue.target</code> - 救援模式</li>
<li><code>emergency.target</code> - 紧急模式</li>
</ul>
<h4 id="目标操作">目标操作</h4>
<ul>
<li><code>systemctl isolate target</code> - 切换到目标</li>
<li><code>systemctl get-default</code> - 获取默认目标</li>
<li><code>systemctl set-default target</code> - 设置默认目标</li>
<li><code>systemctl list-dependencies target</code> - 列出目标依赖</li>
</ul>
<h3 id="5-日志管理">5. 日志管理</h3>
<h4 id="journalctl命令">journalctl命令</h4>
<ul>
<li><code>journalctl</code> - 查看所有日志</li>
<li><code>journalctl -u service</code> - 查看指定服务日志</li>
<li><code>journalctl -f</code> - 实时跟踪日志</li>
<li><code>journalctl --since &quot;1 hour ago&quot;</code> - 时间范围查询</li>
<li><code>journalctl -p err</code> - 查看错误级别日志</li>
</ul>
<h4 id="日志过滤">日志过滤</h4>
<ul>
<li><code>journalctl _PID=1234</code> - 按进程ID过滤</li>
<li><code>journalctl _UID=1000</code> - 按用户ID过滤</li>
<li><code>journalctl -k</code> - 查看内核日志</li>
<li><code>journalctl --disk-usage</code> - 查看日志磁盘使用</li>
</ul>
<h3 id="6-定时任务管理">6. 定时任务管理</h3>
<h4 id="systemd定时器">systemd定时器</h4>
<ul>
<li>替代传统的cron</li>
<li>更精确的时间控制</li>
<li>更好的日志集成</li>
</ul>
<h4 id="定时器配置">定时器配置</h4>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="comment"># timer单元</span></span><br><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=定时任务描述</span><br><span class="line"></span><br><span class="line"><span class="section">[Timer]</span></span><br><span class="line"><span class="attr">OnCalendar</span>=*-*-* <span class="number">02</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attr">Persistent</span>=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=timers.target</span><br></pre></td></tr></table></figure>
<h4 id="传统cron">传统cron</h4>
<ul>
<li><code>/etc/crontab</code> - 系统crontab</li>
<li><code>/etc/cron.d/</code> - 额外cron配置</li>
<li><code>crontab -e</code> - 编辑用户cron</li>
<li><code>crontab -l</code> - 列出用户cron</li>
</ul>
<h3 id="7-服务故障排查">7. 服务故障排查</h3>
<h4 id="常见问题">常见问题</h4>
<ul>
<li>服务启动失败</li>
<li>依赖关系问题</li>
<li>权限配置错误</li>
<li>资源限制问题</li>
</ul>
<h4 id="排查工具">排查工具</h4>
<ul>
<li><code>systemctl status</code> - 查看服务状态</li>
<li><code>journalctl -u</code> - 查看服务日志</li>
<li><code>systemctl daemon-reload</code> - 重载配置</li>
<li><code>systemctl reset-failed</code> - 重置失败状态</li>
</ul>
<h2 id="后话">后话</h2>
<p>这个文档是刚开始学习时的记录。</p>
<p>后面经过一段时间的工作后，觉得能看明白日志，能排查问题才是最重要的。</p>
<p>可能是我作为开发人员的习惯吧，总觉得遇到错误得弄明白才行。</p>
<p>开发人员也有遇到线上问题的时候，这时候能看日志，能通过命令旁敲侧击查找问题的根源就很重要了。</p>
<p>能否处理线上事故，排查的手段是否丰富，这应该是高级开发和普通开发最大的差异点之一了。</p>
<p>就我个人来说，以前写Java也处理过不少线上问题，有自己的经验，但到运维这块，我发现遇到的网络问题明显更多一些…</p>
<p>所以就很头疼，硬着头皮学了不少东西，把网络这块的缺漏又补了一遍。</p>
<p>明明研究生的时候就又重学了一遍网络，没想到工作之后又得学，果然是学无止境。</p>
<p>我做现在的工作时总会想起多隆，解决一个个问题，处理好一件件事情，以后会不会也有机会成为像多隆一样的技术专家呢？</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>中小模型优化</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/tips/%E4%B8%AD%E5%B0%8F%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="背景">背景</h2>
<p>理想情况下，我们购买大公司的算力服务或模型服务，用差不多的提示词调下接口，然后拿着可靠的返回值继续我们的业务逻辑。</p>
<p>但实际工作中，并没有那么多的钱能让我们去买这些算力或模型服务，而且往往是打着数据安全的旗号来的。</p>
<p>最后大部分公司里，可能就是拿着来之不易的一点点经费，自己摸索部署了一个小小的模型来开发对接。</p>
<p>很不幸，虽然我在的公司挺大的，但所在的部门经费有限。</p>
<p>考虑到项目成本和合同收益，让我发挥出了垃圾佬的本性，对着小模型鼓捣了半天，也算是有了些成果。</p>
<p>主打一个花小钱办大事，用不那么聪明的模型来干活。</p>
<h2 id="场景">场景</h2>
<p>应该算是典型的质检验收场景，大概就是安装设备的师傅会拍照上传到平台，平台要用多模态的AI来识别这个照片是否合格。</p>
<p>不同的设备安装合格的要求不一样，有些复杂有些简单，因此模型的智力水平会大大影响结果。</p>
<h2 id="常见的问题与解决方案">常见的问题与解决方案</h2>
<p>先聊聊小模型常见的问题吧。</p>
<h3 id="格式限制不生效">格式限制不生效</h3>
<p>这应该是很常见的问题了。提示词里限制了模型返回JSON格式，但模型就是自说自话返回了大段大段的废话。</p>
<p>解决方法有多个，这些方法可以一起用上。</p>
<ol>
<li>宽松校验：不严格校验模型返回的格式，而是进行关键内容提取，只要内容里有JSON就提取出来，认为模型是返回成功了。因为模型很多时候只是说了些废话，但最终还是能正常返回一个JSON格式的答案。所以只要能提取出最终的JSON，这问题就解决了。</li>
<li>重试：很多时候模型只是小概率返回非预期的回答，此时重试一下可能就好了。</li>
<li>调整温度：温度太高了导致模型开始自由发挥，此时适当调低温度也是可行的，比如从0.75调整到0.5。</li>
<li>模型总结：进行多轮对话，前面是聊业务，在最后一轮让模型把结果总结成JSON格式，大部分时候也是能产生较好的效果。</li>
</ol>
<h3 id="答非所问">答非所问</h3>
<p>在调试过程中，我使用的模型常常会回答&quot;我是个文本模型，不支持图像识别&quot;。</p>
<p>可实际上它是支持图像识别的。感觉是模型训练时有数据污染导致的，这问题是概率性触发。</p>
<p>解决方法：</p>
<ol>
<li>调整TopP和温度：TopP和温度太低时似乎这问题会出现概率变高。</li>
<li>调整系统提示词：告知模型你具有图像识别的能力。</li>
<li>重试：多次尝试大部分时候能正常返回。</li>
</ol>
<h3 id="识别不准确">识别不准确</h3>
<p>在某些场景下，发现模型不能正常识别到图片的内容，开始胡言乱语。</p>
<p>解决方法：</p>
<ol>
<li>调整系统提示词：需要判断是否是系统提示词出现了问题，可能是业务场景涉及到某些专业知识，而模型并没有直接识别到是此类场景，可以调整下系统提示词简要说明行业背景。</li>
<li>调整用户提示词：有些是用户提示词的描述不够准确，比如&quot;电线&quot;的概念较为宽泛，而模型不太能处理此类描述。一个好的办法是先把图片送给模型，<strong>让模型来描述图片的内容，然后挑选模型自己的描述来重构提示词</strong>。</li>
<li>拆分任务：多个任务放在一次问答里返回时效果不太好，因此更建议把任务拆分成一个个小的子任务，让模型分别处理。这问题在大参数量模型上较少出现，但在小参数量模型上会变得较为突出。</li>
</ol>
<h3 id="模型输出较慢">模型输出较慢</h3>
<p>在硬件系统太差的情况下，小模型的输出会很慢，此时建议直接换硬件。</p>
<p>实在不行的话只能限制下模型的输出token，在提示词中尽可能减少需要模型回答的内容。</p>
<p>比如“仅返回是或否”等。</p>
<h2 id="总体优化方向">总体优化方向</h2>
<p>小模型的缺点在于先验知识较少，指令遵循能力较差，返回的内容不可控。</p>
<p>因此，为了提高准确度，只能进行一些特定的优化。说白了就是<strong>拿时间换准确性</strong>。</p>
<p>一种方式是使用类似思维链的能力，在提示词中引导模型一步一步思考，先查什么后查什么，最后总结一个结果。</p>
<p>大部分时候这种方式能让模型在输出一大段对话后给出一个相对可靠的结论。</p>
<p>还有种方式是用代码来替换模型的部分操作，尽可能拆分任务。这就得具体问题具体讨论了，可以参考后面的实践。</p>
<h2 id="实践">实践</h2>
<p>需求：检测图片中是否存在XX设备，网线插入的网线口是否和工单中说明的一致，图片里是否有二维码。这三个都符合则合格。</p>
<p>在做这个需求的时候，显然需要拆分任务。</p>
<p>我先开始是拆成了三个任务：检测设备、检查网线口、检查二维码。</p>
<p>首先遇到的问题是格式限制不生效的问题。我参考其他人的提示词，要求模型返回JSON格式。但实际发现模型完全不会遵循这个指令，只会输出大段的思考过程，然后总结一个JSON的结果出来。</p>
<p>考虑到这是三个任务都是返回个是或否就足够的，我重新优化了一下提示词。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">仅判断图片中是否存在类似&quot;XXX箱&quot;的物体，不做其他判断。输出：存在输出1；不存在输出2。仅输出数字，不得包含其他内容。</span><br></pre></td></tr></table></figure>
<p>修改之后大部分时候是可以返回纯数字了，但偶尔还是会返回思考内容。</p>
<p>于是我更进一步，限制了模型的max_token，直接卡死在1。如此一来，只需要检查是否是返回了数字1或2即可。</p>
<p>这是被阿里的一个二元模型所启发的。</p>
<p>之后就遇到了另一个问题，这三个任务有难有简单，检查网线口的任务复杂程度比另外两个要高。</p>
<p>这个任务限制模型返回1或2后，模型反而完不成任务了。</p>
<p>因此只能继续调试，我发现输出大段思考过程后，模型确实能做出相对正确的判断。</p>
<p>所以就做了结果提取的能力，让模型在第一轮对话里进行思考，再进行第二轮对话，让其总结内容返回1或2。</p>
<p>这样就提高了一定的准确性。</p>
<p>重试的机制也加了，配合max_token调整为1，在前两个简单任务中表现相当不错。</p>
<p>在复杂任务里，重试则分为两部分。总结会重试3次，3次失败之后会回退到前面的图片识别。图片识别则是重试2次，2次失败后认定图片有问题，将其纳入人工干预的范畴。</p>
<p>对于总结这事，本来是考虑另外有个8B的文本模型来进行总结，但因为资源紧张就没落地。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title>用浏览器发送POST请求</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/tips/%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8%E5%8F%91%E9%80%81POST%E8%AF%B7%E6%B1%82/</url>
    <content><![CDATA[<h2 id="场景">场景</h2>
<p>在封闭环境、虚拟机等场景下，我们拿到的环境没法安装postman。</p>
<p>为了解决这问题，可以直接使用浏览器来发送这类请求。</p>
<h2 id="方式">方式</h2>
<p>打开浏览器的console，写入js代码</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> myHeaders = <span class="keyword">new</span> <span class="title class_">Headers</span>();</span><br><span class="line">myHeaders.<span class="title function_">append</span>(<span class="string">&quot;Content-Type&quot;</span>, <span class="string">&quot;application/json&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> raw = <span class="title class_">JSON</span>.<span class="title function_">stringify</span>(&#123;</span><br><span class="line">  <span class="string">&quot;id&quot;</span>: <span class="string">&quot;999999999&quot;</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> requestOptions = &#123;</span><br><span class="line">  <span class="attr">method</span>: <span class="string">&#x27;POST&#x27;</span>,</span><br><span class="line">  <span class="attr">headers</span>: myHeaders,</span><br><span class="line">  <span class="attr">body</span>: raw,</span><br><span class="line">  <span class="attr">redirect</span>: <span class="string">&#x27;follow&#x27;</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="title function_">fetch</span>(<span class="string">&quot;http://127.0.0.1:8101/del-condition&quot;</span>, requestOptions)</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> response.<span class="title function_">text</span>())</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">result</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(result))</span><br><span class="line">  .<span class="title function_">catch</span>(<span class="function"><span class="params">error</span> =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;error&#x27;</span>, error));</span><br></pre></td></tr></table></figure>
<p>表现如下：</p>
<img src="/%E5%B7%A5%E4%BD%9C/work/tips/%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8%E5%8F%91%E9%80%81POST%E8%AF%B7%E6%B1%82/image-20230927153017161.png" class="" title="image-20230927153017161">
<p>完事。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>优秀实践</tag>
      </tags>
  </entry>
  <entry>
    <title>面试笔记-Java基础</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Java%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h2 id="语法基础">语法基础</h2>
<h3 id="Java语言特点">Java语言特点</h3>
<p>一次编译处处运行，天然具有跨平台的能力。只要不用JNI。</p>
<p>开源社区资源丰富，活跃。</p>
<p>适合企业级开发，多方面：有Spring为主流的开源框架，大型项目的构建和维护的成本较低。语言的规范性强。</p>
<h3 id="基本类型和包装类型">基本类型和包装类型</h3>
<p>byte、char、boolean、short、int、float、long、double</p>
<p>基本类型不是对象，包装类型是对象。使用时有自动的拆装箱机制。但编码过程中如果可以用基本类型的建议还是用基本类型。</p>
<p>区别在于对象是有对应的Class类，这些类信息会记录在JVM的ClassLoader中。对象有对象头。</p>
<p>字节码的方法签名，基本类型是BCJFI之类的大写字母，对象是L加全限定类名。</p>
<h3 id="instance-of">instance of</h3>
<p>检测对象是否是某个类型的实例。可以用来检测对象是否实现了某个接口。</p>
<p>HashMap中有使用到，用来检测当前节点的实现是链表还是红黑树。</p>
<h3 id="重写和重载">重写和重载</h3>
<p>重写建议加@Override注解，标明该方法是重写方法。</p>
<p>重写发生在子类重写了父类的同名且参数完全一致的方法，或者是实现了某个接口的方法。有重写就一定是有extend或者impliment。</p>
<p>重载是同名方法用不同的参数实现。同名方法的方法签名是不一样的。</p>
<h3 id="equals和">equals和==</h3>
<p>==是比较两个变量所指向的内存地址是否相同，其实是个指针操作。基本类型就相当于值比较。</p>
<p>equals是Object类的一个方法，Object类中的实现就是==。一般不同的类会有不同的实现，String的实现就是逐个比较字符值是否相等。</p>
<h3 id="四种引用">四种引用</h3>
<p>强引用：使用最多的引用，默认就是强引用。</p>
<p>软引用：缓存会用。可能会被回收，优先级在弱引用之后。</p>
<p>弱引用：young GC时必定会回收。</p>
<p>虚引用：这个引用不会影响GC，需要有其他引用方式指向这个对象。</p>
<h3 id="Cleaner">Cleaner</h3>
<p>Cleaner机制用到了虚引用。Cleaner继承了虚引用，GC后，所有的cleaner会被回收到一个pending队列，reference handler线程会调用这个pending队列中的对象，会检测下是不是Cleaner对象，是的话就直接调用Cleaner的clean方法。</p>
<h3 id="Exception和Error">Exception和Error</h3>
<p>都是Throwable的实现类。</p>
<p>运行时异常不用显式地catch。被检查异常需要catch或向上抛出。</p>
<p>Error是非常严重的错误，可能宕机。但是不需要显式抛出。</p>
<h2 id="数据结构">数据结构</h2>
<h3 id="HashMap">HashMap</h3>
<p>线程不安全。</p>
<p>put：hash之后找到数组中的对应位置，如果为空直接塞；不为空说明哈希冲突，检查一下当前的数据结构，按照数据结构来添加这个对象，可能是替换也可能是新增。</p>
<h3 id="LinkedList">LinkedList</h3>
<p>双向链表，线程不安全。</p>
<h3 id="阻塞队列">阻塞队列</h3>
<p>阻塞队列的经典实现：ArrayBlockQueue，LinkedBlockQueue</p>
<p>用了大小堆的priority queue</p>
<p>阻塞队列的锁就是线程池的锁。所以阻塞队列的性能也一定程度上决定了线程池的性能。举例：Disruptor、参考Disruptor实现了自己的阻塞队列。</p>
<p>阻塞队列可以当做对象池来用。</p>
<h2 id="JVM">JVM</h2>
<h3 id="JVM内存模型">JVM内存模型</h3>
<p>线程独占的：栈，本地方法栈，程序计数器</p>
<p>线程共享的：堆，方法区</p>
<p>栈：存储局部变量，操作栈，动态链接，方法出口。调用一个方法时入栈，方法返回出栈。</p>
<p>本地方法栈：Native方法的栈</p>
<p>程序计数器：当前程序执行的字节码位置。也就是打印异常堆栈时看到的执行到第几行出错。执行到native方法时，程序计数器清空，因为不是在执行字节码了。</p>
<p>堆：存储对象实例，线程共享。会垃圾回收。</p>
<p>方法区：虚拟机加载的类信息，常量，静态变量，JIT优化后的代码。总之就是些全局的信息。</p>
<h3 id="内存可见性">内存可见性</h3>
<p>也就是为什么要volatile关键字。</p>
<p>线程执行时，会拷贝一份线程间的共享变量至线程的工作内存。拷贝的数据可能已经被其他线程修改了，导致执行结果错误。</p>
<p>volatile会在共享变量修改时，强制同步一份副本至所有涉及到的线程的工作空间。</p>
<h3 id="类加载和卸载">类加载和卸载</h3>
<p>加载字节码文件到内存-&gt;验证并解析为Class类，创建静态变量执行静态代码块-&gt;实例化-&gt;GC</p>
<h3 id="三种加载器">三种加载器</h3>
<p>JAVA_HOME/lib: Bootstrap ClassLoader</p>
<p>JAVA_HOME/lib/ext: Extension ClassLoader</p>
<p>Application ClassLoader</p>
<h3 id="双亲委派">双亲委派</h3>
<p>加载器加载一个类时，先委托给父类加载器。父类无法加载才会自己加载。</p>
<p>主要是为了避免同一个类被多个加载器重复加载。已经避免Java的核心类被修改。</p>
<h3 id="回收算法G1">回收算法G1</h3>
<p>高频率回收，减少每次的停顿。</p>
<p>分老年代和年轻代。分块region，年轻代和老年代都由若干个分块组成。</p>
<p>年轻代使用并行的复制和收集算法。</p>
<p>mix-GC会回收一部分老年代。</p>
<p>标记清除算法：STW进行初始标记，确实GC root可直达的对象，伴随一次young GC。然后GC线程和应用线程并行进行并发标记，尽可能标记出存活对象，使用SATB记录对象的引用关系。最终标记，STW，修改并发标记的错误。然后多线程进行GC。</p>
<h3 id="ZGC">ZGC</h3>
<p>低延时垃圾收集器。</p>
<h3 id="Full-GC">Full GC</h3>
<p>当老年代满时会进行，耗时长。需要避免。</p>
<h3 id="对象分配原则">对象分配原则</h3>
<p>新对象优先在eden区，如果大于survivor的二分之一就认定为大对象，直接晋升老年代。</p>
<p>对象没存活过一次young GC，年龄+1，到达一定年龄（默认15）就晋升老年代。</p>
<p>Survivor区中同年龄对象的总和大小超过一半，这个年龄以及这个年龄以上的对象进入老年代。</p>
<h3 id="对象的创建过程">对象的创建过程</h3>
<p>先去常量池找类信息，然后加载类信息，找不到就报ClassNotFound。</p>
<p>为对象分配内存，将除了对象头之外的内存块初始化为0。</p>
<p>设置对象头。</p>
<h3 id="对象结构">对象结构</h3>
<p>对象头12字节，数组16字节。</p>
<p>对象信息，基础类型直接在对象内存存储。</p>
<p>Java会自动排列对象中的Field顺序以更好地满足8字节对齐。</p>
<h3 id="对象头的内容">对象头的内容</h3>
<p>4字节的hashcode</p>
<p>2字节的分代年龄</p>
<p>1字节偏向锁</p>
<p>1字节锁标志</p>
<p>4字节的对象类型指针，指向Class类信息</p>
<p>数组的话还有4字节的数组长度</p>
<h3 id="常见的调优工具">常见的调优工具</h3>
<p>jps：展示所有的java进程</p>
<p>jstat：查看虚拟机运行状态</p>
<p>jmap：主要用于dump</p>
<p>jstack：生成线程快照</p>
<p>jinfo：实时查看和修改JVM参数</p>
<p>MAT：dump文件分析</p>
<p>visualVM：自带可视化界面</p>
<p>arthas：阿里开源的运行时诊断工具</p>
<h2 id="多线程">多线程</h2>
<h3 id="怎么创建线程">怎么创建线程</h3>
<p>只有new Thread()才算创建了一个新线程。其他的方式比如实现Runnable接口Callable接口之类的都没有新线程产生。</p>
<p>Runnable接口Callable接口本质是一个task，需要提交给线程才能执行。</p>
<h3 id="如何停止一个线程">如何停止一个线程</h3>
<p>最佳是用退出标志，完成当前方法后当前线程终止。</p>
<p>推荐调用interrupt，会抛出interrupt异常。</p>
<p>stop可以强行终止，不推荐。</p>
<h3 id="notify和notifyAll有什么区别">notify和notifyAll有什么区别</h3>
<p>notify可能死锁，notifyAll不会。</p>
<p>假如有多个线程正在wait，会要求notify唤醒的任意一个线程可以处理接下来的逻辑，否则就会死锁。</p>
<p>如果无法正确处理，则应该继续notify下一个，并让自己进入wait状态。</p>
<p>notifyAll唤醒所有线程，但是争抢锁还是无序的。</p>
<h3 id="sleep和wait有什么区别">sleep和wait有什么区别</h3>
<p>sleep在线程类中，wait在Object类。</p>
<p>sleep不释放锁，会让出cpu。</p>
<p>wait会释放锁，并且让出cpu。调用wait后，会释放线程持有的所有对象锁，然后进入对象的等待区。只有针对此对象调用notify或notifyAll后，才会获取对象锁进入运行状态。</p>
<h3 id="volatile">volatile</h3>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>面试笔记-Spring</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Spring/</url>
    <content><![CDATA[<h2 id="Spring篇">Spring篇</h2>
<p>Spring是一个Java开发框架，主要是解决企业级开发的一些痛点。一开始可能主要是用于Web应用的开发，但目前实践中它已经在国内Java后端开发这方面一统江湖。</p>
<p>它把各种业务逻辑都抽象封装为Bean，Spring负责项目启动时把这些Bean创建出来，进行业务开发的时候只需要通过Spring提供的API或其他方式，获取到对应的Bean就可以执行各种复杂业务操作。</p>
<h3 id="为什么是Spring">为什么是Spring</h3>
<p>轻量。</p>
<p>IOC，控制反转。业务开发不用关注对象创建之类的事情，只需要编码，并给出依赖，框架会自动帮你找到对应的实现类。</p>
<p>AOP，面向切面编程。</p>
<p>事务管理。</p>
<p>异常处理。</p>
<h3 id="Autowired和Resource的区别">Autowired和Resource的区别</h3>
<p>Autowired是Spring提供的注解，Resource是javax的注解。Spring是支持了javax提供的标准注解，是标准的一个实现。</p>
<p>假如换了框架（一般不会），Autowired必定不可用，Resource可能还能用。</p>
<p>Autowired默认按照type类装配，默认要求对象必须存在且唯一。可以用Qualifier来指定BeanName。</p>
<p>Resource注解提供了type和name两个注解字段。name的优先级高于type。</p>
<h3 id="依赖注入的方式">依赖注入的方式</h3>
<p>构造器、setter、接口。反射注入</p>
<h3 id="Spring-MVC">Spring MVC</h3>
<p>Spring MVC是Spring的一个模块，针对web应用的场景。</p>
<p>V不是普遍意义上的前端，而是用jsp或其他方式渲染的一个页面。</p>
<p>M是逻辑层，做计算和数据库操作。C是控制层，负责接收网络请求。</p>
<p>Spring在Servlet的基础上实现，定义了一个统一的请求接收入口：DispatcherServlet。DispatcherServlet会根据url和请求类型分发请求到用户编码的Controller中，然后执行用户的逻辑。</p>
<p>常用注解：@RequestMapping、@RequestBody、@ResponseBody</p>
<h3 id="AOP">AOP</h3>
<p>把一些业务无关，在系统层面共通的逻辑封装起来，从而减少代码冗余，有利于代码的扩展性和维护性。比如参数校验、日志采集、权限控制。</p>
<p>Spring的AOP是基于动态代理实现的。对于已经实现了接口的，用JDK动态代理，创建一个接口的实现类然后代理。没有实现的，用CGlib，创建一个类的子类然后代理。</p>
<p>也可以用AspectJ实现自己的AOP逻辑。</p>
<p>Spring的AOP属于运行时增强，AspectJ的AOP是编译时增强。AspectJ是字节码操作，性能稍高。</p>
<h3 id="关注点和横切关注点">关注点和横切关注点</h3>
<p>关注点是某个特定的业务功能，横切关注点是多个业务都会用到的系统功能，比如日志、参数校验、权限。</p>
<h3 id="什么是通知advice">什么是通知advice</h3>
<p>方法执行前和后要做的逻辑处理。</p>
<p>before</p>
<p>after</p>
<p>after-returning</p>
<p>after-throwing</p>
<p>around</p>
<p>这个结果处理和Spring WebFlux中的回调很像。</p>
<h3 id="IOC">IOC</h3>
<p>控制反转，把创建对象的权利移交给框架。</p>
<p>对象不需要程序自己去new，而是通过依赖注入从框架中获取。</p>
<p>IOC让组件保持松散的耦合，从而创造了可以进行AOP编程的余地。</p>
<h3 id="Spring-Bean生命周期">Spring Bean生命周期</h3>
<p>Servlet：实例化、初始化、接收请求、销毁。</p>
<p>Bean：</p>
<p>1、配置扫描，创建BeanDefinition，构建BeanFactory。</p>
<p>2、实例化：启动时的第一步。当BeanFactory被请求一个未实例化的Bean时，会调用createBean方法实例化一个Bean。</p>
<p>3、依赖注入：实例化之后的对象在BeanWrapper中，Spring通过BeanDefinition的配置进行依赖注入。这里会先找这个Bean的依赖所对应的BeanFactory，然后提供一个实例化Bean进行依赖注入。</p>
<p>4、处理Aware接口：BeanNameAware、BeanFactoryAware、ApplicationContextAware</p>
<p>5、BeanPostProcessor的postProcessBeforeInitialization方法</p>
<p>6、InitializingBean的afterPropertiesSet</p>
<p>7、BeanPostProcessor的postProcessAfterInitialization方法</p>
<p>8、scope为singleton的缓存在容器，prototype的返回最开始请求的客户端。</p>
<p>9、销毁，调用DisposableBean的afterPropertiesSet</p>
<h3 id="Bean的作用域">Bean的作用域</h3>
<p>1、singleton：单例</p>
<p>2、prototype：每个Bean一个实例</p>
<p>3、request：每个网络请求一个实例</p>
<p>4、session：每个session一个实例</p>
<p>5、globe-session</p>
<h3 id="Spring的设计模式">Spring的设计模式</h3>
<p>简单工厂模式：Bean的创建</p>
<p>单例模式：单例的Bean</p>
<p>代理模式：AOP的实现</p>
<p>适配器：Adapter，Spring中以Adapter结尾的一般都是适配器模式。比如AdvisorAdapter</p>
<p>观察者模式：Spring事件</p>
<p>模版模式：JdbcTemplate</p>
<h3 id="ApplicationContext和BeanFactory">ApplicationContext和BeanFactory</h3>
<p>BeanFactory是基础接口，只提供最基础的Bean管理功能，在spring-beans包中。</p>
<p>ApplicationContext继承了BeanFactory，并且扩展了事务管理、国际化、AOP。</p>
<p>BeanFactory是延迟加载，而ApplicationContext是启动时实例化所有的Bean。</p>
<h3 id="Spring的单例Bean是线程安全的吗">Spring的单例Bean是线程安全的吗</h3>
<p>是否线程安全和单例无关。Spring本身没有对Bean做任何并发的保护，这也不是Spring应该关心的东西。是否线程安全由开发者来保证。</p>
<h3 id="循环依赖怎么解决">循环依赖怎么解决</h3>
<p>三级缓存</p>
<p>第一级缓存是初始化完成的Bean；第二级是完成了实例化，但是没有完成依赖注入的Bean；第三级是没实例化的Bean，存放其BeanFactory。</p>
<p>假设有两个Bean A、B，AB循环依赖</p>
<p>1、Bean都是由BeanFactory创建，A的BeanFactory会先实例化A，放入二级缓存，随后进行依赖注入。</p>
<p>2、A的BeanFactory通过依赖找到了B，先从一级缓存找，一路找到三级缓存，最后找到了B的BeanFactory。这时候B没有创建，所以用B的BeanFactory创建B。BeanFactory会先创建一个B的实例，这样在二级缓存就有了一个B的实例，然后进行依赖注入。</p>
<p>3、B在依赖注入的时候会在二级缓存找到A，这时会直接获取A的实例注入B，这样就完成B的依赖注入。B完成创建后放入一级缓存，然后把B通过BeanFactory的方法返回给A，A就可以继续进行依赖注入。</p>
<h3 id="Spring事务隔离级别">Spring事务隔离级别</h3>
<p>同数据库的级别：读未提交、读已提交、可重复读、串行化</p>
<h3 id="Spring事务传播级别">Spring事务传播级别</h3>
<p>PROPAGATION_REQUIRED：有事务就加入，没有就创建</p>
<p>PROPAGATION_SUPPORTS：有就加入，没有就不加事务</p>
<p>PROPAGATION_MANDATORY：有就加入，没有就抛异常</p>
<p>PROPAGATION_REQUIRES_NEW：永远创建一个新的事务执行</p>
<p>PROPAGATION_NOT_SUPPORTED：永远不以事务执行</p>
<p>PROPAGATION_NEVER：有事务就抛异常</p>
<p>PROPAGATION_NESTED：有事务就创建嵌套事务，没有就创建</p>
<h3 id="Spring事务实现">Spring事务实现</h3>
<p>编程式事务、声明式事务。</p>
<p>PlatformTransactionManager中定义了事务的开始、提交、回滚等操作。不同数据库会有不同实现。</p>
<h3 id="Spring事务管理优点">Spring事务管理优点</h3>
<p>抽象了统一的接口。支持声明式事务管理。</p>
<p>可以和Spring多数据源结合。</p>
<h3 id="事务三要素">事务三要素</h3>
<p>数据源：事务的真正处理者。</p>
<p>事务管理器：处理事务的打开、提交、回滚。</p>
<p>事务应用和配置：表明哪些方法参与事务，事务的隔离级别，传播级别，超时时间。</p>
<h3 id="事务注解的本质">事务注解的本质</h3>
<p>@Transactional仅仅是一些元数据，这里通过AOP的方式，将元信息传递事务管理器，事务管理器再提交给数据源实现具体的事务。</p>
<p>其实就相当于在方法前后加了一些事务的代码。</p>
<h2 id="Spring-Boot篇">Spring Boot篇</h2>
<h3 id="为什么是Spring-Boot">为什么是Spring Boot</h3>
<p>独立运行：内嵌了tomcat、Jetty。不需要打成war包部署到容器。可以打成独立的Jar包运行。</p>
<p>配置简化，自动装配：能根据当前路径下的类、jar来自动配置bean。</p>
<p>无代码生成：配置过程中没有代码生成，没有xml配置文件，都是基于条件注解完成。</p>
<p>监控：默认就提供了很多监控端点。</p>
<p>Spring Boot大量使用了注解来驱动开发。</p>
<h3 id="核心注解">核心注解</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@SpringBootConfiguration</span><br><span class="line">@EnableAutoConfiguration</span><br><span class="line">@ComponentScan</span><br></pre></td></tr></table></figure>
<h3 id="如何理解starters">如何理解starters</h3>
<p>一个把所有依赖都集成在一起的依赖包，简化引入的成本。</p>
<h3 id="如何在启动时执行一些特殊的逻辑">如何在启动时执行一些特殊的逻辑</h3>
<p>ApplicationRunner，CommandLineRunner。</p>
<p>ApplicationRunner有一个实现，是在启动时把程序的pid打印到一个文件中，方便运维。</p>
<h3 id="监视器-actuator">监视器 actuator</h3>
<p>actuator会对外暴露一些端点，可以通过配置的方式管理这些端点（endpoint）。这是能让用户来访问和监控程序当前的运行状态。配合运维平台使用。</p>
<h3 id="异常处理">异常处理</h3>
<p>ControllerAdvice，可以用来处理所有的异常，封装为统一的异常信息返回。</p>
<h3 id="配置加载顺序">配置加载顺序</h3>
<p>Spring Boot的配置加载顺序和其优先级一致。</p>
<p>1、命令行，–大于-D</p>
<p>2、Java系统属性，System.getProperties。</p>
<p>3、环境变量</p>
<p>4、yml文件</p>
<p>5、默认配置</p>
<h3 id="application和bootstrap文件">application和bootstrap文件</h3>
<p>老版本Spring Cloud Alibaba的Nacos只能使用bootstrap文件，后面版本修改了。</p>
<h3 id="自动装配">自动装配</h3>
<p>自动装配就是把第三方的Bean装载到Spring的容器里。以前是需要开发人员写xml才能把这些Bean装载到容器的。</p>
<p>原理：第三方组件定义了Configuration类，在其中声明了需要装载的Bean对象，同时也在这个类里定义了一些自动装配的规则。Spring在启动时通过META-INF/spring.factories文件找到对应的配置类，然后对这些配置类进行动态加载。</p>
<h2 id="Spring-Cloud篇">Spring Cloud篇</h2>
<h3 id="为什么是Spring-Cloud">为什么是Spring Cloud</h3>
<p>是用于构建分布式应用的开源框架。基于Spring Boot，提供与外部系统集成的能力。国内有很多二开的框架，比如Spring Cloud Alibaba，TSF，Spring Cloud Huawei。</p>
<h3 id="什么是微服务">什么是微服务</h3>
<p>一种架构。将单一功能的应用程序划分为一组小的服务，每个服务独立运行，服务之间相互协调、配合，最终实现一个业务功能。</p>
<p>服务之间使用轻量级的通讯机制（通常是http，但是dubbo之类的也可以）。</p>
<p>需要有一个中心来集中化管理这些服务。</p>
<h3 id="服务熔断和降级">服务熔断和降级</h3>
<p>分布式的场景下，某个服务出现异常，当检测到这种情况后，可以切断对该服务的调用。等到服务正常以后，再恢复服务。这就是熔断。</p>
<p>降级是是指服务熔断以后，如果还有对该服务的调用，直接失败。</p>
<h3 id="eureka-zookeeper-nacos">eureka zookeeper nacos</h3>
<p>Eureka的高可用机制比较完善，可以保证服务随时可用。</p>
<p>zookeeper对于多节点的数据一致性处理比较完善，可以用于主从选举。zk其实为了分布式协调而设计的，比如分布式锁、选举都可以用zk来做。</p>
<p>nacos提供了可视化界面，同时支持服务注册发现和配置下发，一个人干了两个人的活。</p>
<h3 id="Spring-Boot-Spring-Cloud">Spring Boot Spring Cloud</h3>
<p>Spring Boot是专注于开发单个微服务。</p>
<p>Spring Cloud是关注分布式系统的，分布式系统可以是多个Spring Boot开发的微服务的集合，Spring Cloud用于提供微服务之间调用、微服务的配置获取、服务注册、路由等。</p>
<h3 id="负载均衡">负载均衡</h3>
<p>某个服务可能有多个实例，调用该服务时，每个请求会分发到不同的实例处理，有助于提高服务的吞吐量。</p>
<h3 id="Feign">Feign</h3>
<p>Feign是一个HTTP请求客户端，提供了声明式的调用方式。主要是通过JDK动态代理实现。它整合了负载均衡的能力（Spring Cloud LoadBalance）</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>面试笔记-数据库</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<h2 id="知识点">知识点</h2>
<h3 id="三范式">三范式</h3>
<p>第一范式：列不可再分；</p>
<p>第二范式：表中的每一行都可以唯一区分，通过主键实现；</p>
<p>第三范式：（用于避免数据冗余，减少内存占用，实践中常被忽视）表的非主键字段不能依赖于其他非主键字段；比如学生表，里边有班级名称字段和辅导员名称字段，那么班级和辅导员会大量重复，应当拆分出班级表和辅导员表。</p>
<h3 id="MySQL的存储引擎">MySQL的存储引擎</h3>
<p>MyISAM、InnoDB、Memory</p>
<p>MyISAM：全表锁，没有事务和外键，单表执行性能高，并发性能差，空间占用小。</p>
<p>InnoDB：行锁，有事务，支持自增序列，支持外键，并发性能高，空间占用大。</p>
<p>Memory：纯内存。</p>
<h3 id="InnoDB和MyISAM">InnoDB和MyISAM</h3>
<p>InnoDB支持事务，默认是每一条SQL都封装为一个事务。MyISAM没有事务。</p>
<p>InnoDB有外键，MyISAM没有。</p>
<p>InnoDB是行锁，MyISAM是表锁，InnoDB并发场景性能会好一些。</p>
<p>InnoDB是聚集索引，必须有主键。在表上建立的其他索引，都是指向主键。通过其他索引查询时，先经过索引查到主键，再通过主键查找数据。MyISAM是非聚集索引，主键和索引都是直接指向数据指针，主键和索引相互独立。</p>
<p>InnoDB不保存表的行数，计算行数时要全表扫描。MyISAM保存了表的行数。</p>
<h3 id="数据库事务">数据库事务</h3>
<p>ACID：atomic、consistency、isolation、durability</p>
<p>原子性：一个事务内的多个操作可以看成一个原子操作，即要么成功要么失败。事务中任意一个操作失败了都会回滚到没有开始事务之前的状态。</p>
<p>一致性：事务操作的结果和业务规则是一致的。即事务成功时，可以达成操作者目的。</p>
<p>隔离性：多个事务之间互相数据隔离，彼此没有影响。</p>
<p>持久性：事务完成后会持久化到数据库。</p>
<h3 id="索引是什么">索引是什么</h3>
<p>官方：一种帮助MySQL快速获取数据的数据结构。</p>
<p>类似目录，默认是B+树实现。</p>
<h3 id="索引的优缺点">索引的优缺点</h3>
<p>优点：提升查询速度。</p>
<p>缺点：索引也有空间占用，更新速度变慢，因为表更新的时候索引也要更新。</p>
<h3 id="SQL优化">SQL优化</h3>
<p>原则：避免全表扫描，查询时尽量走索引。少于三张表的查询允许关联，关联不了就走子查询。</p>
<p>1、尽量不要用select *</p>
<p>2、减少子查询，用少于三张表的关联查询替代</p>
<p>3、少用in和not in，因为绝对可以用exists和not exists替代</p>
<p>4、where子句中慎用!=，走不到索引</p>
<p>5、少用or，走不到索引</p>
<p>6、少用null判断，走不到索引</p>
<h3 id="drop、delete和truncate">drop、delete和truncate</h3>
<p>drop和truncate不能回滚，不在事务中。delete是在事务中，提交时才生效。</p>
<p>drop删的最多，会删表结构，可以重新建同名表，及时生效不在事务中。</p>
<p>truncate其次，对比drop是少删表结构，仅删除数据，还是不在事务中。</p>
<p>delete再次，仅删除表数据，会在事务中，事务提交后才生效。</p>
<h3 id="视图">视图</h3>
<p>理解为虚拟表。类似函数封装的概念。</p>
<p>可以封装复杂查询的结果。</p>
<p>可以用来做权限隔离，比如仅展示某几个字段给特定用户。</p>
<p>底层表有改动，比如拆分了，可以建一个视图，避免上层应用修改SQL。</p>
<h3 id="并发事务的问题">并发事务的问题</h3>
<p>脏读：一个事务读到了另一个事务修改了但未提交的数据。</p>
<p>修改丢失：两个事务同时修改了同一个值，后一个覆盖了前一个。比如两个事务同时做x-1，先读x再减一，并发之后可能结果是x-1而不是x-2。</p>
<p>不可重复读：一个事务未结束时，读到了另一个事务B修改了并提交的最新值。</p>
<p>幻读：一个事务查询一批数据的过程中，这批数据被另一个事务新增或删除了一些数据（比如新增了几条数据），于是查询到了新的数据。</p>
<p>不可重复读重点在修改，幻读重点在新增或删除。重点在行锁和表锁区别。</p>
<h3 id="事务隔离级别">事务隔离级别</h3>
<p>MySQL的InnoDB默认是可重复读</p>
<p>读未提交：脏读，不可重复读，幻读</p>
<p>读已提交：不可重复读，幻读</p>
<p>可重复读：幻读（解决了单行的修改，但没解决表级别的增删）</p>
<p>串行化：事务逐个执行，库锁</p>
<p>大部分数据库是读已提交级别的事务（比如postgre）。</p>
<p>mysql额外用了next key Lock，用行锁和间隙锁在可重复读的场景下避免了幻读。具体做法就是，锁了一行数据的前一条和后一条中间的范围。比如5、10、15三条数据，当10被事务读的时候，如果有一个事务插入一条数据8，则会触发间隙锁，插入8的事务会阻塞。这里和聚簇索引也有关系。</p>
<h3 id="大表优化">大表优化</h3>
<p>方向：单体变分布式-拆，限制结果数量</p>
<p>1、查询时限制范围，分页</p>
<p>2、读写分离，拆到多个机器上</p>
<p>3、垂直拆分，把字段拆到不同的表中</p>
<p>4、水平拆分，根据某些逻辑把数据分到不同的片区。比如地区信息做异地多活。</p>
<h3 id="分库分表后的ID处理">分库分表后的ID处理</h3>
<p>可转化为全局唯一ID问题：与消息中间件的消息防丢差不多。</p>
<p>uuid、雪花、美团的leaf。</p>
<h3 id="MySQL的一条查询SQL执行过程">MySQL的一条查询SQL执行过程</h3>
<p>8.0没有查询缓存。</p>
<p>1、语法分析：包括解析SQL语法的正确性，涉及到的表和字段是否存在</p>
<p>2、准备阶段：会对查询进行逻辑优化，比如选择索引，去除不必要的子查询之类的。逻辑优化后还有物理优化，会根据统计信息和成本计算模型来确定具体的执行计划</p>
<p>3、执行查询：由执行引擎和存储引擎交互产出查询结果</p>
<p>4、结果返回：去重排序之类的处理，最终结果返回给客户端</p>
<h3 id="varchar和char的区别">varchar和char的区别</h3>
<p>varchar可变长度，char不可变，定长。</p>
<p>比如varchar(30)的字段存一个字节长度为3的字符，实际空间占用可能为5或者6字节左右，因为有一定的空间用于存储其字段长度。</p>
<p>char(30)的字段存同样的字符，那么固定占用30字节，后面空的会补零。</p>
<p>char读写快，空间占用大。varchar省空间，读写慢。</p>
<h3 id="int-11-的11含义">int(11)的11含义</h3>
<p>不影响字段的存储范围，仅影响查询的展示效果。</p>
<h3 id="MySQL的索引类型">MySQL的索引类型</h3>
<p>主键索引：必须唯一，不可为空</p>
<p>普通索引：允许重复和空</p>
<p>唯一索引：值必须唯一，可以为空</p>
<p>全文索引：只能在文本字段创建，用于加速like查询</p>
<p>空间索引</p>
<p>前缀索引</p>
<p>单列和组合索引：最左匹配原则，优先用组合索引</p>
<h3 id="什么场景不适合索引">什么场景不适合索引</h3>
<p>1、经常更新的列</p>
<p>2、内容大量重复的列</p>
<p>3、表记录太少（不清楚具体是多少）</p>
<p>4、写远大于读的表</p>
<h3 id="MVCC">MVCC</h3>
<p>多版本并发控制。用来解决读写冲突，是无锁并发。事务分配事务号（单向递增），每个修改保存一个版本。读只读老版本的数据，修改在新版本。可以同时避免脏读和不可重复读。</p>
<p>实现：</p>
<p>1、每行数据有一个版本链</p>
<p>2、事务id，单调递增</p>
<p>3、可见性判断，根据事务级别来判断是否可见</p>
<p>4、过期数据清理</p>
<p>级别和判断逻辑：</p>
<p>读已提交：单行数据版本号小于当前事务版本号，并且此事务已提交，则可以看到</p>
<p>可重复读：创建一致性视图，包含事务开始时所有可读的事务号。</p>
<p>缺点，做不到串行化执行，在解决写冲突的时候还是要用锁或者重做</p>
<h3 id="MySQL锁">MySQL锁</h3>
<p>读锁和写锁（共享和排他）。</p>
<p>按照粒度，可以划分为表锁和行锁。MyISAM是表级别的读写锁，InnoDB支持行锁。</p>
<h3 id="锁升级">锁升级</h3>
<p>行锁只能在索引上，没索引自动升级成表锁。</p>
<p>没走索引时也会升级成表锁。比如非唯一索引相同的内容超过表的一半，优化器会选择不走索引。</p>
<h3 id="乐观锁和悲观锁">乐观锁和悲观锁</h3>
<p>悲观锁：倾向于一行数据总是会被同时修改，所以修改前加上排他锁</p>
<p>乐观锁：倾向于一行数据不一定会被同时修改。加上版本号，类似MVCC，修改前读取版本号，修改后版本号+1，在更新版本号时做版本号检查，如果版本号和预期不符，说明此时有其他人修改了数据，否则就直接更新。乐观锁一般配合自旋，形成一个类似CAS的操作。</p>
<h3 id="避免死锁">避免死锁</h3>
<p>获取锁一定要加超时时间；</p>
<p>按照固定顺序获取资源；</p>
<p>事务尽量简短；</p>
<p>事务隔离级别低一些；</p>
<p>避免事务中的用户交叉；</p>
<h3 id="索引注意事项">索引注意事项</h3>
<p>1、where中使用!=、&lt;&gt;、or会导致放弃使用索引</p>
<p>2、符合索引要复合最左前缀原则</p>
<p>3、where中进行字段表达式运算、函数运算可能导致索引失效</p>
<p>4、Like使用是%不能在前，模糊匹配可以用全文索引</p>
<p>5、字段是字符串类型，必须加引号，否则索引失效</p>
<h3 id="主键-索引">主键 索引</h3>
<p>主键是唯一索引，唯一索引不一定是主键</p>
<p>主键不允许空，唯一索引可以为空</p>
<p>一个表只能有一个主键，但可以有多个唯一索引</p>
<p>主键是约束，而唯一索引是冗余的数据结构</p>
<h3 id="MySQL的高可用">MySQL的高可用</h3>
<p>MySQL分库分表。</p>
<p>意义不是很大，一般是整个系统都做高可用。</p>
<h2 id="总结">总结</h2>
<p>MySQL的MVCC机制是一个非常标准的实现，可以和我之前做的缓存框架结合起来，很多道理都是共通的。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>JNI调用的优化</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/JNI%E8%B0%83%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="传统的优化方式">传统的优化方式</h2>
<p>首先，我这里给出JNI的官方手册：<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/jniTOC.html">https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/jniTOC.html</a></p>
<p>Java本身已经提供了相当数量的接口用于JNI开发，一般来说是够用了。但在低时延或频繁调用的场景，JNI层的性能损耗还是不能忽视的。</p>
<p>在传统的优化方式中，最常提到的就是缓存方法ID、字段ID和类。通过<code>GetFieldID</code>或<code>GetMethodID</code>获取到的指针（或者说句柄），在JVM的全生命周期都是可用的，因此完全可以把它们缓存起来。每次调用时如果都去获取一遍，会有相当大的性能损耗。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int sumValues2(JNIEnv∗ env, jobject obj, jobject allValues)&#123;</span><br><span class="line">   // 这些都可以缓存</span><br><span class="line">   jclass cls = (∗env)‑&gt;GetObjectClass(env,allValues);</span><br><span class="line">   jfieldID a = (∗env)‑&gt;GetFieldID(env, cls, &quot;a&quot;, &quot;I&quot;);</span><br><span class="line">   jfieldID b = (∗env)‑&gt;GetFieldID(env, cls, &quot;b&quot;, &quot;I&quot;);</span><br><span class="line">   jfieldID c = (∗env)‑&gt;GetFieldID(env, cls, &quot;c&quot;, &quot;I&quot;);</span><br><span class="line">   jfieldID d = (∗env)‑&gt;GetFieldID(env, cls, &quot;d&quot;, &quot;I&quot;);</span><br><span class="line">   jfieldID e = (∗env)‑&gt;GetFieldID(env, cls, &quot;e&quot;, &quot;I&quot;);</span><br><span class="line">   jfieldID f = (∗env)‑&gt;GetFieldID(env, cls, &quot;f&quot;, &quot;I&quot;);</span><br><span class="line">   // 调用时如果是通过缓存的句柄来调用，就不用每次都get一遍句柄，可以大大提升性能</span><br><span class="line">   jint avalue = (∗env)‑&gt;GetIntField(env, allValues, a);</span><br><span class="line">   jint bvalue = (∗env)‑&gt;GetIntField(env, allValues, b);</span><br><span class="line">   jint cvalue = (∗env)‑&gt;GetIntField(env, allValues, c);</span><br><span class="line">   jint dvalue = (∗env)‑&gt;GetIntField(env, allValues, d);</span><br><span class="line">   jint evalue = (∗env)‑&gt;GetIntField(env, allValues, e);</span><br><span class="line">   jint fvalue = (∗env)‑&gt;GetIntField(env, allValues, f);</span><br><span class="line">   return avalue + bvalue + cvalue + dvalue + evalue + fvalue</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至于其他的方式，基本没有像缓存句柄这样显著的提升了。这些优化方式可以在百度中搜索IBM+最佳实践的关键字找到。原文链接的话在这：<a href="https://developer.ibm.com/articles/j-jni/">https://developer.ibm.com/articles/j-jni/</a></p>
<h2 id="新的优化方式">新的优化方式</h2>
<p>上述的文章是2009年发表，至今（2023年）已经过去了14年。时代在进步，经过这么多年的实践和探索，在性能调优这方面，大家有了新的思路和手段。</p>
<p>这里我不得不提一句，FastJSON2给了我很大的帮助，在阅读其源码的过程中，我也尝试着把它的一些优秀实现迁移到我的工作项目中来。</p>
<h3 id="使用Unsafe构建结构体">使用Unsafe构建结构体</h3>
<p>某些情况下，可以通过构建结构体来与JNI层通讯。需要强调的是，这种操作在大部分时候都不会有很好的效果。</p>
<p>只有少数场合——尤其是想复用一个已经存在的C++程序的能力时，才可能有些用处。</p>
<p>通过构建结构体，最大的好处是，使得JNI接口可以传递指针了。</p>
<p>举例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 查询</span><br><span class="line"> *</span><br><span class="line"> * @param record      结构体指针</span><br><span class="line"> * @return 查询结果</span><br><span class="line"> */</span><br><span class="line">public native long select(long record);</span><br></pre></td></tr></table></figure>
<p>上面这个接口，我们通过传递了一个结构体指针。</p>
<p>查询条件我们写到这个结构体里，C++拿着结构体中的条件数据去查询，查完了再把结果写到原来的结构体内，最后Java解析这个结构体，封装为Java对象传回上层。</p>
<p>上面这事说起来简单，但其实已经经过了Java对象到结构体，结构体再转回Java对象的序列化和反序列化两个处理。</p>
<p>通过传递指针，可以让C++的JNI这一层变得非常简单，很多时候都是透传，直接去调用原生的接口了。</p>
<p>实际写代码的时候，这部分逻辑会变得相当抽象，下面给个示例的硬编码代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">long pointer = UNSAFE.allocateMemory(32);</span><br><span class="line">// pointer是内存块的起始地址</span><br><span class="line">long offset = pointer;</span><br><span class="line">// 正常模式、备用模式(只读方式) 4</span><br><span class="line">UNSAFE.putInt(offset, instance.getRunType());</span><br><span class="line">offset += 4;</span><br><span class="line">// 补齐 8</span><br><span class="line">offset += 4;</span><br><span class="line">// 内存数据库大小 16</span><br><span class="line">UNSAFE.putLong(offset, instance.getDbSize());</span><br><span class="line">offset += 8;</span><br><span class="line">// 内存数据库事务日志大小 24</span><br><span class="line">UNSAFE.putLong(offset, instance.getRedoLogSize());</span><br><span class="line">offset += 8;</span><br><span class="line">// 内存数据库事务日志文件数量 28</span><br><span class="line">UNSAFE.putInt(offset, instance.getRedoLogNum());</span><br><span class="line">offset += 4;</span><br><span class="line">// 补齐 32</span><br><span class="line">offset += 4;</span><br></pre></td></tr></table></figure>
<p>还得考虑内存对齐，编码体验确实不太好，但确实性能上是满足了现在的需求。</p>
<p>基于这种逻辑，我实现了一种通用的结构体创建方式，但是很遗憾由于保密协议我不能在此分享。</p>
<p>性能上来说：硬编码&gt;通用。</p>
<p>因为内存数据库存储的数据行是由Java对象转换过来的，所以必须有一种通用的结构体转换方式，这写的时候还是废了我不少功夫的。</p>
<h3 id="字符串序列化优化">字符串序列化优化</h3>
<p>正常在JNI层，如果需要使用Java传递的字符串，我们会使用以下的方式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;jni.h&gt;</span><br><span class="line">#include &lt;string&gt;</span><br><span class="line"></span><br><span class="line">extern &quot;C&quot; JNIEXPORT void JNICALL</span><br><span class="line">Java_MyJNIClass_nativeDoSomething(JNIEnv *env, jobject obj, jstring str) &#123;</span><br><span class="line">    const char *data = env-&gt;GetStringUTFChars(str, NULL);</span><br><span class="line">    // 使用data处理Java字符串</span><br><span class="line">    // ...</span><br><span class="line">    env-&gt;ReleaseStringUTFChars(str, data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>实际测试之后，发现这个GetStringUTFChars方法还是有些性能损耗的。</p>
<p>那么，有没有办法避免这种字符串转码的性能损耗呢？答案是肯定的。</p>
<p>还是利用Unsafe的能力，我们在Java中可以做到内存拷贝。</p>
<p>通过直接把String中的char数组内存拷贝到一个固定的内存块上，我们就可以避免序列化，直接把数据传递给了JNI层。</p>
<p>甚至，如果可以保证JNI层不会修改字符串的数据，我们可以再次优化，直接将char数组的指针传给C++程序。</p>
<p>以下是代码示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">   * 存入字符串</span><br><span class="line">   *</span><br><span class="line">   * @param pointer 指针</span><br><span class="line">   * @param size    长度</span><br><span class="line">   * @param value  字符串</span><br><span class="line">   */</span><br><span class="line">  public static void putString(long pointer, long size, String value) &#123;</span><br><span class="line">      // size必须为偶数</span><br><span class="line">      char[] valueChars = StringOptimizer.getCharArray(value);</span><br><span class="line">      long length = (long) valueChars.length &lt;&lt; 1;</span><br><span class="line">      if (length &gt; size) &#123;</span><br><span class="line">          UNSAFE.copyMemory(valueChars, Unsafe.ARRAY_CHAR_BASE_OFFSET, null, pointer, size);</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">          char[] chars = new char[(int) size &gt;&gt; 1];</span><br><span class="line">          System.arraycopy(valueChars, 0, chars, 0, valueChars.length);</span><br><span class="line">          UNSAFE.copyMemory(chars, Unsafe.ARRAY_CHAR_BASE_OFFSET, null, pointer, size);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>解释一下，StringOptimizer是一个工具类，使用Unsafe类去直接获取字符串中的char数组。由于java9对String字符串有重写，需要在启动时就进行判断jdk版本，不同版本会有不同的实现。为了方便使用，这里单独抽了一个工具类出来。</p>
<p>另外，由于Unsafe工具类申请的内存可能含有脏数据，需要申请者手动置0或者覆盖。由于字符串的长度可能小于申请的内存块，所以先拷贝到一个长度与内存块相同的char数组中，再把这个char数据内存拷贝到内存块中，这样就避免了手动置0的操作。</p>
<p>字符串在Java中的使用实在是过于频繁了，毕竟好用嘛。在C++中字符串用起来比Java要麻烦很多，这也导致在JNI优化的时候，字符串不得不单独拎出来优化。</p>
<h2 id="总结">总结</h2>
<p>在特定场景下，使用Unsafe能显著提高Java程序与C++的交互性能。</p>
<p>但我觉得更重要的是，使用Unsafe使得Java具有了直接去操作内存的能力，这就解放了JNI调用的束缚，可以直接通过指针的方式来交互。这在异构系统的层次划分和接口设计上是会有相当大的影响的。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title>面试笔记-网络协议</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/</url>
    <content><![CDATA[<h3 id="HTTP响应码">HTTP响应码</h3>
<p>200 - 成功</p>
<p>301 - 永久重定向    302 - 临时重定向</p>
<p>4开头是客户端问题</p>
<p>400 - 客户端请求有问题  404 - 找不到对应资源，url错了</p>
<p>5开头是服务器问题</p>
<p>500 - 服务器崩了  504 - badgateway</p>
<h3 id="Forward和Redirect">Forward和Redirect</h3>
<p>Forward是服务器把请求转发给其他服务器或应用处理，处理完原路返回给客户端</p>
<p>Redirect是服务器直接返回指令，让客户端重新请求其他服务器 （去买牛肉，到店了发现店面贴着告示，说牛肉店搬到另一条街了，所以要去新的地址买）</p>
<h3 id="GET和POST">GET和POST</h3>
<p>用途不同，GET用来获取资源，POST用来提交数据，体现在浏览器的标签只能收藏GET请求，不能收藏POST请求</p>
<p>参数：GET一般把参数直接拼在URL，POST在消息头或消息体</p>
<p>编码：GET和URL一致，POST无所谓，编码按照约定来</p>
<h3 id="TCP和UDP">TCP和UDP</h3>
<p>TCP先建立连接才能通讯，可靠，传输性能一般</p>
<p>UDP无连接，不可靠，传输性能高</p>
<p>TCP是点对点，UDP支持广播</p>
<p>但UDP也不是绝对不可靠，HTTP3的底层换成了QUIC协议，是基于UDP实现的</p>
<h3 id="HTTP和HTTPS">HTTP和HTTPS</h3>
<p>HTTP用80端口，HTTPS用443</p>
<p>HTTPS多了加密，有性能开销，且加密证书需要额外购买</p>
<h3 id="HTTP、TCP和Socket">HTTP、TCP和Socket</h3>
<p>Socket是网络协议的API，由应用层的程序或编程语言提供</p>
<p>用Socket可以实现一个HTTP协议的客户端或服务端</p>
<p>HTTP是应用层的协议，基于TCP来实现</p>
<p>TCP是网络层协议</p>
<h3 id="HTTP的长连接和短连接">HTTP的长连接和短连接</h3>
<p>本质是TCP的长连接和短连接。消息头里有个字段是keep-alive，如果为true，则一次请求后之前建立的TCP连接还会保留，不会进行四次挥手，下次再有请求就复用这个连接。</p>
<p>在同一个客户端会有大量访问的情况下能提升性能，但是对服务器的连接数有要求。所以有了NIO，比如Netty，能支持大量的客户端连接。</p>
<p>保持长连接的时间由服务端进行控制。tomcat有配置。</p>
<h3 id="TCP三次握手">TCP三次握手</h3>
<p>服务端在某个端口开启监听，客户端通过ip+port向服务器发起连接请求。</p>
<p>第一次：客户端-&gt;服务端，syn=1，seq=x</p>
<p>第二次：服务端-&gt;客户端，syn=1，seq=y，ack=x+1。第二次表示客户端到服务端的链路已经通了，这时候要验证服务端到客户端的链路是否通。</p>
<p>第三次：客户端-&gt;服务端，seq=x+1, ack=y+1。告知服务端，你发送的消息我也能收到。</p>
<p>为什么要三次：因为是双工通讯，要确认消息序号的起始值。</p>
<h3 id="TCP四次挥手">TCP四次挥手</h3>
<p>主动断开的一方，发送FIN，告知不再发送消息；对端接收到，返回ack；</p>
<p>此时对端还可以发送消息，因为对端可能还有消息没传完。</p>
<p>对端传完之后对端发送FIN，告知不再发送消息；主动断开的一方返回ack，连接彻底断开。</p>
<h3 id="TCP粘包">TCP粘包</h3>
<p>本质是因为TCP是传输字节流，字节流是没有边界概念的。</p>
<p>包的概念是怎么来的？字节流实际在TCP传输的过程中是会分成多个数据包依次传输，这里的数据包切割方式和上层应用无关，因此这些数据包很可能和上层应用的协议包对不上。比如上层应用发了两个请求，但是底层会划分为3个数据包来传输。</p>
<p>TCP的分包是由滑动窗口来控制的。</p>
<p>解决方式，都是在应用的协议层解决：</p>
<p>1、最常用，在协议包里定义协议头，协议头是固定格式的，在协议头里再定义一个协议体长度的变量。HTTP等协议都是如此。</p>
<p>2、把协议固定长度，所有协议包的长度都一致。</p>
<p>3、特殊分隔符号。</p>
<h3 id="TCP可靠性">TCP可靠性</h3>
<p>最重要的就是序列号和确认号（ack）：包里带seq，接收端检测包的完整性，完整则返回ack。</p>
<p>超时重传：发送端发了包以后开始计时，如果一定时间内没收到ack，则重传。</p>
<p>重排序：多个数据包在传输过程中可能乱序，tcp收到后对数据包重排序，保证上层读取的字节流是和发送端传的一致。</p>
<p>丢弃重复包：比如超时重传等情况会造成重复包，tcp会丢弃这些重复的。</p>
<p>流量控制：滑动窗口来控制流量，避免发送过快接收端无法处理。（行情客户端遇到过）</p>
<h3 id="OSI七层模型">OSI七层模型</h3>
<p>应用层：HTTP、FTP</p>
<p>表示层：加解密</p>
<p>会话层：RPC</p>
<p>传输层：TCP、UDP</p>
<p>网络层：IP、IPv6</p>
<p>数据链路层：物理寻址层。交换机等</p>
<p>物理层：硬件</p>
<p>各种RPC框架一般是涵盖了会话层以下的所有能力，业务框架可能还会涵盖表示层。</p>
<h3 id="浏览器输入一个网址后发生了什么">浏览器输入一个网址后发生了什么</h3>
<p>1、域名-&gt;IP的转换，会经过浏览器缓存、系统缓存、hosts配置文件、路由器缓存，搜索域名对应的服务器。</p>
<p>2、建立TCP连接</p>
<p>3、发送HTTP的GET请求</p>
<p>4、请求经过路由器转发到服务器</p>
<p>5、服务器处理请求，返回网页文件（HTML）</p>
<p>6、浏览器渲染html（渲染过程中执行了js，可能产生新的HTTP请求）</p>
<h3 id="如何跨域">如何跨域</h3>
<p>浏览器执行js的时候，如果产生新的HTTP请求，且新的请求和当前网址不一致，则发生了跨域，会被拒绝。</p>
<p>CORS可以，但是需要服务器和浏览器都支持才行。</p>
<p>使用NGINX反向代理，浏览器不用做任何支持，更合适。原理也是CORS，只是在nginx这一层改了请求。</p>
<h3 id="HTTP-1-0-1-1-2-0-3-0">HTTP 1.0 1.1 2.0 3.0</h3>
<p>1.0是无状态无连接，也就是每次请求都建立一次tcp连接。</p>
<p>1.1添加了connection:keep-alive，可以建立长连接。但是要求服务器必须对应所有请求的顺序返回响应。</p>
<p>2.0 添加了数据流，gRPC有使用。服务器可以并行传输数据，因为每个流有自己的streamid和序号。但所有流用的是一个TCP连接。</p>
<p>2.0 还做了头部压缩，通过让服务器和客户端都缓存请求头的field表来实现。</p>
<p>3.0 底层使用QUIC，不再使用TCP，QUIC是基于UDP实现的。在UDP上实现了TCP的可靠传输能力。</p>
<h3 id="HTTP与TCP-IP">HTTP与TCP/IP</h3>
<p>HTTP是应用层的报文协议，一般数据传输是用TCP/IP实现。</p>
<p>TCP传输的是字节流，没有对包的格式做要求。在此基础上，HTTP定义了请求包的格式。</p>
<p>理论上可以把HTTP的包用其他传输协议来发送。</p>
<h3 id="HTTP长连接短连接">HTTP长连接短连接</h3>
<p>本质是TCP的长连接和短连接。HTTP的1.1定义了Connection:keep-alive的请求头字段，避免每次请求都要三次握手和四次挥手。</p>
<h3 id="长连接和短连接的优缺点">长连接和短连接的优缺点</h3>
<p>长连接对于活跃的客户端，能减少连接和断连的成本。但是客户端一多，服务器资源比较浪费，可以用NIO来避免这个问题，一个线程处理多个TCP连接。</p>
<p>短连接对服务端的管理比较简单，但是qps上去之后在连接和断连上会浪费很多时间和带宽。</p>
<h3 id="域名解析过程">域名解析过程</h3>
<p>从开销最小的地方开始找，没有就去更远的地方找。</p>
<p>1、本机：浏览器缓存、操作系统缓存、hosts文件，</p>
<p>2、本地配置的DNS服务器，可能是学校、企业的，如果缓存中有，直接返回。</p>
<p>3、本地配置的DNS服务器没有，则其会向更高的根域名服务器查询，获得对应的权威域名服务器地址，然后再请求权威域名服务器获得IP。获得IP后，本地的DNS服务器会返回给本机，并缓存该域名，下一次再查询就直接从本地的DNS服务器可以查到。</p>
<p>4、浏览器、操作系统也可能会缓存这个域名。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>JNI调用的优化（第二版)</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/JNI%E8%B0%83%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88/</url>
    <content><![CDATA[<p>源头是这篇博客：<a href="http://blog.hakugyokurou.net/?p=1758">http://blog.hakugyokurou.net/?p=1758</a></p>
<p>讲到了最正式的文档也就是bug系统中的一条记录：<a href="https://bugs.openjdk.org/browse/JDK-7013347">https://bugs.openjdk.org/browse/JDK-7013347</a></p>
<p>另外在stackoverflow上有人爆料了这个能力：<a href="https://stackoverflow.com/questions/36298111/is-it-possible-to-use-sun-misc-unsafe-to-call-c-functions-without-jni/36309652#36309652">https://stackoverflow.com/questions/36298111/is-it-possible-to-use-sun-misc-unsafe-to-call-c-functions-without-jni/36309652#36309652</a></p>
<p>处于验证的目的，我写了jmh对其进行测试。</p>
<p>不过测试结果倒是有提升，但也仅仅是20ns。</p>
<p>聊胜于无，就目前的场景（单次调用800ns）来看，并没有必要做这个优化。</p>
<p>带来的不稳定因素反而是更大的问题。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title>Java反射调用的优化</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/Java%E5%8F%8D%E5%B0%84%E8%B0%83%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="场景">场景</h2>
<p>在公司内部的缓存框架中，需要实现类似数据库的能力：比如主键、索引，还有条件查询等。</p>
<p>这些能力不可避免的需要从一个对象中，通过反射的方式来取参数的值。且目前没有办法通过定义接口的方式来优化。</p>
<h2 id="实现">实现</h2>
<p>以前的方式大多是建立Method对象的缓存，但是在查阅资料之后，我使用了一个新的方式。</p>
<p>这里我先给出一个原本的实现:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  private static final Map&lt;String, Method&gt; methodsCache = new ConcurrentHashMap&lt;&gt;(256);</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">   * 获取Object对象中指定属性的值。</span><br><span class="line">   * @param instance instance</span><br><span class="line">   * @param fieldName fieldName</span><br><span class="line">   * @return Object</span><br><span class="line">   */</span><br><span class="line">  public static Object getFieldValue(Class&lt;?&gt; clazz, Object instance, String fieldName) &#123;</span><br><span class="line">      Method method = findMethod(clazz, fieldName);</span><br><span class="line">      if (!Objects.isNull(method)) &#123;</span><br><span class="line">          try &#123;</span><br><span class="line">              return method.invoke(instance);</span><br><span class="line">          &#125; catch (IllegalAccessException | InvocationTargetException e) &#123;</span><br><span class="line">              throw new RuntimeException(e);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      return null;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  private static Method findMethod(Class&lt;?&gt; clazz, String fieldName) &#123;</span><br><span class="line">      String methodName = &quot;get&quot; + changeFirstCharacterCase(fieldName, true);</span><br><span class="line">      // 优先从缓存获取</span><br><span class="line">      Method method = methodsCache.get(clazz.getName() + &quot;#&quot; + methodName);</span><br><span class="line">      if (!Objects.isNull(method)) &#123;</span><br><span class="line">          return method;</span><br><span class="line">      &#125;</span><br><span class="line">      // 缓存中未找到，从clazz中获取</span><br><span class="line">      try &#123;</span><br><span class="line">          method =  clazz.getMethod(methodName);</span><br><span class="line">          methodsCache.put(clazz.getName() + &quot;#&quot; + methodName, method);</span><br><span class="line">          return method;</span><br><span class="line">      &#125; catch (NoSuchMethodException e) &#123;</span><br><span class="line">          logger.error(&quot;在&#123;&#125;中未找到名为&#123;&#125;的方法名。&quot;, clazz.getName(), methodName);</span><br><span class="line">      &#125; catch (Exception e) &#123;</span><br><span class="line">          logger.error(e.getMessage(), e);</span><br><span class="line">      &#125;</span><br><span class="line">      return null;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这逻辑不难理解，缓存了Method对象，避免每次都要进行查找。一般来说这可以很大程度的提升性能。</p>
<p>不过我随后进行了jmh的测试，发现了一些问题。</p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Mode</th>
<th>Cnt</th>
<th>Score</th>
<th>Score</th>
<th>Units</th>
</tr>
</thead>
<tbody>
<tr>
<td>testNormal</td>
<td>avgt</td>
<td>10</td>
<td>0.338</td>
<td>±   0.003</td>
<td>ns/op</td>
</tr>
<tr>
<td>testRef</td>
<td>avgt</td>
<td>10</td>
<td>4.423</td>
<td>±   0.174</td>
<td>ns/op</td>
</tr>
<tr>
<td>testRefBuild</td>
<td>avgt</td>
<td>10</td>
<td>181.405</td>
<td>±  21.063</td>
<td>ns/op</td>
</tr>
</tbody>
</table>
<p>表格中，第一行数据是通过get方法取值；第二行是通过从缓存中获取Method然后调用取值；第三行是构建Method方法并取值。</p>
<p>不难看出：哪怕是通过缓存的方式来取值，也会导致性能下降大约十倍。</p>
<p>在查阅资料时，我发现了这篇文章：</p>
<p>这里提供了一个思路：通过LambdaMetafactory构建lambda表达式，在构建的lambda表达式中调用对应的方法。</p>
<p>最后的实现如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 对象访问器</span><br><span class="line"> *</span><br><span class="line"> * @author daizheli</span><br><span class="line"> * @since 4.2.0 2023/4/13 </span><br><span class="line"> */</span><br><span class="line">public class ObjGetter &#123;</span><br><span class="line"></span><br><span class="line">    private final Function getterFunction;</span><br><span class="line"></span><br><span class="line">    public ObjGetter(Method method) &#123;</span><br><span class="line">        MethodHandles.Lookup lookup = MethodHandles.lookup();</span><br><span class="line">        try &#123;</span><br><span class="line">            MethodHandle methodHandle = lookup.unreflect(method);</span><br><span class="line">            CallSite site = LambdaMetafactory.metafactory(lookup, &quot;apply&quot;, MethodType.methodType(Function.class),</span><br><span class="line">                MethodType.methodType(Object.class, Object.class), methodHandle, methodHandle.type());</span><br><span class="line">            getterFunction = (Function) site.getTarget().invokeExact();</span><br><span class="line">        &#125; catch (Throwable e) &#123;</span><br><span class="line">            throw new RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public Object executeGetter(Object bean) &#123;</span><br><span class="line">        return getterFunction.apply(bean);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 对象设置器</span><br><span class="line"> *</span><br><span class="line"> * @author daizheli</span><br><span class="line"> * @since 4.2.0 2023/4/13 </span><br><span class="line"> */</span><br><span class="line">public class ObjSetter &#123;</span><br><span class="line"></span><br><span class="line">    private final BiConsumer function;</span><br><span class="line"></span><br><span class="line">    public ObjSetter(Method method) &#123;</span><br><span class="line">        MethodHandles.Lookup lookup = MethodHandles.lookup();</span><br><span class="line">        try &#123;</span><br><span class="line">            MethodHandle methodHandle = lookup.unreflect(method);</span><br><span class="line">            CallSite site = LambdaMetafactory.metafactory(lookup, &quot;accept&quot;, MethodType.methodType(BiConsumer.class),</span><br><span class="line">                MethodType.methodType(void.class, Object.class, Object.class), methodHandle, methodHandle.type());</span><br><span class="line">            function = (BiConsumer) site.getTarget().invokeExact();</span><br><span class="line">        &#125; catch (Throwable e) &#123;</span><br><span class="line">            throw new RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void executeSetter(Object bean, Object value) &#123;</span><br><span class="line">        function.accept(bean, value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>也跑了一下jmh，测试结果是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Benchmark                           Mode  Cnt      Score     Error  Units</span><br><span class="line">ObjGetterBatchTest.testLambda       avgt   10      0.692 ±   0.037  ns/op</span><br><span class="line">ObjGetterBatchTest.testLambdaBuild  avgt   10  25439.081 ± 956.824  ns/op</span><br><span class="line">ObjGetterBatchTest.testNormal       avgt   10      0.338 ±   0.003  ns/op</span><br><span class="line">ObjGetterBatchTest.testRef          avgt   10      4.423 ±   0.174  ns/op</span><br><span class="line">ObjGetterBatchTest.testRefBuild     avgt   10    181.405 ±  21.063  ns/op</span><br></pre></td></tr></table></figure>
<p>构建的速度有明显下降，但是每次调用的速度也有明显的提升。</p>
<p>在我们内部的场景下，会有启动时从数据库加载数据创建索引的步骤，因此启动时就会构建好这部分缓存，从而提高运行时的速度。</p>
<h2 id="总结">总结</h2>
<p>每次反射都去查询Method是不可接受的。在缓存的基础上，通过MethodHandles其实可以提高一部分调用的性能。</p>
<p>但是综合考虑之后，还是使用LambdaMetafactory在运行时构建lambda表达式更适合当前的场景。</p>
<p>可惜的是LambdaMetafactory的案例和解析在中文网站上几乎找不到，哪怕是英文资料也很少。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty的FastThreadLocal带来了什么？</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/Netty%E7%9A%84FastThreadLocal%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/</url>
    <content><![CDATA[<h2 id="和Netty的缘分">和Netty的缘分</h2>
<p>要聊能力前，先聊聊我和Netty的缘分。</p>
<p>最初接触Netty，是在一个和它完全不相关的项目。需求是要基于C++同事提供的网络通讯中间件写一个Java的网络通讯框架，有人实现了第一版，随后就由我接手了这框架。</p>
<p>在那个时候就有人告诉我，整个系统链路的性能瓶颈是在这个网络通讯框架上。</p>
<p>不过在当时也是才疏学浅，一开始定位方向就错了。我在那时候是觉得这框架卡在了服务端的处理上，使用了BIO而不是NIO的方式进行通讯，造成大量的线程空转，以致于拉低了吞吐量。</p>
<p>接着就开始研究NIO，也就自然而然地学习了Reactor，以及Netty。</p>
<p>得益于公司提供的极客时间企业会员，我在极客时间上把Netty的课程学了一遍，然后就慢慢了解了Netty的使用方式以及一些实现细节。</p>
<p>但学完之后却是完全没用上。直到后来做行情客户端、做公司业务协议的服务器时，才用上这部分知识。</p>
<p>最后，更是把Netty的能力拆分，用到了我自己写的交易框架上。</p>
<h2 id="FastThreadLocal快在哪？">FastThreadLocal快在哪？</h2>
<p>聊一个技术，总是得聊聊实现。</p>
<p>先说结论：<code>FastThreadLocal</code>比起JDK自带的<code>ThreadLocal</code>，少了一次Hash的计算，这就是它快的地方。</p>
<p>然后再来聊聊其中的实现。</p>
<p>JDK自带的<code>ThreadLocal</code>，为了做线程隔离，是在每个线程中都创建了一个Hash表。</p>
<p>这个Hash表的Key是<code>ThreadLocal</code>对象，Value是具体的值。</p>
<p>它的get()过程是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、Thread.currentThread()获取到当前线程</span><br><span class="line">2、从Thread对象的hash表中获取当前ThreadLocal对应的Object并返回</span><br></pre></td></tr></table></figure>
<p>在从hash表获取Object的过程中，不可避免会有一次hash计算。</p>
<p>而<code>FastThreadLocal</code>则不一样。Netty创建了一个<code>FastThreadLocalThread</code>，继承JDK的<code>Thread</code>类，使用一个<code>Object[]</code>替换了其中的Hash表。</p>
<p>核心思路就是，创建<code>FastThreadLocal</code>对象时，给其分配一个全局的ID（或者说index）。<br>
这样的话，它的get()过程就可以优化为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、Thread.currentThread()获取到当前线程</span><br><span class="line">2、检查当前线程是不是FastThreadLocalThread，是的话走fastGet();否则走JDK原生的get()</span><br><span class="line">3、fastGet()会从FastThreadLocalThread的Object[]，通过创建FastThreadLocal获得的全局ID，直接用数组随机访问的方式获取值</span><br></pre></td></tr></table></figure>
<p>从结果上看，一个hash表取值的过程就优化为了数组随机访问，这就是最大的提升。</p>
<h2 id="带来了什么？">带来了什么？</h2>
<p>终于讲到重点了。<br>
FastThreadLocal把访问线程本地变量的时间，从一次hash计算的时间优化到了一次数组随机访问的时间。从时间上看，大约是4-10ns的操作优化为了小于1ns的操作。</p>
<p>这带来了一些影响：<br>
1、线程级别的资源，可以自行回收而不依赖JVM的GC。比如Netty中有一个工具类，存储着ArrayList和StringBuilder之类的对象，这些对象都存放于FastThreadLocal中。每次使用时，不需要new，而是从工具类中获取当前线程之前使用过的对象，使用完毕后手动清空这些对象即可。<br>
2、在1的基础上，构建了Recycler，以及ObjectPool。这些是Netty中Pooled的Buffer的最核心实现。</p>
<p>也就是说，线程级别的资源访问成本变低了，而线程数量又可控的情况下，我们可以把某些资源每个线程都分配一个。</p>
<p>同时，在线程自己的视角，所有的资源都只被当前线程使用，线程安全，不需要做任何并发安全的编码，有效提升性能。</p>
<p>虽然运行时的内存占用上去了，但是不会有更多的垃圾对象产生，这就让JVM的GC压力变得特别小。</p>
<h2 id="感想">感想</h2>
<p>Netty不愧是Java编程的教科书，这个FastThreadLocal在我看来，几乎是Java编程思想的集大成之作，完美发挥了Java的长处，尽可能避免了其短处。<br>
我虽然工作中已经有使用Netty，但我觉得更底层的细节其实我还是不太清楚。<br>
不谈FastThreadLocal，Netty还有很多优秀的实现值得参考，比如它的’0拷贝’、堆外内存的池化和回收机制。这值得我继续深入研究。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title>Unsafe的使用记录</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/Unsafe%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="什么是Unsafe">什么是Unsafe</h2>
<p><code>sun.misc.Unsafe</code>是sun包下的一个类。它的类注释如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * A collection of methods for performing low-level, unsafe operations.</span><br><span class="line"> * Although the class and all methods are public, use of this class is</span><br><span class="line"> * limited because only trusted code can obtain instances of it.</span><br><span class="line"> *</span><br><span class="line"> * @author John R. Rose</span><br><span class="line"> * @see #getUnsafe</span><br><span class="line"> */</span><br><span class="line">public final class Unsafe &#123;</span><br></pre></td></tr></table></figure>
<p>可见，这个类过于底层，至少Java的开发者本身是不希望其他人使用这个类的。</p>
<p>为何如此？</p>
<p>我想，最大的原因，就是Java本身是一种内存安全的语言。由于JVM的兜底机制，Java程序很少出现程序崩溃之类的问题。但是Unsafe提供的方法不同，正如其类名所述，它的方法都是“Unsafe”的，使用不当可能会导致程序崩溃。</p>
<p>可事实上，Unsafe更像是一个语言开发者留给自己的后门，看JDK中的源码，我们不难发现它其实被Jdk中的包广泛使用。更有甚者，在很多知名开源项目中，也会利用Unsafe类的能力来提高程序的性能。</p>
<h2 id="使用Unsafe">使用Unsafe</h2>
<p>在程序中使用Unsafe，目前只能通过反射的方式来获取。这是因为Unsafe类添加了<code>@CallerSensitive</code>注解，只有特定类加载器加载的类可以使用。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@CallerSensitive</span><br><span class="line">  public static Unsafe getUnsafe() &#123;</span><br><span class="line">      Class&lt;?&gt; caller = Reflection.getCallerClass();</span><br><span class="line">      if (!VM.isSystemDomainLoader(caller.getClassLoader()))</span><br><span class="line">          throw new SecurityException(&quot;Unsafe&quot;);</span><br><span class="line">      return theUnsafe;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>但是也不麻烦，我们可以使用如下代码获取到</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">private static final Unsafe UNSAFE = reflectGetUnsafe();</span><br><span class="line"></span><br><span class="line">private static Unsafe reflectGetUnsafe() &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);</span><br><span class="line">        field.setAccessible(true);</span><br><span class="line">        return (Unsafe) field.get(null);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        throw new RuntimeException(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不过一定要注意，不同版本的Unsafe类有不同的实现！使用前还是要谨慎。</p>
<h2 id="内存操作">内存操作</h2>
<p>要说Unsafe提供最大的能力，就是内存操作了。</p>
<p>C++程序中，我们可以申请一段内存，然后往里边设置数据，再把内存的指针传递给其他方法使用，最后释放内存。</p>
<p>这种操作在Java中，对应的就是创建一个对象，然后往对象里设置值，把对象传递给其他类的方法使用，最后交由JVM回收对象。</p>
<p>显然，Java是不能直接操作内存的，但是通过Unsafe类，我们可以做到这种能力。但同时，这也意味着内存管理的职责从JVM转移到了程序员自身，如果申请了内存没有释放，就会造成内存泄漏（OOM）。</p>
<p>那么我们看一下实际怎么操作内存：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 使用unsafe分配内存</span><br><span class="line">long addr = UNSAFE.allocateMemory(4);</span><br><span class="line">// 往内存块设置一个int类型数据</span><br><span class="line">UNSAFE.putInt(addr, 18);</span><br><span class="line">// 从内存块获取一个int类型数据</span><br><span class="line">UNSAFE.getInt(addr);</span><br><span class="line">// 调整大小</span><br><span class="line">UNSAFE.reallocateMemory(8)</span><br><span class="line">// 释放内存</span><br><span class="line">UNSAFE.freeMemory(addr);</span><br></pre></td></tr></table></figure>
<p>这种操作，几乎和C++程序是一致的了。</p>
<p>设置数据和获取数据的操作在Unsafe类中每种基础类型都已提供对应方法，这里就不再赘述。</p>
<p>当然还有最关键的copyMemory方法，可以从Java的数组对象之间，或者Java的数组对象与内存块之间拷贝数据。</p>
<p>不过需要注意的是：从内存块到Bean对象的拷贝是不被允许的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Sets all bytes in a given block of memory to a copy of another</span><br><span class="line"> * block.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;This method determines each block&#x27;s base address by means of two parameters,</span><br><span class="line"> * and so it provides (in effect) a &lt;em&gt;double-register&lt;/em&gt; addressing mode,</span><br><span class="line"> * as discussed in &#123;@link #getInt(Object,long)&#125;.  When the object reference is null,</span><br><span class="line"> * the offset supplies an absolute base address.</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;The transfers are in coherent (atomic) units of a size determined</span><br><span class="line"> * by the address and length parameters.  If the effective addresses and</span><br><span class="line"> * length are all even modulo 8, the transfer takes place in &#x27;long&#x27; units.</span><br><span class="line"> * If the effective addresses and length are (resp.) even modulo 4 or 2,</span><br><span class="line"> * the transfer takes place in units of &#x27;int&#x27; or &#x27;short&#x27;.</span><br><span class="line"> *</span><br><span class="line"> * @since 1.7</span><br><span class="line"> */</span><br><span class="line">public native void copyMemory(Object srcBase, long srcOffset,</span><br><span class="line">                              Object destBase, long destOffset,</span><br><span class="line">                              long bytes);</span><br></pre></td></tr></table></figure>
<h2 id="对象操作">对象操作</h2>
<p>接着是对象操作，使用反射和Unsafe，可以极快地获取对象中的字段信息。</p>
<p>不过需要注意，这种操作会绕过字段的各种限制，相当于是直接从对象的内存块上取数据。这种操作很方便，但完全违反了面向对象的原则。</p>
<p>首先来看一个Java对象的内存结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">OFFSET  SIZE               TYPE DESCRIPTION                               VALUE</span><br><span class="line">     0     4                    (object header)                           01 00 00 00 </span><br><span class="line">     4     4                    (object header)                           00 00 00 00 </span><br><span class="line">     8     4                    (object header)                           18 0a 06 00 </span><br><span class="line">    12     4                int User.age                                  0</span><br><span class="line">    16     4   java.lang.String User.name                                 null</span><br><span class="line">    20     4   java.lang.String User.name1                                null</span><br><span class="line">    24     4   java.lang.String User.name2                                null</span><br><span class="line">    28     4   java.lang.String User.name3                                null</span><br><span class="line">    32     4   java.lang.String User.name4                                null</span><br><span class="line">    36     4   java.lang.String User.name5                                null</span><br><span class="line">    40     4   java.lang.String User.name6                                null</span><br><span class="line">    44     4   java.lang.String User.name7                                null</span><br><span class="line">    48     4   java.lang.String User.name8                                null</span><br><span class="line">    52     4   java.lang.String User.name9                                null</span><br><span class="line">    56     4   java.lang.String User.name10                               null</span><br><span class="line">    60     4   java.lang.String User.name11                               null</span><br><span class="line">    64     4   java.lang.String User.name12                               null</span><br><span class="line">    68     4   java.lang.String User.name13                               null</span><br><span class="line">    72     4   java.lang.String User.name14                               null</span><br><span class="line">    76     4   java.lang.String User.name15                               null</span><br><span class="line">    80     4   java.lang.String User.name16                               null</span><br><span class="line">    84     4   java.lang.String User.name17                               null</span><br><span class="line">    88     4   java.lang.String User.name18                               null</span><br><span class="line">    92     4                    (loss due to the next object alignment)</span><br></pre></td></tr></table></figure>
<p>一个Java对象，有12字节长的对象头。基础类型会直接存放在对象中，引用类型存放的是对象的引用（4字节）。</p>
<p>基础类型在各种处理上都有明显的优势，这里也可以理解为什么性能敏感的项目并不推荐使用包装类型。包装类型在对象中的存储方式就是引用类型，和String、BigDecimal是一样的，在存取效率和使用效率上会有明显的差异。</p>
<p>Unsafe提供的第一种能力，就是直接通过offset的方式，从对象中获取数据。</p>
<p>下面看下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) throws NoSuchFieldException &#123;</span><br><span class="line">        User user = new User();</span><br><span class="line">        // 使用unsafe的api获取字段的偏移量，需要通过反射来获取字段的Field对象</span><br><span class="line">        Field age = User.class.getDeclaredField(&quot;age&quot;);</span><br><span class="line">        long ageAddr = UNSAFE.objectFieldOffset(age);</span><br><span class="line">        // 设置时把对象的偏移量传入</span><br><span class="line">        UNSAFE.putInt(user, ageAddr, 10);</span><br><span class="line">        // 取出时也是通过偏移量</span><br><span class="line">        UNSAFE.getInt(user, ageAddr);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码中，类型操作是个重点。如果使用错误的api来获取对象数据，很可能出现程序崩溃的异常！这也是为什么这个类称之为Unsafe的原因，使用不当极有可能导致程序崩溃。正常的Java程序是内存安全的。</p>
<p>上述方法在获取和设置对象的字段信息时，绕过了方法区和对象的字段范围限制。显然，这也脱离了面向对象的思维。</p>
<p>另外，还提供了绕过构造器创建对象的方法。原理上就是直接划分一个对应大小内存块。这里就不多提了。</p>
<h2 id="CAS操作">CAS操作</h2>
<p>CAS操作不多解释，Java的Concurrent包下的AtomicInteger这些原子操作都是通过Unsafe的CAS相关API进行操作。ConcurrentHashMap也是使用到了此类操作。</p>
<p>下面简单看一个api：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Atomically update Java variable to &lt;tt&gt;x&lt;/tt&gt; if it is currently</span><br><span class="line"> * holding &lt;tt&gt;expected&lt;/tt&gt;.</span><br><span class="line"> * @return &lt;tt&gt;true&lt;/tt&gt; if successful</span><br><span class="line"> */</span><br><span class="line">public final native boolean compareAndSwapObject(Object o, long offset,</span><br><span class="line">                                                 Object expected,</span><br><span class="line">                                                 Object x);</span><br></pre></td></tr></table></figure>
<p>比较并替换，设置之前比较数据是否是和预期是一致的，设置之后比较数据是否和设置的数据是一致的。</p>
<p>这种方式能在无锁的情况下进行并发操作，性能会非常高。</p>
<p>类似的还有比较并递增，但是它的实现会有些区别：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Atomically adds the given value to the current value of a field</span><br><span class="line"> * or array element within the given object &lt;code&gt;o&lt;/code&gt;</span><br><span class="line"> * at the given &lt;code&gt;offset&lt;/code&gt;.</span><br><span class="line"> *</span><br><span class="line"> * @param o object/array to update the field/element in</span><br><span class="line"> * @param offset field/element offset</span><br><span class="line"> * @param delta the value to add</span><br><span class="line"> * @return the previous value</span><br><span class="line"> * @since 1.8</span><br><span class="line"> */</span><br><span class="line">public final int getAndAddInt(Object o, long offset, int delta) &#123;</span><br><span class="line">    int v;</span><br><span class="line">    do &#123;</span><br><span class="line">        v = getIntVolatile(o, offset);</span><br><span class="line">    &#125; while (!compareAndSwapInt(o, offset, v, v + delta));</span><br><span class="line">    return v;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到是个do while的循环，实现了一个自旋操作来保证数据的递增操作是原子的。这就是AtomicInteger中所使用的方法。</p>
<h2 id="版本支持">版本支持</h2>
<p>还是要额外提一下关于Unsafe的版本支持问题。</p>
<p>其实随着JDK版本的更新，确实有部分方法被取消了。但同时，有更多的方法被添加到了Unsafe类中。</p>
<p>目前测试了Unsafe的jdk17和21版本，这两个版本都可以正常使用Unsafe。而本文提到的这些api，在这两个高级版本中都是可以正常使用，并且不需要其他任何配置或代码改动的。</p>
<h2 id="总结">总结</h2>
<p>本文简单说明了Unsafe的内存操作、对象操作和CAS操作。其实Unsafe的api中还包含了关于对于静态字段的处理、线程的操作（比如park），这些操作实际很少使用，目前就先不提。</p>
<p>目前在工作中，使用到的主要还是内存和对象的操作，用来提升序列化和反序列化的速度。</p>
<p>Unsafe说是不安全操作，但其实在JDK中是广泛使用。如果希望提升程序的性能，该用就用，毕竟Java开源生态中有大把大把的开源软件也在使用这个类。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title>内存分析记录手册</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E8%AE%B0%E5%BD%95%E6%89%8B%E5%86%8C/</url>
    <content><![CDATA[<h2 id="常用命令">常用命令</h2>
<p><code>jps</code> jps命令，查看所有java程序</p>
<p><code>jmap -heap &lt;pid&gt;</code> jmap命令，查看jvm内存分区，包括老年代、新生代等内存占用情况</p>
<p><code>jmap -dump:live,format=b,file=/tmp/dump.hprof &lt;pid&gt;</code> jmap的dump命令</p>
<p><code>jmap -histo &lt;pid&gt;</code> 和 <code>jmap -histo:live &lt;pid&gt;</code> 抓取内存中各对象的统计数据（直方图），主要包含实例个数，以及占用的内存空间。其中前一个命令，是抓取所有的对象，包括垃圾对象，而后一个命令只抓取存活对象</p>
<p>arthus命令略，可借用arthus的IDEA插件生成command</p>
<h2 id="什么是大对象">什么是大对象</h2>
<p>都说大对象会进入老年代，那么什么才是大对象呢？</p>
<p>假如一个对象A，内部引用了对象B，那么在计算对象大小的时候，是否会把对象B的大小也计入对象A呢？</p>
<p>答案是不会，这个有很多的地方可以证明：每个对象其实都只是存了其他对象的指针；dump文件在分析时，对象大小需要先用工具进行计算；在代码中分析对象大小大家用的都是第三方工具。这些都从侧面说明了，JVM本身并没有去计算对象引用的实际大小。</p>
<p>那么，JVM做垃圾回收时，其实垃圾收集器关心的只是对象本身的大小。所有对象的引用，都是一个内存地址，也就是指针。</p>
<p>举例，假如B是一个大数组，B在老年代。假如A在B进入老年代之后，持有了B对象作为成员变量。</p>
<p>在Java的垃圾回收机制中，对象进入老年代（Old Generation）通常需要满足以下条件：</p>
<ol>
<li>对象经过多次GC仍然存活。在Eden区进行Minor GC后，如果对象仍然存活，会被移动到Survivor区。在Survivor区进行GC后，如果对象仍然存活，会被移动到老年代。</li>
<li>对象的大小超过了Survivor区的阈值。每个Survivor区都有一个固定的容量限制。如果新创建的对象太大，以至于在当前Survivor区容纳不下，那么这个对象就会被直接分配到老年代。</li>
<li>对象被长期持有。一些被长时间持有的对象，比如长期存活或者被强引用的对象，可能会被直接分配到老年代。</li>
</ol>
<p>所以，如果对象A持有一个老年代对象B，并不意味着A自己会进入老年代。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title>双重锁和CAS</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/%E5%8F%8C%E9%87%8D%E9%94%81%E5%92%8CCAS/</url>
    <content><![CDATA[<h2 id="引子">引子</h2>
<p>在做一些变量的初始化时，我会有如下的实现：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 缓存存储对象的类型</span><br><span class="line"> */</span><br><span class="line">private volatile Class&lt;?&gt; rowType;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 获取缓存存储对象的类型</span><br><span class="line"> *</span><br><span class="line"> * @return 缓存存储对象的类型</span><br><span class="line"> */</span><br><span class="line">public Class&lt;?&gt; rowType() &#123;</span><br><span class="line">    if (rowType == null) &#123;</span><br><span class="line">        synchronized (this) &#123;</span><br><span class="line">            if (rowType == null) &#123;</span><br><span class="line">                // todo 这里是初始化rowType的逻辑</span><br><span class="line">             </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return rowType;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这种写法，我最初是在Protobuf生成的代码中看到的，后来查阅了一下，这种逻辑叫双重锁。</p>
<p>或者说，叫双重检查模式，是一种软件的设计模式。</p>
<p>而我在写一些其他的代码时，往往也会使用类似这种模式的方式。用多了以后，我觉得可以分析一下其中的道理。</p>
<h2 id="分析">分析</h2>
<p>双重锁的逻辑是两次检查：首先验证锁定条件(第一次检查)，只有通过锁定条件验证才真正的进行加锁逻辑并再次验证条件(第二次检查)。</p>
<p>那么，如果中间的锁定操作，我们改成一个计算过程，在最后赋值之前做二次检查，是否也是可以的呢？</p>
<p>答案是肯定的。下面给个伪代码说明：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int a = 0;</span><br><span class="line">int b = a;</span><br><span class="line">// 第一次检查</span><br><span class="line">if (a == b) &#123;</span><br><span class="line">  // 上锁</span><br><span class="line">  lock.lock();</span><br><span class="line">  // 第二次检查</span><br><span class="line">  if (a == b) &#123;</span><br><span class="line">  	// 计算操作</span><br><span class="line">		int c = b + 1；</span><br><span class="line">  	// 赋值</span><br><span class="line">  	a = c;</span><br><span class="line">  &#125;</span><br><span class="line">  lock.unLock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可是这样就太重了，要知道，有些时候，加锁的成本也很高。使用双重锁仅仅是能避免锁定中的操作多次重复，但是没有从根本上避免锁，所有的操作还是在锁中进行的，这就没有很好地发挥多线程的优势。</p>
<p>那么优化一下，把这个锁去掉，只在计算结束后进行一次检查，是否可行呢？答案也是肯定的，这样就变成了乐观锁+自旋锁的结合。伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int a = 0;</span><br><span class="line">// 自旋</span><br><span class="line">for (;;) &#123;</span><br><span class="line">	int b = a;</span><br><span class="line">	// 计算操作</span><br><span class="line">	int c = b + 1；</span><br><span class="line">	// 第一次检查</span><br><span class="line">	if (b == a) &#123;</span><br><span class="line">		// 赋值</span><br><span class="line">		a = c;</span><br><span class="line">		// 第二次检查</span><br><span class="line">		if (a == c) &#123;</span><br><span class="line">			break;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到锁被去掉了，这样并发时性能会远优于加锁。这就是CAS机制。</p>
<p>但是这里的CAS机制还不够，并不能保证极端情况下的线程安全。因为还有指令重排序的问题。</p>
<p>为了解决指令重排序的问题，需要在特定的变量上添加volatile注解。</p>
<p>在高性能场景下，CAS是一种非常优秀的机制，有以下优点：</p>
<ol>
<li>高效性：CAS 操作不需要加锁，因此可以避免加锁操作所带来的性能开销。</li>
<li>原子性：CAS 操作是原子的，因此可以保证操作的一致性。</li>
<li>无阻塞：CAS 操作不会阻塞线程，因此可以避免线程的切换和上下文切换带来的开销。</li>
</ol>
<h2 id="总结">总结</h2>
<p>双重锁的方式，一般是用于初始化的场景，是用来避免某个代码块执行两次的。</p>
<p>而在此基础上我们推演出自旋锁+乐观锁的方式，这样能实现无锁并发，这就是CAS机制。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>在Java程序使用Grpc protobuf的动态加载及类型反射</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/%E5%9C%A8Java%E7%A8%8B%E5%BA%8F%E4%B8%AD%E4%BD%BF%E7%94%A8Grpc%20protobuf%E7%9A%84%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%8F%8A%E7%B1%BB%E5%9E%8B%E5%8F%8D%E5%B0%84/</url>
    <content><![CDATA[<h2 id="准备工作">准备工作</h2>
<p>在阅读下面的文章之前，读者需要懂得gRPC的服务端、调用端的基本使用方式。否则可能无法理解文章中出现的部分概念。</p>
<h2 id="区分Protobuf和gRPC">区分Protobuf和gRPC</h2>
<p>我发现很多人会把Protobuf和gRPC混为一谈，这是不对的。</p>
<p>我这里直接引用Protobuf官网文档中的一段话来说明：</p>
<blockquote>
<p>The most straightforward RPC system to use with protocol buffers is <a href="https://grpc.io/">gRPC</a>: a language- and platform-neutral open source RPC system developed at Google. gRPC works particularly well with protocol buffers and lets you generate the relevant RPC code directly from your <code>.proto</code> files using a special protocol buffer compiler plugin.</p>
<p>If you don’t want to use gRPC, it’s also possible to use protocol buffers with your own RPC implementation. You can find out more about this in the <a href="https://protobuf.dev/programming-guides/proto#services">Proto2 Language Guide</a>.</p>
<p>There are also a number of ongoing third-party projects to develop RPC implementations for Protocol Buffers. For a list of links to projects we know about, see the <a href="https://github.com/protocolbuffers/protobuf/blob/master/docs/third_party.md">third-party add-ons wiki page</a>.</p>
</blockquote>
<p>gRPC是一种RPC通讯的方式，而Protobuf是一种用于序列化和反序列化结构化数据的二进制编码格式。gRPC在通讯时将传输的数据转变为Protobuf格式。</p>
<p>如果不使用gRPC，完全可以基于Protobuf的api实现一套自己的RPC通讯框架。</p>
<h2 id="Protobuf的Descriptor">Protobuf的Descriptor</h2>
<p>在百度中查询关于gRPC反射的资料，得到的信息大多牛头不对马嘴。但是查询Protobuf的反射，则可以获得一些案例。</p>
<p>这其实也说明了Protobuf和gRPC并不是同一个玩意儿。</p>
<p>Protobuf封装了Descriptor对象，提供了反射构建Protobuf消息对象的能力。所有Protobuf消息对象都要实现Message接口。</p>
<p>但是Descriptor对象的来源还是proto文件，为了使用反射的能力，我们需要一种特殊的二进制文件。</p>
<p>可以通过在maven编译插件中添加如下配置来生成这种二进制文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">    &lt;plugins&gt;</span><br><span class="line">        &lt;plugin&gt;</span><br><span class="line">            &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;protobuf.plugin.version&#125;&lt;/version&gt;</span><br><span class="line">            &lt;configuration&gt;</span><br><span class="line">                &lt;protocArtifact&gt;com.google.protobuf:protoc:$&#123;protoc.version&#125;:exe:$&#123;os.detected.classifier&#125;</span><br><span class="line">                &lt;/protocArtifact&gt;</span><br><span class="line">                &lt;pluginId&gt;grpc-java&lt;/pluginId&gt;</span><br><span class="line">                &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:$&#123;grpc.version&#125;:exe:$&#123;os.detected.classifier&#125;</span><br><span class="line">                &lt;/pluginArtifact&gt;</span><br><span class="line">                &lt;writeDescriptorSet&gt;true&lt;/writeDescriptorSet&gt;</span><br><span class="line">                &lt;descriptorSetOutputDirectory&gt;src/main/resources/desc&lt;/descriptorSetOutputDirectory&gt;</span><br><span class="line">                &lt;descriptorSetFileName&gt;descriptor.pb&lt;/descriptorSetFileName&gt;</span><br><span class="line">                &lt;descriptorSetClassifier&gt;descriptor&lt;/descriptorSetClassifier&gt;</span><br><span class="line">                &lt;clearOutputDirectory&gt;false&lt;/clearOutputDirectory&gt;</span><br><span class="line">            &lt;/configuration&gt;</span><br><span class="line">            &lt;executions&gt;</span><br><span class="line">                &lt;execution&gt;</span><br><span class="line">                    &lt;goals&gt;</span><br><span class="line">                        &lt;goal&gt;compile&lt;/goal&gt;</span><br><span class="line">                        &lt;goal&gt;compile-custom&lt;/goal&gt;</span><br><span class="line">                    &lt;/goals&gt;</span><br><span class="line">                &lt;/execution&gt;</span><br><span class="line">            &lt;/executions&gt;</span><br><span class="line">        &lt;/plugin&gt;</span><br><span class="line">    &lt;/plugins&gt;</span><br><span class="line"></span><br><span class="line">    &lt;extensions&gt;</span><br><span class="line">        &lt;extension&gt;</span><br><span class="line">            &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt;</span><br><span class="line">            &lt;!--引入操作系统os设置的属性插件,否则$&#123;os.detected.classifier&#125; 操作系统版本会找不到 --&gt;</span><br><span class="line">            &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;os.plugin.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/extension&gt;</span><br><span class="line">    &lt;/extensions&gt;</span><br><span class="line">&lt;/build&gt;</span><br></pre></td></tr></table></figure>
<p>在protobuf的maven编译插件中添加了生成<code>descriptor.pb</code>文件的配置，这个文件中包含了所有proto文件中的信息。</p>
<p>然后，我们开始加载这份文件，这里使用的是Protobuf的api：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PathMatchingResourcePatternResolver resourceLoader = new PathMatchingResourcePatternResolver();</span><br><span class="line">Resource[] descriptorFiles = new Resource[0];</span><br><span class="line">try &#123;</span><br><span class="line">    descriptorFiles = resourceLoader.getResources(&quot;classpath*:**/*.pb&quot;);</span><br><span class="line"></span><br><span class="line">    if (descriptorFiles.length == 0) &#123;</span><br><span class="line">        logger.info(&quot;No pb file found!&quot;);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">    for (Resource descriptorFile : descriptorFiles) &#123;</span><br><span class="line">        logger.log(Level.INFO, &quot;正在加载pb文件: &quot; + descriptorFile.getURL());</span><br><span class="line">        // 使用Protobuf提供的api，加载文件</span><br><span class="line">        DescriptorProtos.FileDescriptorSet fileSet =</span><br><span class="line">            DescriptorProtos.FileDescriptorSet.parseFrom(descriptorFile.getInputStream());</span><br><span class="line">    &#125;</span><br><span class="line">&#125; catch (IOException e) &#123;</span><br><span class="line">    throw new RuntimeException(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>待续…</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title>字符串编解码的特殊处理</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%BC%96%E8%A7%A3%E7%A0%81%E7%9A%84%E7%89%B9%E6%AE%8A%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>起因是在做内存数据库时，遇到了序列化的问题。其中，Java的字符串最是重量级，转化时怎么搞都有很大的性能问题。</p>
<p>后来搜寻了资料，FastJSON2的作者高铁在阿里开发者的公众号分享了一篇文章，阅读后受益匪浅，决定改动之后运用到自己的项目中。</p>
<p>高铁对String对象转化字节数组的优化主要有两方面：</p>
<p>1、直接获取char数组，避免自带方法的判断逻辑。</p>
<p>2、重写unicode到utf8的转换逻辑。</p>
<p>而字节数组转化为String对象，使用的是：</p>
<p>1、重写utf8到unicode的转换逻辑。</p>
<p>2、通过零拷贝构造器构建String对象。</p>
<p>说白了，就是通过一些旁门左道（比如Lambda表达式工厂替代反射，Unsafe操作）来绕过String对象本身的一些限制，从而重写其编解码逻辑。</p>
<p>但是话又说回来，结合实际场景分析后，字节数组转化为String对象似乎并没有太多的提升。后文会解释为什么提升有限。</p>
<p>实际运用到自己项目中时，我也进行了一些改造，从而适配项目本身的情况。</p>
<h2 id="String转byte">String转byte[]</h2>
<p>Java的String，本质是一个封装好的不可变char数组对象。</p>
<p>Java的char类型，底层编码是unicode，每个char占两位字节。而UTF-8使用可变长度的编码，不同字符所占的字节数不同。</p>
<p>FastJSON2的优化就如上文所述，分两步：</p>
<p>1、直接获取char数组，避免自带方法的判断逻辑。</p>
<p>2、重写unicode到utf8的转换逻辑。</p>
<p>我们先开看第一步，以下是核心代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 当前优化仅在Java8有效</span><br><span class="line">// Java9修改了String的字符串实现，因此无法使用以下的方式初始化</span><br><span class="line">if (JVM_VERSION == 8) &#123;</span><br><span class="line">	Field field = null;</span><br><span class="line">	long fieldOffset = -1;</span><br><span class="line">	if (!ANDROID) &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			field = String.class.getDeclaredField(&quot;value&quot;);</span><br><span class="line">			field.setAccessible(true);</span><br><span class="line">			fieldOffset = UNSAFE.objectFieldOffset(field);</span><br><span class="line">		&#125; catch (Exception ignored) &#123;</span><br><span class="line">			FIELD_STRING_VALUE_ERROR = true;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	FIELD_STRING_VALUE = field;</span><br><span class="line">	FIELD_STRING_VALUE_OFFSET = fieldOffset;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用反射和Unsafe获取了value对象的偏移量，缓存到了一个静态变量汇总。</p>
<p>后续是使用Unsafe，通过缓存的静态变量来获取char数组：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static char[] getCharArray(String str) &#123;</span><br><span class="line">    // GraalVM not support</span><br><span class="line">    // Android not support</span><br><span class="line">    if (!FIELD_STRING_VALUE_ERROR) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            return (char[]) UNSAFE.getObject(str, FIELD_STRING_VALUE_OFFSET);</span><br><span class="line">        &#125; catch (Exception ignored) &#123;</span><br><span class="line">            FIELD_STRING_VALUE_ERROR = true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return str.toCharArray();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而编码逻辑，则是参考了JDK原来的实现，进行了一定的修改：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    public static int encodeUTF8(char[] src, int offset, int len, byte[] dst, int dp) &#123;</span><br><span class="line">        int sl = offset + len;</span><br><span class="line">        int dlASCII = dp + Math.min(len, dst.length);</span><br><span class="line"></span><br><span class="line">        // ASCII only optimized loop</span><br><span class="line">        while (dp &lt; dlASCII &amp;&amp; src[offset] &lt; &#x27;\u0080&#x27;) &#123;</span><br><span class="line">            dst[dp++] = (byte) src[offset++];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        while (offset &lt; sl) &#123;</span><br><span class="line">            char c = src[offset++];</span><br><span class="line">            if (c &lt; 0x80) &#123;</span><br><span class="line">                // Have at most seven bits</span><br><span class="line">                dst[dp++] = (byte) c;</span><br><span class="line">            &#125; else if (c &lt; 0x800) &#123;</span><br><span class="line">                // 2 bytes, 11 bits</span><br><span class="line">                dst[dp] = (byte) (0xc0 | (c &gt;&gt; 6));</span><br><span class="line">                dst[dp + 1] = (byte) (0x80 | (c &amp; 0x3f));</span><br><span class="line">                dp += 2;</span><br><span class="line">            &#125; else if (c &gt;= &#x27;\uD800&#x27; &amp;&amp; c &lt; (&#x27;\uDFFF&#x27; + 1)) &#123; //Character.isSurrogate(c) but 1.7</span><br><span class="line">                final int uc;</span><br><span class="line">                int ip = offset - 1;</span><br><span class="line">                if (c &lt; &#x27;\uDBFF&#x27; + 1) &#123; // Character.isHighSurrogate(c)</span><br><span class="line">                    if (sl - ip &lt; 2) &#123;</span><br><span class="line">                        uc = -1;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        char d = src[ip + 1];</span><br><span class="line">                        // d &gt;= &#x27;\uDC00&#x27; &amp;&amp; d &lt; (&#x27;\uDFFF&#x27; + 1)</span><br><span class="line">                        if (d &gt;= &#x27;\uDC00&#x27; &amp;&amp; d &lt; (&#x27;\uDFFF&#x27; + 1)) &#123; // Character.isLowSurrogate(d)</span><br><span class="line">                            uc = ((c &lt;&lt; 10) + d) + (0x010000 - (&#x27;\uD800&#x27; &lt;&lt; 10) - &#x27;\uDC00&#x27;); // Character.toCodePoint(c, d)</span><br><span class="line">                        &#125; else &#123;</span><br><span class="line">//                            throw new JSONException(&quot;encodeUTF8 error&quot;, new MalformedInputException(1));</span><br><span class="line">                            dst[dp++] = (byte) &#x27;?&#x27;;</span><br><span class="line">                            continue;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    //</span><br><span class="line">                    // Character.isLowSurrogate(c)</span><br><span class="line">                    dst[dp++] = (byte) &#x27;?&#x27;;</span><br><span class="line">                    continue;</span><br><span class="line">//                        throw new JSONException(&quot;encodeUTF8 error&quot;, new MalformedInputException(1));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                if (uc &lt; 0) &#123;</span><br><span class="line">                    dst[dp++] = (byte) &#x27;?&#x27;;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    dst[dp] = (byte) (0xf0 | ((uc &gt;&gt; 18)));</span><br><span class="line">                    dst[dp + 1] = (byte) (0x80 | ((uc &gt;&gt; 12) &amp; 0x3f));</span><br><span class="line">                    dst[dp + 2] = (byte) (0x80 | ((uc &gt;&gt; 6) &amp; 0x3f));</span><br><span class="line">                    dst[dp + 3] = (byte) (0x80 | (uc &amp; 0x3f));</span><br><span class="line">                    dp += 4;</span><br><span class="line">                    offset++; // 2 chars</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // 3 bytes, 16 bits</span><br><span class="line">                dst[dp] = (byte) (0xe0 | ((c &gt;&gt; 12)));</span><br><span class="line">                dst[dp + 1] = (byte) (0x80 | ((c &gt;&gt; 6) &amp; 0x3f));</span><br><span class="line">                dst[dp + 2] = (byte) (0x80 | (c &amp; 0x3f));</span><br><span class="line">                dp += 3;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return dp;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这里有个很抽象的逻辑需要解释一下。</p>
<p>上述编码的方法入参有个名为dst的byte数组，它的意思是最终要写入的目标数组。在序列化框架中，有的时候就是要在一个已经提前创建好的byte[]数组里，从某个位置开始把转换后的结果append进去。这个方法就是为了兼容这种情况，所以还额外提供了dp这一入参，用来标识是从dst[]的第几位开始写数据。</p>
<h2 id="byte-转String">byte[]转String</h2>
<p>FastJSON2在处理此类场景时，也是进行了优化，分两步：</p>
<p>1、重写utf8到unicode的转换逻辑。</p>
<p>2、通过零拷贝构造器构建String对象。</p>
<p>重写后的代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public static int decodeUTF8(byte[] src, int off, int len, char[] dst) &#123;</span><br><span class="line">    final int sl = off + len;</span><br><span class="line">    int dp = 0;</span><br><span class="line">    int dlASCII = Math.min(len, dst.length);</span><br><span class="line"></span><br><span class="line">    // ASCII only optimized loop</span><br><span class="line">    while (dp &lt; dlASCII &amp;&amp; src[off] &gt;= 0) &#123;</span><br><span class="line">        dst[dp++] = (char) src[off++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    while (off &lt; sl) &#123;</span><br><span class="line">        int b1 = src[off++];</span><br><span class="line">        if (b1 &gt;= 0) &#123;</span><br><span class="line">            // 1 byte, 7 bits: 0xxxxxxx</span><br><span class="line">            dst[dp++] = (char) b1;</span><br><span class="line">        &#125; else if ((b1 &gt;&gt; 5) == -2 &amp;&amp; (b1 &amp; 0x1e) != 0) &#123;</span><br><span class="line">            // 2 bytes, 11 bits: 110xxxxx 10xxxxxx</span><br><span class="line">            if (off &lt; sl) &#123;</span><br><span class="line">                int b2 = src[off++];</span><br><span class="line">                if ((b2 &amp; 0xc0) != 0x80) &#123; // isNotContinuation(b2)</span><br><span class="line">                    return -1;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    dst[dp++] = (char) (((b1 &lt;&lt; 6) ^ b2) ^</span><br><span class="line">                            (((byte) 0xC0 &lt;&lt; 6) ^</span><br><span class="line">                                    ((byte) 0x80)));</span><br><span class="line">                &#125;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125; else if ((b1 &gt;&gt; 4) == -2) &#123;</span><br><span class="line">            // 3 bytes, 16 bits: 1110xxxx 10xxxxxx 10xxxxxx</span><br><span class="line">            if (off + 1 &lt; sl) &#123;</span><br><span class="line">                int b2 = src[off];</span><br><span class="line">                int b3 = src[off + 1];</span><br><span class="line">                off += 2;</span><br><span class="line">                if ((b1 == (byte) 0xe0 &amp;&amp; (b2 &amp; 0xe0) == 0x80) //</span><br><span class="line">                        || (b2 &amp; 0xc0) != 0x80 //</span><br><span class="line">                        || (b3 &amp; 0xc0) != 0x80) &#123; // isMalformed3(b1, b2, b3)</span><br><span class="line">                    return -1;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    char c = (char) ((b1 &lt;&lt; 12) ^</span><br><span class="line">                            (b2 &lt;&lt; 6) ^</span><br><span class="line">                            (b3 ^</span><br><span class="line">                                    (((byte) 0xE0 &lt;&lt; 12) ^</span><br><span class="line">                                            ((byte) 0x80 &lt;&lt; 6) ^</span><br><span class="line">                                            ((byte) 0x80))));</span><br><span class="line">                    boolean isSurrogate = c &gt;= &#x27;\uD800&#x27; &amp;&amp; c &lt; (&#x27;\uDFFF&#x27; + 1);</span><br><span class="line">                    if (isSurrogate) &#123;</span><br><span class="line">                        return -1;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        dst[dp++] = c;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125; else if ((b1 &gt;&gt; 3) == -2) &#123;</span><br><span class="line">            // 4 bytes, 21 bits: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx</span><br><span class="line">            if (off + 2 &lt; sl) &#123;</span><br><span class="line">                int b2 = src[off];</span><br><span class="line">                int b3 = src[off + 1];</span><br><span class="line">                int b4 = src[off + 2];</span><br><span class="line">                off += 3;</span><br><span class="line">                int uc = ((b1 &lt;&lt; 18) ^</span><br><span class="line">                        (b2 &lt;&lt; 12) ^</span><br><span class="line">                        (b3 &lt;&lt; 6) ^</span><br><span class="line">                        (b4 ^</span><br><span class="line">                                (((byte) 0xF0 &lt;&lt; 18) ^</span><br><span class="line">                                        ((byte) 0x80 &lt;&lt; 12) ^</span><br><span class="line">                                        ((byte) 0x80 &lt;&lt; 6) ^</span><br><span class="line">                                        ((byte) 0x80))));</span><br><span class="line">                if (((b2 &amp; 0xc0) != 0x80 || (b3 &amp; 0xc0) != 0x80 || (b4 &amp; 0xc0) != 0x80) // isMalformed4</span><br><span class="line">                        ||</span><br><span class="line">                        // shortest form check</span><br><span class="line">                        !(uc &gt;= 0x010000 &amp;&amp; uc &lt; 0X10FFFF + 1) // !Character.isSupplementaryCodePoint(uc)</span><br><span class="line">                ) &#123;</span><br><span class="line">                    return -1;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    dst[dp] = (char) ((uc &gt;&gt;&gt; 10) + (&#x27;\uD800&#x27; - (0x010000 &gt;&gt;&gt; 10))); // Character.highSurrogate(uc);</span><br><span class="line">                    dst[dp + 1] = (char) ((uc &amp; 0x3ff) + &#x27;\uDC00&#x27;); // Character.lowSurrogate(uc);</span><br><span class="line">                    dp += 2;</span><br><span class="line">                &#125;</span><br><span class="line">                continue;</span><br><span class="line">            &#125;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return dp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至于零拷贝的构造器，是使用了Lambda工厂来实现的，这里不多提，就看下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (JVM_VERSION == 8) &#123;</span><br><span class="line">	MethodHandles.Lookup lookup = trustedLookup(String.class);</span><br><span class="line"></span><br><span class="line">	MethodHandle handle = lookup.findConstructor(</span><br><span class="line">				String.class, methodType(void.class, char[].class, boolean.class)</span><br><span class="line">		);</span><br><span class="line"></span><br><span class="line">	CallSite callSite = LambdaMetafactory.metafactory(</span><br><span class="line">				lookup,</span><br><span class="line">				&quot;apply&quot;,</span><br><span class="line">				methodType(BiFunction.class),</span><br><span class="line">				methodType(Object.class, Object.class, Object.class),</span><br><span class="line">				handle,</span><br><span class="line">				methodType(String.class, char[].class, boolean.class)</span><br><span class="line">	);</span><br><span class="line">	stringCreatorJDK8 = (BiFunction&lt;char[], Boolean, String&gt;) callSite.getTarget().invokeExact();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主要还是讲下为什么这个零拷贝构造器实际用的时候发现很鸡肋。</p>
<p>首先，这个零拷贝构造器是要求传入一个<code>char[]</code>，传的<code>char[]</code>是什么它就用什么。</p>
<p>那么这个<code>char[]</code>哪里来？通过<code>decodeUTF8</code>方法构建的。</p>
<p>但是，在编码这一步，我们不能保证获得一个正确的<code>char[]</code>。这问题是UTF-8和Unicode的编码长度差异带来的。</p>
<p>我简单用代码举个例子。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 假设我们已经有了一个固定长度的byte[]</span><br><span class="line">public String getString(byte[] src) &#123;</span><br><span class="line">		// 首先得创建一个dst，才能decode</span><br><span class="line">		char[] dst = new char[src.length / 3];</span><br><span class="line">		int dp = StringUtils.decodeUTF8(src, 0, src.length, dst);</span><br><span class="line">		// 后续代码略……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，必须先创建好dst对象，才能做decode。但是由于UTF-8和Unicode编码长度的差异，初始化的dst长度可能过长了，也就是dst可能最后几位是<code>\u0000</code>。</p>
<p>如果不清理最后这几位，直接用零拷贝的方法去构建String，就会导致字符串在其他地方展示的时候最后有乱码或空白。</p>
<p>但是Java中又没有办法零拷贝截断数组。所有的截断方式本质都是通过创建一个新的数组，然后把原来数组的数据拷贝过去。</p>
<p>所以，用零拷贝的方式去构建，就必须在外部显式地拷贝一次。那既然如此，和直接使用String本身提供的方法又有什么区别呢？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public String(char value[], int offset, int count) &#123;</span><br><span class="line">        if (offset &lt; 0) &#123;</span><br><span class="line">            throw new StringIndexOutOfBoundsException(offset);</span><br><span class="line">        &#125;</span><br><span class="line">        if (count &lt;= 0) &#123;</span><br><span class="line">            if (count &lt; 0) &#123;</span><br><span class="line">                throw new StringIndexOutOfBoundsException(count);</span><br><span class="line">            &#125;</span><br><span class="line">            if (offset &lt;= value.length) &#123;</span><br><span class="line">                this.value = &quot;&quot;.value;</span><br><span class="line">                return;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // Note: offset or count might be near -1&gt;&gt;&gt;1.</span><br><span class="line">        if (offset &gt; value.length - count) &#123;</span><br><span class="line">            throw new StringIndexOutOfBoundsException(offset + count);</span><br><span class="line">        &#125;</span><br><span class="line">        this.value = Arrays.copyOfRange(value, offset, offset+count);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>可以看到String本来就是拷贝一次然后创建对象的。</p>
<p>所以这种零拷贝的方式就很鸡肋。</p>
<h2 id="使用">使用</h2>
<p>最后简单聊聊我在项目的使用。</p>
<p>我的项目是需要把String的数据转换为UTF-8编码，然后通过Unsafe写到一个内存块上。同时也有从内存块读取的需求。</p>
<p>很可惜现在提供的api，最终都是落到byte[]。因此我修改了这两个方法，重写了其中对于dst的操作，变更为直接操作内存块。</p>
<p>修改后的代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">    private static int getStringUTF8JDK8(long off, int len, char[] dst) &#123;</span><br><span class="line">        final long sl = off + len;</span><br><span class="line">        int dp = 0;</span><br><span class="line">        int dlASCII = Math.min(len, dst.length);</span><br><span class="line"></span><br><span class="line">        // ASCII only optimized loop</span><br><span class="line">        while (dp &lt; dlASCII &amp;&amp; UNSAFE.getByte(off) &gt; 0) &#123;</span><br><span class="line">            dst[dp++] = (char) UNSAFE.getByte(off++);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        while (off &lt; sl) &#123;</span><br><span class="line">            int b1 = UNSAFE.getByte(off++);</span><br><span class="line">            if (b1 == 0) &#123;</span><br><span class="line">            // 读到0直接返回，不需要继续读取</span><br><span class="line">                return dp;</span><br><span class="line">            &#125; else if (b1 &gt; 0) &#123;</span><br><span class="line">                // 1 byte, 7 bits: 0xxxxxxx</span><br><span class="line">                dst[dp++] = (char) b1;</span><br><span class="line">            &#125; else if ((b1 &gt;&gt; 5) == -2 &amp;&amp; (b1 &amp; 0x1e) != 0) &#123;</span><br><span class="line">                // 2 bytes, 11 bits: 110xxxxx 10xxxxxx</span><br><span class="line">                if (off &lt; sl) &#123;</span><br><span class="line">                    int b2 = UNSAFE.getByte(off++);</span><br><span class="line">                    if ((b2 &amp; 0xc0) != 0x80) &#123; // isNotContinuation(b2)</span><br><span class="line">                        return -1;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        dst[dp++] = (char) (((b1 &lt;&lt; 6) ^ b2) ^ (((byte) 0xC0 &lt;&lt; 6) ^ ((byte) 0x80)));</span><br><span class="line">                    &#125;</span><br><span class="line">                    continue;</span><br><span class="line">                &#125;</span><br><span class="line">                return -1;</span><br><span class="line">            &#125; else if ((b1 &gt;&gt; 4) == -2) &#123;</span><br><span class="line">                // 3 bytes, 16 bits: 1110xxxx 10xxxxxx 10xxxxxx</span><br><span class="line">                if (off + 1 &lt; sl) &#123;</span><br><span class="line">                    int b2 = UNSAFE.getByte(off);</span><br><span class="line">                    int b3 = UNSAFE.getByte(off + 1);</span><br><span class="line">                    off += 2;</span><br><span class="line">                    if ((b1 == (byte) 0xe0 &amp;&amp; (b2 &amp; 0xe0) == 0x80) //</span><br><span class="line">                        || (b2 &amp; 0xc0) != 0x80 //</span><br><span class="line">                        || (b3 &amp; 0xc0) != 0x80) &#123; // isMalformed3(b1, b2, b3)</span><br><span class="line">                        return -1;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        char c = (char) ((b1 &lt;&lt; 12) ^ (b2 &lt;&lt; 6) ^</span><br><span class="line">                            (b3 ^ (((byte) 0xE0 &lt;&lt; 12) ^ ((byte) 0x80 &lt;&lt; 6) ^ ((byte) 0x80))));</span><br><span class="line">                        boolean isSurrogate = c &gt;= &#x27;\uD800&#x27; &amp;&amp; c &lt; (&#x27;\uDFFF&#x27; + 1);</span><br><span class="line">                        if (isSurrogate) &#123;</span><br><span class="line">                            return -1;</span><br><span class="line">                        &#125; else &#123;</span><br><span class="line">                            dst[dp++] = c;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    continue;</span><br><span class="line">                &#125;</span><br><span class="line">                return -1;</span><br><span class="line">            &#125; else if ((b1 &gt;&gt; 3) == -2) &#123;</span><br><span class="line">                // 4 bytes, 21 bits: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx</span><br><span class="line">                if (off + 2 &lt; sl) &#123;</span><br><span class="line">                    int b2 = UNSAFE.getByte(off);</span><br><span class="line">                    int b3 = UNSAFE.getByte(off + 1);</span><br><span class="line">                    int b4 = UNSAFE.getByte(off + 2);</span><br><span class="line">                    off += 3;</span><br><span class="line">                    int uc = ((b1 &lt;&lt; 18) ^ (b2 &lt;&lt; 12) ^ (b3 &lt;&lt; 6) ^</span><br><span class="line">                        (b4 ^ (((byte) 0xF0 &lt;&lt; 18) ^ ((byte) 0x80 &lt;&lt; 12) ^ ((byte) 0x80 &lt;&lt; 6) ^ ((byte) 0x80))));</span><br><span class="line">                    if (((b2 &amp; 0xc0) != 0x80 || (b3 &amp; 0xc0) != 0x80 || (b4 &amp; 0xc0) != 0x80) // isMalformed4</span><br><span class="line">                        ||</span><br><span class="line">                        // shortest form check</span><br><span class="line">                        !(uc &gt;= 0x010000 &amp;&amp; uc &lt; 0X10FFFF + 1) // !Character.isSupplementaryCodePoint(uc)</span><br><span class="line">                    ) &#123;</span><br><span class="line">                        return -1;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        dst[dp] = (char) ((uc &gt;&gt;&gt; 10) + (&#x27;\uD800&#x27; - (0x010000 &gt;&gt;&gt; 10))); // Character.highSurrogate(uc);</span><br><span class="line">                        dst[dp + 1] = (char) ((uc &amp; 0x3ff) + &#x27;\uDC00&#x27;); // Character.lowSurrogate(uc);</span><br><span class="line">                        dp += 2;</span><br><span class="line">                    &#125;</span><br><span class="line">                    continue;</span><br><span class="line">                &#125;</span><br><span class="line">                return -1;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                return -1;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return dp;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">private static long putStringUTF8JDK8(char[] src, int offset, int len, long dp, int size) &#123;</span><br><span class="line">        int sl = offset + len;</span><br><span class="line">        long dlASCII = dp + Math.min(len, size);</span><br><span class="line"></span><br><span class="line">        // ASCII only optimized loop</span><br><span class="line">        while (dp &lt; dlASCII &amp;&amp; src[offset] &lt; &#x27;\u0080&#x27;) &#123;</span><br><span class="line">            UNSAFE.putByte(dp++, (byte) src[offset++]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        while (offset &lt; sl) &#123;</span><br><span class="line">            char c = src[offset++];</span><br><span class="line">            if (c &lt; 0x80) &#123;</span><br><span class="line">                // Have at most seven bits</span><br><span class="line">                UNSAFE.putByte(dp++, (byte) c);</span><br><span class="line">            &#125; else if (c &lt; 0x800) &#123;</span><br><span class="line">                // 2 bytes, 11 bits</span><br><span class="line">                UNSAFE.putByte(dp, (byte) (0xc0 | (c &gt;&gt; 6)));</span><br><span class="line">                UNSAFE.putByte(dp + 1, (byte) (0x80 | (c &amp; 0x3f)));</span><br><span class="line">                dp += 2;</span><br><span class="line">            &#125; else if (c &gt;= &#x27;\uD800&#x27; &amp;&amp; c &lt; (&#x27;\uDFFF&#x27; + 1)) &#123; //Character.isSurrogate(c) but 1.7</span><br><span class="line">                final int uc;</span><br><span class="line">                int ip = offset - 1;</span><br><span class="line">                if (c &lt; &#x27;\uDBFF&#x27; + 1) &#123; // Character.isHighSurrogate(c)</span><br><span class="line">                    if (sl - ip &lt; 2) &#123;</span><br><span class="line">                        uc = -1;</span><br><span class="line">                    &#125; else &#123;</span><br><span class="line">                        char d = src[ip + 1];</span><br><span class="line">                        // d &gt;= &#x27;\uDC00&#x27; &amp;&amp; d &lt; (&#x27;\uDFFF&#x27; + 1)</span><br><span class="line">                        if (d &gt;= &#x27;\uDC00&#x27; &amp;&amp; d &lt; (&#x27;\uDFFF&#x27; + 1)) &#123; // Character.isLowSurrogate(d)</span><br><span class="line">                            uc = ((c &lt;&lt; 10) + d) +</span><br><span class="line">                                (0x010000 - (&#x27;\uD800&#x27; &lt;&lt; 10) - &#x27;\uDC00&#x27;); // Character.toCodePoint(c, d)</span><br><span class="line">                        &#125; else &#123;</span><br><span class="line">                            //                            throw new JSONException(&quot;encodeUTF8 error&quot;, new</span><br><span class="line">                            //                            MalformedInputException(1));</span><br><span class="line">                            UNSAFE.putByte(dp++, (byte) &#x27;?&#x27;);</span><br><span class="line">                            continue;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    //</span><br><span class="line">                    // Character.isLowSurrogate(c)</span><br><span class="line">                    UNSAFE.putByte(dp++, (byte) &#x27;?&#x27;);</span><br><span class="line">                    continue;</span><br><span class="line">                    //                        throw new JSONException(&quot;encodeUTF8 error&quot;, new MalformedInputException</span><br><span class="line">                    //                        (1));</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                if (uc &lt; 0) &#123;</span><br><span class="line">                    UNSAFE.putByte(dp++, (byte) &#x27;?&#x27;);</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    UNSAFE.putByte(dp, (byte) (0xf0 | ((uc &gt;&gt; 18))));</span><br><span class="line">                    UNSAFE.putByte(dp + 1, (byte) (0x80 | ((uc &gt;&gt; 12) &amp; 0x3f)));</span><br><span class="line">                    UNSAFE.putByte(dp + 2, (byte) (0x80 | ((uc &gt;&gt; 6) &amp; 0x3f)));</span><br><span class="line">                    UNSAFE.putByte(dp + 3, (byte) (0x80 | (uc &amp; 0x3f)));</span><br><span class="line">                    dp += 4;</span><br><span class="line">                    offset++; // 2 chars</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // 3 bytes, 16 bits</span><br><span class="line">                UNSAFE.putByte(dp, (byte) (0xe0 | ((c &gt;&gt; 12))));</span><br><span class="line">                UNSAFE.putByte(dp + 1, (byte) (0x80 | (((c &gt;&gt; 6) &amp; 0x3f))));</span><br><span class="line">                UNSAFE.putByte(dp + 2, (byte) (0x80 | ((c &amp; 0x3f))));</span><br><span class="line">                dp += 3;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return dp;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>另外，从内存块读取字节时，读到<code>0x00</code>就可以停止了，这个逻辑我也加了进去。</p>
<h2 id="总结">总结</h2>
<p>还是得例行总结一下。</p>
<p>阅读开源代码确实能快速提升个人能力，我觉得以后这种事情应该多做。</p>
<p>使用开源代码，不仅仅是引入人家的包，为了追求技术可控性，我们也应当了解开源代码中的实现。而且追求极致性能的场景，还是得改改人家的代码，拿过来直接能用的概率还是挺小的。</p>
<p>再说远点的话，读到高铁的分享时，我确实觉得是受益匪浅。程序员中有一类很特殊的人，自己写了个很牛逼的东西，希望全世界都能知道我写了个很牛逼的玩意儿，让大家都用起来。就是有着这类人，才让软件行业一往无前地汹涌发展吧。</p>
<p>我尊敬，并希望也能成为那样的人。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title>我是怎么使用线程池的</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/%E6%88%91%E6%98%AF%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84/</url>
    <content><![CDATA[<h2 id="简单的说明">简单的说明</h2>
<p>首先给出声明的方法，也就是线程池的构造器。</p>
<img src="/%E5%B7%A5%E4%BD%9C/work/java/%E6%88%91%E6%98%AF%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84/image-20230926151418320.png" class="" title="image-20230926151418320">
<ul>
<li>
<p>corePoolSize：线程池中一直存活的线程数量</p>
</li>
<li>
<p>maximunPoolSize：线程池中最多存活的线程数量</p>
</li>
<li>
<p>keepAliveTime：当存活线程数量大于核心线程数量时，多余线程的存活时间，空闲时间超过这个数值则销毁线程</p>
</li>
<li>
<p>unit：时间单位</p>
</li>
<li>
<p>workQueue：工作队列，必须是阻塞的</p>
</li>
<li>
<p>threadFactory：线程工厂，用于新建线程时给线程添加一些配置。最常用的就是设置线程名。</p>
</li>
<li>
<p>handler：当任务被拒绝时的后续处理。默认实现是任务被拒绝时会抛出一个异常。</p>
</li>
</ul>
<p>线程池还有很多构造器，其他构造器大多是封装了一些默认实现，比如给了默认的threadFactory或者handler。</p>
<hr>
<p>线程池有一个很反直觉的逻辑：只有任务队列满之后，才会创建新线程。</p>
<p>为什么这么设计？我们只需要记住：创建线程、销毁线程是一个性能开销很大的工作，我们应该尽量复用线程。</p>
<p>因此，<strong>除非任务队列已满，否则都不会创建线程</strong>。</p>
<p>下面来看一个实际使用时线程池的声明。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ThreadPoolExecutor EXECUTOR = new ThreadPoolExecutor(1, 1, 10, TimeUnit.SECONDS, new ArrayBlockingQueue(1), r -&gt; new Thread(r, &quot;cache-clean-thread&quot;), new ThreadPoolExecutor.DiscardOldestPolicy());</span><br></pre></td></tr></table></figure>
<p>我们来模拟一下这个线程池的处理逻辑，假设有耗时很长的任务：</p>
<ul>
<li>
<p>第一个任务来到线程池，任务直接由核心线程执行。</p>
</li>
<li>
<p>第二个任务来到线程池，没有空闲线程，进入任务队列。</p>
</li>
<li>
<p>第三个任务来到线程池，没有空闲线程，任务队列也满了。这时候假如最大线程数大于核心线程数，则应该要创建一个新线程来执行任务，而当前任务则进入任务队列。但是我们不允许创建更多的线程，于是这个任务会被拒绝，进入handler的后置处理逻辑。我们直接使用了<code>new ThreadPoolExecutor.DiscardOldestPolicy()</code>作为后置处理逻辑，这个方法会移除最老的任务，然后把当前任务放到队列末尾。于是这个任务进入队列，最老的任务被移除，由于刚好我们队列为1，所以结果就是正在等待的任务被新来的任务替换了。</p>
</li>
</ul>
<p>可以看到，线程池处理的关键是workQueue，threadFactory和handler这三个参数，通过设定这三个参数，我们可以把线程池玩出各种花样来。</p>
<p>接下来的章节，就主要针对线程池的使用了。</p>
<h2 id="线程池的使用">线程池的使用</h2>
<h3 id="命名规定">命名规定</h3>
<p>我们要求使用线程池时必须重写threadFactory来命名线程。在命名线程时说明线程大概要处理的任务，可以有效提高后续通过日志排查问题的效率。</p>
<p>以下是命名的示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 创建读线程池</span><br><span class="line"> */</span><br><span class="line">private static final ThreadPoolExecutor READ_EXECUTOR = </span><br><span class="line">	new ThreadPoolExecutor(4, 4, 30, TimeUnit.SECONDS, </span><br><span class="line">		new LinkedBlockingQueue(400), </span><br><span class="line">		new ThreadFactory() &#123;</span><br><span class="line">			private final AtomicInteger threadNumber = new AtomicInteger(1);</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public Thread newThread(Runnable r) &#123;</span><br><span class="line">				return new Thread(r, &quot;cache-read-thread-&quot; + threadNumber.getAndIncrement());</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br></pre></td></tr></table></figure>
<h3 id="提交任务">提交任务</h3>
<p>有两个方法：excuse和submit</p>
<p>区别在于submit之后可以获得一个Future，在后续逻辑中监控任务是否执行完，并获得其堆栈。</p>
<p>excuse方法执行完之后当前线程就无法感知这个任务是否执行完了，这在大多数情况下是不可接受的。</p>
<p>一般是建议使用submit。</p>
<p>案例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Runnable writeTask1 = () -&gt; &#123;</span><br><span class="line">// do something</span><br><span class="line">&#125;;</span><br><span class="line">Runnable writeTask2 = () -&gt; &#123;</span><br><span class="line">// do something</span><br><span class="line">&#125;;</span><br><span class="line">int writeThreadCount = 4;</span><br><span class="line">Future[] writeFutures = new Future[writeThreadCount];</span><br><span class="line">// 提交任务到线程池</span><br><span class="line">for (int i = 0; i &lt; writeThreadCount; i++) &#123;</span><br><span class="line">	writeFutures[i] = WRITE_EXECUTOR.submit(i % 2 == 0 ? writeTask1 : writeTask2);</span><br><span class="line">&#125;        </span><br><span class="line">// 等待所有线程执行完毕</span><br><span class="line">for (Future future : writeFutures) &#123;</span><br><span class="line">	future.get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="拒绝策略">拒绝策略</h3>
<p>一般来说，拒绝策略可以通过设置workQueue和handler两种方式来修改。</p>
<p>ThreadPoolExecutor中已提供了四种内置策略，已经覆盖了绝大部分场景</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 在当前线程执行任务</span><br><span class="line">new ThreadPoolExecutor.CallerRunsPolicy()</span><br><span class="line">// 抛出任务被拒绝的异常</span><br><span class="line">new ThreadPoolExecutor.AbortPolicy()</span><br><span class="line">// 忽略最新提交的任务</span><br><span class="line">new ThreadPoolExecutor.DiscardPolicy()</span><br><span class="line">// 忽略最老提交的任务</span><br><span class="line">new ThreadPoolExecutor.DiscardOldestPolicy()</span><br></pre></td></tr></table></figure>
<p>以下列举两种特殊的策略</p>
<h4 id="不拒绝任何任务">不拒绝任何任务</h4>
<p>不希望有任何任务被拒绝，需要设置workQueue为LinkedBlockingQueue，并且不设置长度限制。但要注意人物堆积时可能导致内存溢出。</p>
<p>同时，由于线程池的创建线程只发生在任务队列已满时，这种用链表作为workQueue的线程池将不会创建任何新的线程。</p>
<p>以下是示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">private static final ThreadPoolExecutor notifyExecutor =</span><br><span class="line">        new ThreadPoolExecutor(5, 5, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(),</span><br><span class="line">            new ThreadPoolExecutor.AbortPolicy());</span><br></pre></td></tr></table></figure>
<p>由于没有任何任务被拒绝，handler其实也没有什么用了。</p>
<h4 id="任务溢出时让工作线程参与任务，且保证顺序">任务溢出时让工作线程参与任务，且保证顺序</h4>
<p>这是一种特殊情况下出现的需求，要求任务能保持一个大概的顺序（有时间戳），且数据不能丢失。</p>
<p>下面是代码示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">private static final ThreadPoolExecutor NOTIFY_EXECUTOR =</span><br><span class="line">    new ThreadPoolExecutor(1, 1, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(5000),</span><br><span class="line">        r -&gt; new Thread(r, &quot;cache-tx-notify-thread&quot;), (r, e) -&gt; &#123;</span><br><span class="line">        // 把最老的任务拿出来在当前线程执行，把新任务放到队列里</span><br><span class="line">        // 用来保证任务的顺序性</span><br><span class="line">        if (!e.isShutdown()) &#123;</span><br><span class="line">            Runnable oldTask = e.getQueue().poll();</span><br><span class="line">            e.execute(r);</span><br><span class="line">            oldTask.run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>老年代大对象的问题排查</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/%E8%80%81%E5%B9%B4%E4%BB%A3%E5%A4%A7%E5%AF%B9%E8%B1%A1%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<h2 id="堆内存">堆内存</h2>
<p>堆内存被划分为老年代和新生代。而新生代又可以划分为Eden区和Suivior区，Suivior还可以分为s1和s2。</p>
<p>先说为什么要分为老年代和新生代。内存中会有一些对象会长久的存活而不能回收（比如缓存对象），这些对象会放入老年代。我们可以把每一次GC当做是一次轮回，每次新生代GC后，如果有某一个对象没有被回收，那么就认定其年龄增长了一岁。当这个对象的年龄超过了某个值（默认是15）后，它就会从新生代被挪到老年代中。另外，如果一个对象的大小超过了某个值，那么会直接被挪到老年代。</p>
<h2 id="场景分析">场景分析</h2>
<p>我们目前遇到的情况是，启动时耗费了大量的内存空间，导致项目起不来。目前唯一能让项目起来的方式是把内存加到18G。业务希望能避免这种情况，尽量不要有太多的内存占用。</p>
<p>在我们的缓存框架中，启动时会加载数据库中的数据至内存。后续所有操作都是在内存中进行，而不会去直接操作数据库。数据库只是一个持久化的方式，这里的实现是后台异步入库。</p>
<p>那么，根据堆内存的基础知识，不难发现：启动时加载的数据会放到缓存对象中，而缓存对象在运行时会一直存在，因此它必定会存在于老年代中。</p>
<h2 id="排查过程">排查过程</h2>
<p>在排查的过程中用到了各种内存分析的工具。主要有三个：arthus、jmap、VisualVM。</p>
<p>实际用arthus应该也可以做到类似jmap的能力，但是我个人还是更喜欢直接用jmap命令行来做简单的内存分析，毕竟不用额外起个arthus。</p>
<blockquote>
<p>jmap -histo pid 和 jmap -histo:live pid，抓取内存中各对象的统计数据（直方图），主要包含实例个数，以及占用的内存空间。其中前一个命令，是抓取所有的对象，包括垃圾对象，而后一个命令只抓取存活对象的，结合这两个命令的输出，进行比对，能够快速找出垃圾对象信息。关键是，这个命令速度很快，可以快速进行多次操作。</p>
</blockquote>
<p>当然直接用jmap pid的命令也可以，可以快速查看堆内存信息。</p>
<p>然后是dump文件，通过dump文件可以很细致地进行内存对象的分析。arthus可以生成dump文件。</p>
<blockquote>
<p>jmap -dump:live,format=b,file=/tmp/dump.hprof pid</p>
<p>使用jmap产生一个dump，运用jvisualVM进行后续分析</p>
</blockquote>
<p>我在分析时，首先使用jmap查看了堆内存信息，发现老年代极大。当内存不够时，按理来说会进行full gc从而回收老年代中的对象，但实际这些老年代的对象并没有被回收。</p>
<p>那么是不是启动的过程中没有及时的把这些对象的引用释放呢？</p>
<p>为了验证这个猜想，我加大了内存，保证可以正常启动。启动后，直接查看堆内存，发现老年代是12G。通过 jmap -histo:live pid命令，手动触发一次GC，随后再查看堆内存，发现老年代只有6G了。很显然，就是在启动的过程中出现了一直被人持有的大对象。</p>
<p>于是开始翻代码，果然在数据加载的逻辑中找到了问题的原因。</p>
<p>在加载一个数据库表的数据时，代码中直接把sql的执行结果拿了出来做putAll，并且这是个并发的加载操作。如果表数据非常大，那么就同时会有很多大对象被创建出来，而这些大对象会直接进入老年代，只在full gc时回收。如果这些对象用完了内存，而数据还没有加载完，这些对象一直被其他对象持有，自然就会出现大对象无法回收的问题。</p>
<h2 id="解决">解决</h2>
<p>解决方式也很简单，通过jdbc的流式api，做成类似分页查询的操作，避免直接将所有数据查询出来加载到内存。</p>
<p>修改代码后，启动时内存变为了匀速增长，虽然启动速度有所下降，但确实不会有内存溢出和大对象无法回收的情况出现了。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title>远程调试案例</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/java/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E6%A1%88%E4%BE%8B/</url>
    <content><![CDATA[<p>下面我们来看一下怎么使用jvm的远程调试能力。</p>
<h2 id="前提">前提</h2>
<p>本地需要有源码，有源码才可以敲断点调试。</p>
<h2 id="编写启动脚本">编写启动脚本</h2>
<p>在实际项目中我们往往是通过脚本来启动Java程序，我们需要在启动命令上添加参数来开启远程debug模式。</p>
<p>需要添加的命令如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-Xdebug -Xrunjdwp:transport=dt_socket,address=5005,server=y,suspend=y</span><br></pre></td></tr></table></figure>
<p>以下是一份常见的启动脚本示例</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">get current folder.</span></span><br><span class="line">CMD_DIR=$(cd $(dirname $0); pwd)</span><br><span class="line">cd &quot;$CMD_DIR/..&quot;</span><br><span class="line">CURRENT_DIR=$(pwd)</span><br><span class="line">echo User dir: &quot;$CURRENT_DIR&quot;</span><br><span class="line">CONF_DIR=&quot;$CURRENT_DIR/conf&quot;</span><br><span class="line">STATIC_DIR=&quot;$CURRENT_DIR/static&quot;</span><br><span class="line">ARGS=$*</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">get file name.</span></span><br><span class="line">FILE_PATH=&quot;$CURRENT_DIR/lib&quot;</span><br><span class="line">files=$(ls &quot;$FILE_PATH&quot;)</span><br><span class="line">for filename in $files</span><br><span class="line">do</span><br><span class="line">   echo Main Jar: $filename</span><br><span class="line">done</span><br><span class="line">if [[  -f &quot;$CONF_DIR/application.yml&quot; || -f &quot;$CONF_DIR/bootstrap.yml&quot; ]]; then</span><br><span class="line">    echo &quot;Startup app $filename with parameter: $ARGS &quot;</span><br><span class="line">    nohup java \</span><br><span class="line">    -server \</span><br><span class="line">    -Dspring.web.resources.static-locations=&quot;$STATIC_DIR/&quot; \</span><br><span class="line">    -Dspring.config.location=&quot;$CONF_DIR/&quot; \</span><br><span class="line">    -Dkoca.config.location=&quot;config&quot; \</span><br><span class="line">    -Dkoca.lcp.dump.location=&quot;$CURRENT_DIR/&quot; \</span><br><span class="line">    -Dlogging.config=&quot;$CONF_DIR/logback-spring.xml&quot; \</span><br><span class="line">    -Dspring.banner.location=&quot;file:$CONF_DIR/banner.txt&quot; \</span><br><span class="line">    -Duser.timezone=GMT+08 \</span><br><span class="line">    -Xdebug \</span><br><span class="line">    -Xrunjdwp:transport=dt_socket,address=5005,server=y,suspend=y \</span><br><span class="line">    -jar &quot;$CURRENT_DIR/lib/$filename&quot; \</span><br><span class="line">    $ARGS \</span><br><span class="line">    &gt;./nohup.log 2&gt;&amp;1 &amp;</span><br><span class="line">else</span><br><span class="line">    echo &quot;Configuration folder or files is not exist.&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="运行启动脚本">运行启动脚本</h2>
<p>我们修改脚本后，将这份脚本上传到服务器。</p>
<p>正常启动时，程序会有一大堆运行日志。但是使用这份脚本启动后，程序启动时会卡住，等待其他客户端连接debug端口。</p>
<p>这个debug端口就是命令中设置的5005。</p>
<h2 id="本地创建客户端">本地创建客户端</h2>
<p>本地使用IDEA创建客户端。</p>
<img src="/%E5%B7%A5%E4%BD%9C/work/java/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E6%A1%88%E4%BE%8B/image-20230630174009789.png" class="" title="image-20230630174009789">
<p>修改host为服务器地址</p>
<img src="/%E5%B7%A5%E4%BD%9C/work/java/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E6%A1%88%E4%BE%8B/image-20230630174033683.png" class="" title="image-20230630174033683">
<p>创建完毕后运行该客户端，运行时该客户端会和服务端建立连接。</p>
<p>可以看到原本卡住的服务端开始正常运行。</p>
<p>在本地的代码中敲断点，就可以进行debug了，和平时在本地debug没什么差别。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>运维部署</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型技术到底带来了什么</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%88%B0%E5%BA%95%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<h2 id="正文">正文</h2>
<p>时间到2024年，以LLM为首的AI热潮似乎开始冷却。但是工具已经开始普及，大部分人已经开始尝试和AI一起工作。</p>
<p>我首先想提的是国内大模型的水平。目前接触下来，国产的AI在下限方面基本已经满足了我们的日常生活需要。也就是说，平时一些简单的任务已经可以让AI去完成，大部分问题都能收到一个令人满意的回答。对于大部分人的日常工作来说，已经足够。</p>
<p>如果要用一个角色来形容AI目前的水平，我觉得是一个知识面很广，能力很强，在经过适当调教能很好地完成任务的实习生。</p>
<p>这其实已经对我的日常工作方式有相当强烈地冲击了。举例来说，平日有些费时费力的总结报告，现在可以让AI来填写。一些技术文档全篇很长，而我需要知道的又只是其中的一个小点，那就可以让AI快速阅读之后我对其提问来获取答案。这种场景下，我的需求和问题都很明确，答案也有现成的，只是让AI在特定范围内进行一个快速的搜索，像是把LLM当做一个非常强大的搜索引擎，这种时候就非常好用。</p>
<p>还有种场景是内容的格式改写，比如数据改写为JSON格式。人工做很费力，但是AI能听懂指令快速生成结果。这就很好用。</p>
<p>那么工作的重点就变了。以前我的重点是把任务人工完成，要出力；现在我的重点是理清思路，转化为AI可以完成的任务，然后让AI先做一遍，我再检查一遍。这种思路确实就和分配任务给实习生是一样的。</p>
<p>所以，这就引出了LLM最适合的工作场景之一：<strong>重复性的、有明确工作规范和成果验收的工作</strong>。</p>
<p>另外，与AI协作的时候，很多人会感觉自己的能力也提高了。有一种场景，比如需要写一些自己平时不擅长的代码，像是后端程序员刚开始接触一门新的语言。这时候程序员可能是知道要做什么，但是苦于不知道怎么实现，因此需要一些额外的时间去学习。有了AI之后，这个学习成本降低了非常多，并且没有让人排斥的搜寻资料的过程。很多时候，我们要做的就是打开LLM输入界面，然后写出需求，等到LLM的回答，然后开始干活。得益于技术水平的提高，现在的LLM基本都很聪明，它们的回答大多数时候都是有用的。</p>
<p>感觉自己能力的提高后，会让人变得自信，然后就愿意去做一些以前不能做的事情。</p>
<p>但究其根本，不是人的能力提高了，而是<strong>学习的成本降低</strong>了。</p>
<p>这就是LLM最适合的第二个工作场景：<strong>快速让人在一个知识领域达到入门水平</strong>。</p>
<p>经过一些调教，我相信LLM在教育这方面大有可为。</p>
<p>然后我就要提GitHub Copilot。作为代码提示工具，有了LLM加持后，它聪明得让人欣喜。有人评价是，有了Copilot之后，编码的方式就变成了：写好注释，写好框架代码，然后停下来，等待Copilot填充。这确实是我的真实写照。</p>
<p>我觉得这就是大模型带来的最大影响：<strong>评价一个问题的难易程度，是取决于它有多少的部分能被LLM执行</strong>。</p>
<p>在一个任务中，我们总是倾向于让LLM做更多，而自己做更少。为什么这么说？第一个原因，LLM执行任务非常快，快到人类无法比拟的程度了；第二个原因，LLM执行任务的成本极低，几乎相当于没有成本。</p>
<p>但我们遇到的问题在最初往往并不是LLM可以直接解决的问题，因此我们要把问题转化为一个个LLM可以执行的最小单元。这考验了一个人思考问题、拆解问题和描述问题的能力，而显而易见的结论就是，这种能力越强的人，与LLM协作的能力也越强。</p>
<p>反过来，这其实也让我们每个人先专注于分析问题，而不是埋头就做。某种意义上来说，也算是反哺自身，让人去思考得更深入。</p>
<p>那么，我可以抛出一个命题：<strong>与大模型协作的能力越强，这个人的工作能力就越强</strong>。就像上文说的，一个人只有能分析拆解好问题，才能更好地让LLM完成工作。巧合的是，你把前面这句话中的LLM换成同事、下属也是一样成立的。原先AI部的同事就和我说过，常带实习生，或者手下有几个人的技术骨干，往往用Copilot也特别顺手。</p>
<p>在肉眼可见的未来，大家的工作中必定绕不开LLM，那么今早培养好自己相关的能力，可能也是条出路吧。</p>
<h2 id="总结">总结</h2>
<p>目前在工作和学习中，与大模型协作是非常常见的场景。</p>
<p>LLM的工作成本低，工作速度快，因此很适合进行一些重复性强、严格控制输入输出的工作。</p>
<p>LLM的语料资源丰富，能有效降低知识的学习门槛。</p>
<p>未来，人的工作能力可能很大程度上取决于他和AI配合能力的高低。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title>AI Coding使用记录-20250813</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/AI-Coding%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95-20250813/</url>
    <content><![CDATA[<p>今年AI coding赛道一直挺火热。从25年2月左右我因为学校的项目开始使用cursor写前端，到目前在工作里用claude code之类的工具写业务，这中间也用了不少工具，体验有差异。这里记录下目前的体验。</p>
<h2 id="GitHub-Copilot-初版">GitHub Copilot(初版)</h2>
<p>单独把初版的Copilot拿出来说，还是因为它在当时确实太惊艳了。</p>
<p>最初版的copilot只有代码补全的能力，但仅仅靠着这个能力，就征服了一众开发者的心。</p>
<p>我刚开始使用的时候，copilot主要是可以补全一些变量名和写了一半的代码。</p>
<p>我在代码里输入前缀，它就会自动补全我的后续内容。</p>
<p>比如我输入下面这句话。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">OrderVO order = new Order();</span><br></pre></td></tr></table></figure>
<p>当我输入Or后，代码编辑器的提示就出现了，会让我选择什么对象，并自动引入。</p>
<p>然后我按下空格，copilot自动帮我生成了一个变量名，我tab接收。</p>
<p>再接着我按下=，输入new，copilot就自动帮我生成后续的Order();。</p>
<p>整个流程非常顺畅。</p>
<p>使用copilot能大大减少程序员在IDE中进行代码复制粘贴的情况。</p>
<p>还有种用法是通过注释编写一些提示词，让copilot帮你写一些小的代码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 生成订单号</span><br></pre></td></tr></table></figure>
<p>比如我在代码中写下注释，生成订单号，copilot就会自动根据上下文（本文件内）尝试补全。</p>
<p>这种类似于对话的方式，也能节省一定的开发时间。</p>
<p>总的来说，在初版的Copilot出现时，<strong>大家几乎一边倒的好评</strong>，绝大多数质疑还仅仅是集中于代码的隐私问题。</p>
<p>当时有博主发文称，已经不知道离开copilot怎么编码了。用了copilot之后，他的工作就变成了：搭建好框架，写好注释，然后停下来，等copilot帮他生成后续的代码。</p>
<p>或许后面AI Coding的一些问题，此时也初现倪端。</p>
<h2 id="通义灵码">通义灵码</h2>
<p>在阿里推出通义大模型后，通义灵码的插件也快速上线了，对标的就是Copilot。功能上也相似，提供代码补全。</p>
<p>公网版我试用之后，觉得提示的质量不及Copilot，于是弃用。</p>
<p>但后来公司采购了企业版的通义灵码，私有化部署并且上传了公司的代码库，之后又尝试用了一段时间。</p>
<p>私有化部署解决了企业内部使用代码补全插件的隐私问题。发展到这一步时，我觉得代码补全的功能已经算相当完善了。</p>
<p>比起Copilot，通义灵码最大的优势是快。毕竟没有墙，甚至是内网部署，补全的速度比Copilot要快非常多。</p>
<p>这段时间Copilot也陆续推出了一些工具，比如生成注释、生成单测之类的能力，通义灵码也跟进了，但我用的不多。</p>
<p>而这时候，claude才刚推出2.0，大家觉得是个gpt-4的平替，还没有意识到它后续的统治力。</p>
<p>这段时间，我们公司内部报告说代码补全生成的代码占到了我们公司新增代码的10%。</p>
<h2 id="代码补全的小总结">代码补全的小总结</h2>
<p>第一阶段的AI Coding，主要作用是代码补全。</p>
<p>我见过一些论调是代码补全的能力与IDE本身提供的关键字、提示有一些冲突。对于熟练使用IDE插件的人来说，这个补全的功能有些鸡肋。</p>
<p>从我自身的角度来说，我是觉得还算好用的。编程中有个说法是“心流”，代码补全插件能节省我编程时在文件间来回切换，复制粘贴的操作，能更加关注于代码本身，也就更加容易进入“心流”。</p>
<p>大多数人的评价应该是与我一致的：<strong>好用，对编程速度有一定的提升，但没有产生质变</strong>。</p>
<p>微软对Copilot的定位是一个编程的副驾驶，主要起辅助工作，编程的主要责任还是在用户。</p>
<p>这个定位相当准确，在人机交互上也是相当友好——光标停顿时自动进行补全。使用久了之后，我基本可以预测Copilot可以帮我补全哪些代码，我仅需要写好必要的内容，然后等它补全完毕，再按下tab就行。</p>
<h2 id="GitHub-Copilot-Chat">GitHub Copilot Chat</h2>
<p>在Copilot推出一段时间后，微软和Github又推出了Copilot Chat。</p>
<p>Copilot Chat像是一个<strong>过渡产品</strong>，它的作用是让用户在IDE中和LLM对话，询问一些技术问题。</p>
<p>本意可能是为了让程序员不需要另外切换窗口来复制代码，但实际使用时，挑选合适的代码文件也是个很麻烦的活。</p>
<p>产品性上，Copilot Chat有直接插入代码到文件中的能力。有一些用，但不多。</p>
<p>还有选中一段代码，直接贴到Copilot Chat中询问，也没太多用处。</p>
<p>但还是有些场景是比较适合的。代码补全只能覆盖到写代码的场景，但实际工作中，还会有写配置、Debug的情况，这种时候Copilot Chat更能发挥一些作用。spring boot工程有很多配置项，有些开源组件的配置一时想不起来也很正常，我这时候会打开Copilot Chat问一下，往往能获得准确的回答。</p>
<h2 id="通义灵码（企业版）">通义灵码（企业版）</h2>
<p>上面也说了我们公司采购了通义灵码，这里有几个比较有趣的事情。</p>
<p>企业版的通义灵码是支持定制企业logo的，但我们上的第一版还是通义灵码的logo，直到第二个版本才更新。所以所有人都知道这玩意儿是个套壳的。但我们的AI部还是厚着脸皮和领导汇报说是自己产出的代码插件生成的采纳率达到了多少多少…</p>
<p>企业版的通义灵码支持上传企业代码库。我们公司是用的自己的中台框架，通义灵码的提示有的时候确实无法提示到公司框架的API。按理说这里就得上传公司的代码和文档，方便通义灵码提示。但我们的AI部不知道哪根筋抽了，只上传了工具类，导致相当长一段时间公司框架的问题通义灵码都回答不上来，为此我们部门还被领导骂了（中台框架就是我们写的）。</p>
<p>通义灵码后来也有样学样搞了个对话框，还支持企业配置自己的提示词和指令。我们部门抽调过去的小哥配了个单测的指令，试图一键生成单元测试的代码。但最后使用效果不太好，主要是上下文缺失，生成的代码少了很多赋值操作。</p>
<h2 id="Chat插件总结">Chat插件总结</h2>
<p>在代码补全插件的基础上，把对话框也搬进IDE，能拓展一部分覆盖场景，但终究带来的提升还是有限。</p>
<p>现在回头看的话，当时的大模型可能已经能正常生成我们想要的代码了，问题在于筛选上下文的工作太麻烦，以至于大家不太愿意去做。</p>
<p>试想一下，我要生成一个service文件的单元测试，我得把这个文件涉及到的所有POJO都一并传递给LLM，才有可能生成我想要的代码。</p>
<p>所以，Chat插件就卡在了一个不上不下的地方。</p>
<p>那么解决方案呢？就是索引和工具，或者用个更加新潮的说法：agent。</p>
<h2 id="Cursor">Cursor</h2>
<p>Cursor在产品刚推出的时候我就有关注。</p>
<p>Cursor是从VS Code的仓库fork了一个自己的分支，因此可以使用VS Code的插件。这方式挺取巧的，但确实不赖。</p>
<p>一开始Cursor想和Copilot做区分，Copilot的定位是帮你补全目前光标所在为止的代码，Cursor的定位是预测你下一个光标要移动的位置。</p>
<p>这是个很神奇的体验。我刚改了上一行代码，然后Cursor就会自动提示是否要跳转到另外一行，按tab接收就会自动跳转过去，并进行新的补全和提示。用Cursor写前端项目的话，确实就一直是在tab tab tab。</p>
<p>但Cursor真正火起来，还是在Claude 3.5 sonnect推出之后。因为Cursor Composer配合Claude 3.5 sonnect的效果实在是太惊艳了。</p>
<p>Cursor Composer的功能很简单，你写需求和指令，它帮你生成对应的代码，然后你接受，则自动插入到仓库的文件中。</p>
<p>说白了就是帮你写代码。Cursor给LLM开发了各种工具，能索引代码片段送给LLM，也能把LLM生成的代码写入到文件。</p>
<p>Cursor Composer一开始用的模型都不够聪明，导致生成的代码充满了报错、异常。</p>
<p>写个小功能还不如自己来，那么为什么还要用模型来生成呢？</p>
<p>在AI Coding界，Claude 3.5 sonnect可以说就像是人类第一次学会了用火，此后就迎来了跨越式的发展。</p>
<p>在Claude 3.5 sonnect的加持下，Cursor Composer生成代码可用性大大提升。</p>
<p>我也就是这个时候开始使用Cursor的，绝大多数时候生成的代码都是可用的，如果不行大不了回退然后修改提示词重新生成一次。</p>
<p>整个开发流程完全变了，从我亲自写代码，变成了写需求和指令给Cursor，然后筛选下相关的文件，最后等它生成。</p>
<p>这就是Vibe Coding的魅力啊。</p>
<p>后续Cursor修改了代码生成的模式，改为提供agent模式，进一步简化了开发流程。</p>
<p>我甚至不再需要去做文件筛选的工作了，Cursor会主动寻找它需要的代码文件，读取到上下文中。</p>
<p>这时候写一份高质量提示词才是我最重要的工作，其次就是看懂Cursor的输出，并修改其中不正确的部分。</p>
<p>如果说要我评价此时的Cursor，应该说是<strong>如日中天，颠覆性的体验</strong>。</p>
<h2 id="Cursor-（锁区）">Cursor （锁区）</h2>
<p>好景不长，后来Cursor因为成本问题几次三番修改使用条款，不断缩减20刀订阅计划的使用次数。</p>
<p>最开始是用完了订阅的请求次数，还能用慢请求，大不了排队。</p>
<p>后面改成了用完了请求次数就只能用auto模式的请求。auto模式是由Cursor来帮你选择用什么模型生成代码。</p>
<p>最后又改，auto也限流了。</p>
<p>我正好在换工作，开发任务不多，也很少用Cursor了，限流对我的影响倒是没那么大。</p>
<p>但是有一天，Cursor锁区了。</p>
<p>于是我把它彻底埋了。</p>
<p>当初捧得有多高，现在摔得有多惨。</p>
<h2 id="后Cursor时代">后Cursor时代</h2>
<p>在Cursor锁区之后，我尝试寻找Cursor的替代品。</p>
<p>AI coding体验过之后，很难再接受手动编写大量的代码了。</p>
<p>那段时间我试了Cline、Roo Code、Claude Code。</p>
<p>模型上则是用了Kimi K2、GLM 4.5、Deepseek V3、Deepseek V3.1、Qwen3 Coder等。</p>
<p>该说不说，Claude 3.5 Sonnect是个坎。模型的能力过了这个坎，写的代码就能在实际中用了。</p>
<h2 id="Claude-Code">Claude Code</h2>
<p>Cursor无疑是带火了AI Coding赛道。这是目前大家肉眼可见能赚钱的地方。</p>
<p>但死活没想到的是，模型提供商自己入局了。</p>
<p>Claude Code就是Anthropic推出的代码工具，主打一个Agent。</p>
<p>这也是个颠覆性的产品，居然是命令行操作。</p>
<p>命令行的好处是能嵌入所有的IDE终端，VS Code、Cursor、IDEA等等，都能无缝再接入一个Claude Code。</p>
<p>作为一个产品，实在是过于超前了。以至于google光速抄了一个Gemini Cli出来并开源了。</p>
<p>但国内使用还是有些问题，比如账户和锁区。所以我是配合Claude Code Router转发了国内的模型来使用的。</p>
<p>虽然很可惜用不上最强的能力，但总体来说体验还是不错的，尤其是Cursor锁区的情况下。</p>
<p>Claude Code有个todo list的功能，应该说是相当优秀，会先列出需要执行的任务，然后依次执行。</p>
<p>后面cursor、roo code等其他工具也都跟进了todo list。</p>
<p>Cluade Code的计划模式是一个比较有特色的功能，shift + tab按两次就切换到plan mode，这个模式下给出的任务会先进行规划而不进行具体的代码实现，如果发现计划不对可以及时指出并修改。一个很好的实践是先用4.0进行规划，再切换3.5进行代码生成。</p>
<p>我个人很喜欢计划模式。因为很多时候其实需求描述出来我自己心里也没底，看到Claude Code帮我生成了具体的实现方案后，我再看其中的细节我才能确认它写的对不对。</p>
<p>Claude Code离谱的点在于，依托于它强大的底层模型，只要计划没什么问题，它最终实现出来的代码几乎是立刻就能拿来用的。</p>
<p>另外再大概聊聊使用的几个国产模型。</p>
<p>Kimi K2在这里的表现不太行，当我在计划模式里两次修改了计划后，它就开始前言不接后语了，拉黑。</p>
<p>Qwen3 Coder很棒，但真的是token杀手，给我三个问题干了25块钱，因此也被我拉黑。</p>
<p>Deepseek V3的表现过于平庸，也弃用。</p>
<p>GLM 4.5出乎我意料，还挺不错的。但问题是Claude Code的上下文是以256K为基准，而GLM 仅有128K，不算少但使用时多少还是有些不方便。</p>
<h2 id="Roo-Code">Roo Code</h2>
<p>对标Cursor的Composer功能，社区推出了Cline，一个开源的VS Code插件。</p>
<p>但由于Cline不太愿意合并社区的pr，因此又有人另外fork了Cline的仓库，推出了Roo Code。</p>
<p>我后面有不少功能是用Roo Code写的。</p>
<p>Roo Code有不少很亮眼的功能：上下文窗口显示、仓库索引、自定义模式、子任务模式。</p>
<p>对于小任务，我直接配合GLM 4.5先计划后实现。而较大的任务则可以使用Orchestrator模式拆分为多个子任务，每个子任务有独立的上下文窗口，从而在有限的上下文里实现更多的功能。</p>
<p>Orchestrator模式的潜力我觉得还没完全发挥出来，目前传递给子任务的上下文还是有缺失，很多时候父任务已经阅读过的内容在子任务中还得重新阅读一遍，这就导致整个流程会拉得很长，并且有相当多的token被浪费了。</p>
<h2 id="Github-Copilot（Agent）">Github Copilot（Agent）</h2>
<p>在Cursor锁区后，想用Claude就得费点功夫了。</p>
<p>有网友推荐我可以用Github Copilot，目前也是支持Claude 4.0的。于是我时隔半年再次开始使用Github Copilot。</p>
<p>有意思的是，这次我打开Copilot就看到一个Agent模式。试用了一下，体验也和Cursor类似。</p>
<p>毕竟有学生优惠，而且还能直连，所以后面也尝试用Copilot写了一些小功能。</p>
<p>Claude 4还是厉害，写出来的代码质量很高。</p>
<p>缺点就是使用上有些小功能比不上Cursor，而且任务执行总是会中断，但总体来说给人一种它很想取代Cursor，或者说是把Cursor作为直接竞争对手的感觉…</p>
<p>Copilot在IDEA中的Agent模式总是会卡死，因此我后面都切换到VS Code里去了。</p>
<h2 id="Vibe-Coding">Vibe Coding</h2>
<p>现在流行的概念叫Vibe Coding，倒是不清楚这名字怎么来的…但突然间都在说。</p>
<p>大概指的就是利用各种AI编程工具，仅用提示词来写代码，完成需求。</p>
<p>或许最终目标就是自动化编程吧，仅仅提下需求就能完成所有的实现工作。</p>
<p>我觉得这是个很困难的事情，事实上大部分人在一个东西做出来之前并不知道它到底长啥样，也是因此才有敏捷开发，快速迭代的概念出来。</p>
<h2 id="小小的总结">小小的总结</h2>
<p>话题回到最近用的几个编码工具。很显然，AI Coding的过程经历了几个阶段：代码补全、被动问答、主动搜索仓库问答、agent。</p>
<p>代码补全就是Github Copilot为代表的插件。主要是协助编码，效率提升在10%-20%。</p>
<p>被动问答则是Github Copilot Chat为代表的插件。主要能在IDE内进行问答，还能添加项目文件到对话框。编码效率没有提升多少，但debug之类的效率能有一定提升，算它总体30%吧。</p>
<p>主动问答是类似Cursor这类编码IDE，能建立仓库代码文件的索引，也有用向量数据库做的。这类的特点是会自动搜索相关的代码片段一起传给LLM。在被动问答的基础上减轻了开发者的提问负担，生成的代码有时候也可以直接使用了。</p>
<p>最后就是Agent模式。Agent不仅能使用工具，与之前所有的模式最大的差别在于，它具有规划的能力。Agent能拆解任务，并逐步执行，在每一步都选择合适的工具来完成任务。这让它最终产出的代码质量有了极大的提升。</p>
<p>那么，我们不妨把视角从AI Coding这赛道中抽离出来。当我们提供更加丰富的工具，打通了LLM访问其他业务数据的渠道，这种Agent的能力，是否会泛化到各行各业的工作中去呢？</p>
<p>我不好说，但唯一能确定的就是：</p>
<p><strong>后面可用的AI应用，只会是Agent，也只能是Agent</strong>。</p>
<h2 id="题外话">题外话</h2>
<p>纵观AI Coding的发展过程，最关键的是基础模型的进步。</p>
<p>这个进步方向有三个：</p>
<p>1、模型代码能力的进步。这决定了模型生成的代码是否可用，是否有错误。在最开始我使用Claude 3.5时，它生成的代码还常常有语法错误，需要反复修改。而到Claude 4.0之后，则很少出现这种语法错误了。</p>
<p>2、模型的任务规划能力和工具调用能力进步。这些是Agent使用工具的前置条件，Cline使用复杂的提示词也能做到类似的工具调用和规划能力，但是终究效果不及从模型训练时就添加相关训练数据来得好。</p>
<p>3、模型的上下文长度。这个在编码中意外地重要。代码文件是个很耗费token的玩意儿，上下文越长，越能记住有用的信息。128k的长度在现在已经很常见了，但128k的上下文在使用效果上还是有些落后。目前先进的模型上下文直接到256K，甚至是1M，这让模型能直接阅读完仓库内的所有文件，甚至比业务开发更了解业务代码。另外，多轮对话的过程中会有很多工具调用等，也会大量占用上下文窗口。就我使用下来，64K的上下文目前几乎是不可用的状态。</p>
<p>提到上下文，就还得提个上下文工程的概念。模型的上下文是有限的，并且不可能无限增长。目前我们给LLM提供了工具调用的能力，LLM能主动去获取外界的信息了。但是我们还是缺少控制上下文内容的能力，很多时候LLM在工具调用过程中浪费了不少上下文。</p>
<p>在Vibe Coding的过程中，我绝大多数时间是在与GLM 4.5这短小的128K上下文做斗争。</p>
<p>另外说一句，在上下文超过长度的50%时，大多数模型的输出效果会显著变差，目前用下来仅有Claude是还能正常遵循规则进行工具调用的，不知道是不是因为Anthropic专门把Claude Code的api拿去训练了。</p>
<p>也提一嘴百度。</p>
<p>AI Coding的模型中我唯独没用百度的模型，一方面是在LLM这个赛道上，Qwen真的是一路领先…另一方面还是百度有点烂泥扶不上墙。</p>
<p>大家总说百度起个大早赶个晚集，没想到在LLM居然也是一样的结果。GPT 3.5刚发布时，百度率先推出文心一言，大约有GPT 3.0的水平，此时国内其他厂还仅有GPT 2.5的水平。结果3年过去了，Qwen、deepseek、Kimi、智谱清言都有开源的优秀模型推出，反而是百度渐渐淡出了大家的视野。明明最早提出All in AI的也是百度，咋最后就又竞争不过了呢。</p>
<p>顺便一提，Agent是下一个风口这话我也是最早从Robin嘴里听到的，某种意义上百度还真是行业明灯啊。方向永远是对的，执行结果总是错的，也是没谁了。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>AI Coding</tag>
      </tags>
  </entry>
  <entry>
    <title>对于当前大模型的直觉认知</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E5%AF%B9%E4%BA%8E%E5%BD%93%E5%89%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9B%B4%E8%A7%89%E8%AE%A4%E7%9F%A5/</url>
    <content><![CDATA[<h2 id="亦有差距">亦有差距</h2>
<p>这个文是9月5号的时候想起来要写的，但实际落笔写完时9月28日了。</p>
<p>当时是看到项目组里的人对大模型有些不切实际的认知，才想到要些这个文章。</p>
<p>我遇到过的有几类人。</p>
<p>第一类是过度依赖模型，妄图让模型处理一切的。</p>
<p>我看到有人让模型来处理大量的结构化数据。这操作一看就恼火，<strong>模型的上下文是非常珍贵的资源</strong>，把无序的数据直接灌给模型是一种非常无用且低效的做法。</p>
<p>还有种做法是让大模型来打分，但是没有明确的打分标准。这种情况是提示词不到位，觉得模型能生成一个可有可无的分数就够了。</p>
<p>这第一类人的本质，是工作中想偷懒，希望有个全能的神来帮助他们完成工作。</p>
<p>第二类是无法正确使用模型，导致效果比预期差上不少。</p>
<p>比如有个视觉识别的模型，有个人让模型在一次回答中，先进行推理，再进行多次判断，最后要求模型只返回限定格式的结果而不返回思考过程。最后结果是模型一直输出思考过程，绝不遵循返回格式的限定。</p>
<p>第二类人与第一类的不同点在于，他们会写非常详细的提示词，也会持续优化。虽然思路是错的，但至少工作态度是对的。</p>
<p>第三类人则是过于低估模型能力，不信任模型。</p>
<p>有部分领导既不懂模型原理，也不懂开发，但就喜欢拿着自媒体上看到的一点点碎片化知识对下属指手画脚。只要是涉及AI的功能，上来就是一句幻觉怎么处理，结果是不是不可用，而忽视了<strong>很多事情并没有正确答案，一个近似解已经是非常优秀的结果</strong>。</p>
<p>这些问题的本质，还是没有理解大模型的原理，没有一个直觉化的认知。</p>
<h2 id="给大模型的画像">给大模型的画像</h2>
<p>我觉得直觉认知很重要，我们日常工作中有80%的决策是基于直觉来做的。</p>
<p>那么，不妨给大模型一个画像，来让人有更直接的理解。</p>
<p>我对大模型的评价是：<strong>一个能力很强的社招新员工</strong>。</p>
<p>过去我可能会说是实习生，写写代码还会犯点低级错误，但现在模型能力已经强到专家这一级别了。</p>
<p>大模型参与我们的日常工作，更多的时候是<strong>缺失上下文而不是缺失相关能力</strong>。</p>
<p>当你构建好上下文，优化了提示词，大模型的结果往往会优秀得让你觉得惊讶。</p>
<p>就如同一个新来的员工，你知道它能力很强，能胜任这份工作，但问题是它刚来公司，一些流程、制度、业务规范完全不懂。</p>
<p>所以你得告诉它，代码命名要遵循驼峰，数据处理前要报备，文件注释里要带上自己的名字和当前的时间……</p>
<p>假设你的项目有详细的文档，新来的员工能快速理解，那么这份文档往往也能相当程度上帮助大模型。</p>
<h2 id="更深入的理解">更深入的理解</h2>
<p>目前大模型生成token的方式，是基于全部的上下文来预测下一个token，这里的上下文包含模型自己之前生成的token。</p>
<p>因此，思维链的可用性也很容易被理解了。大模型先进行了思考，最后基于上下文中的思考过程给出了正确的结论。</p>
<p>同时，大模型阅读文字的方式不是像人一样逐字逐句阅读，而是一次性把所有的上下文输入到GPU的不同计算单元内。同时会把上下文中最相关的内容的权重调高。</p>
<p>因此，一次性输入结构化的原始数据来做统计类工作效率很低。比如给了一批数据让模型来做字数统计，模型往往给不出正确的结论。</p>
<p>大部分时候，<strong>你应该让大模型利用工具做它擅长的事情</strong>。</p>
<p>比如数据分析的任务，你应该让模型来写python代码来进行数据分析，而不是直接把原始数据给大模型。</p>
<p>比如你写了一份简略的提示词，但模型总不能很好地完成任务，你应该先和模型探讨这个提示词中缺失的上下文，让模型先给出实施计划。模型不能直接理解你的意图，但它知道当前你给的提示中有什么缺失的东西。</p>
<p>比如你有多个目标要在一个对话上下文里完成，你应该使用todo list的方式让模型时刻进行更新。</p>
<p>诸如此类的场景还有很多，就不再一一列举。</p>
<p>归根结底，<strong>要控制模型做事的方法，而不是让它自由发挥</strong>。</p>
<h2 id="制定规范">制定规范</h2>
<p>有句话叫形式化的事情都可以自动化。</p>
<p>这句话在目前的工作中尤其有用，任何形式化的工作内容都可以使用大模型技术来进行简化。</p>
<p>这里的形式化工作，指的是有明确的执行方式、考核方式且结果的好坏影响不大的事情。比如要撰写一个邮件发给XXX，比如要审查文档的内容是否有XX问题。</p>
<p>软件开发的流程中有相当多的形式化工作，比如撰写接口文档，提供审计报告，根据数据库设计编写数据库脚本等等…</p>
<p>有些是开发流程上的规定，有些是公司制度的规定，但这些本质上都是规范，用来管控个人的产出。</p>
<p>那么，既然能管人的产出，能不能管AI的产出呢？</p>
<p>答案是肯定的。</p>
<p>大模型的输出需要进行严格的管控，避免其乱输出或输出幻觉。</p>
<p>我们通过编排工作流，写代码来让模型进行多轮对话，让其逐步完成任务。</p>
<p>这种工作流实际就是规范。以前模型不能很好地遵循指令，我们只能用dify之类的工作流框架进行编排。现在模型能力足够强了，已经能做到让模型自己去编排任务，然后再去执行，也就是Agent模式。</p>
<p>比较好笑的一点就是，以前软件工程里有相当多的开发模式，实际执行的过程中大家往往觉得文档过多不愿意去全量执行。现在大模型出来后，最苦的打字工作模型会帮你做的，但是模型生成的内容不可靠，所以大家反而愿意去执行标准的开发模式。</p>
<p>这何尝不是一种制定规范来限制模型生成内容的方式呢？</p>
<p><strong>或许软件工程的目标，就是在不关注代码内容的情况下保证项目的正确交付吧？</strong></p>
<h2 id="直觉认知">直觉认知</h2>
<p>最后回到一开始的主题，我提到大家同样是使用大模型，但亦有差距。</p>
<p>这其中最大的差别，就是大家对于大模型的直觉认知存在不同。</p>
<p>我相信这篇文章里讲的内容都很浅显，大多数人看过一遍就应该明白了。修正了认知的大方向，后续工作才不会走弯路。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title>工作中印象最深刻的一件事</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%8D%B0%E8%B1%A1%E6%9C%80%E6%B7%B1%E5%88%BB%E7%9A%84%E4%B8%80%E4%BB%B6%E4%BA%8B/</url>
    <content><![CDATA[<h2 id="技术之外的东西">技术之外的东西</h2>
<p>如果是放在还没参加工作时，看到这个问题“你在项目中遇到过的印象最深刻的一件事”，我大概率就是：胡诌一个很难的技术问题，然后说这问题解决的过程有些困难，但是经过我艰苦卓绝地努力，还是完成了，最后觉得自己很有成就感巴拉巴拉……</p>
<p>但是放到今天，再看这问题，我就倾向于带一些技术之外的东西进去。</p>
<p>这能聊的就多了。</p>
<p>比如有个不怎么开窍的实习生，怎么教都教不会，最后是我自己帮他写了代码。我反思之后，觉得自己带人的方式有些问题，从此之后就换了一种方式教人。如果实习生能力差，就选取一些时间上限制不那么多的任务；如果愿意挑战，就分一些预研性质的任务，让他产出方案。<br>
这样能说的就多多了，我相信也是大部分面试官可以感同身受的。</p>
<p>当然上面只是个例子，最主要的一点就是，我觉得和同事相处的方式、选取某种技术的决断、一些任务优先级的取舍，这些都可以是印象深刻的事情。对于这些事情，技术固然包含在其中，但提升了这些事难度的、给人深刻印象的，恰恰就是技术之外的东西。</p>
<h2 id="印象最深的一件事">印象最深的一件事</h2>
<p>然后就提到我自己参加工作后印象最深的一件事，应该就是写公司业务协议序列化框架的纯Java版本了。</p>
<p>准确说起来，这块的代码我没有写多少。我主要是负责这个任务的分配、监督和技术指导，编码由组内的一个同事负责。</p>
<p>前期预研时，阅读了Protobuf的源码，然后实现时是参考了C++的实现。</p>
<p>简单来说，就是参考C++的代码，从Protobuf中找到对应的可用代码，然后移植到我们的框架中。</p>
<p>包体的解析逻辑有大量的可用实现，但是Java对象属性的获取和设置的逻辑，我们是用Unsafe重新写了一遍。</p>
<p>整个过程顺利得不可思议，原计划两个月的任务，最后一个月就完成了。</p>
<p>但是问题就出在这个完成之后，我们发现还有一些性能优化的空间。</p>
<p>这个同事有些钻牛角尖，希望能把整个代码重构，然后做性能优化。但是我组织了他。</p>
<p>这就是我印象最深的地方了，我经过了取舍，决定把重构和优化的工作往后无限期推迟，让他先基于目前的版本给出详细的文档。</p>
<p>我们大部分同事都不具备给项目收尾的能力，就是一个模块，写到什么程度，我们就应该停止迭代，转而发布正式版。</p>
<p>这个界定是有些困难的，作为开发者，你永远不会满意，永远会觉得还有优化空间。</p>
<p>但工作都是由优先级的，我们只能接受不完美的现实，把有限的精力投入更高优先级的事项中去。</p>
<p>这就是我从这件事情里学到的。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title>我也是全栈</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E6%88%91%E4%B9%9F%E6%98%AF%E5%85%A8%E6%A0%88/</url>
    <content><![CDATA[<h2 id="经历">经历</h2>
<p>如果说我是什么时候有这个想法，那我觉得最早应该要追溯到大一的时候了。</p>
<p>当时刚入学，正在军训。我们有一次思想测验，当时年级里有同学搭了一个网站供我们考试。</p>
<p>刚上大学的我对这操作惊为天人。</p>
<p>后来从别人那了解到，这些东西在大二的时候基本都会教。</p>
<p>可惜，事实是直到大三我都不知道他们是怎么搭建的这网站。</p>
<p>接着就是实习，才开始对软件开发有了些概念。了解了前端、后端，各种开发语言，各种基础概念。也算是开始学以致用了。</p>
<p>毕业之后，我开始工作。</p>
<p>还记得上班的第一天，部门最大的领导过来有个谈话的环节。</p>
<p>海航总问我们，你们有什么目标吗？</p>
<p>没人回应。</p>
<p>稍稍沉默之后，我鼓起勇气回答道：“我想做全栈。”</p>
<p>我觉得这就是我开始有做全栈的决心的时候。</p>
<p>时光飞逝，我不断加深着后端的技能。数据库，运维部署，监控，开发框架，缓存，流量治理，网络通讯，这些点在我工作的这些年里我也慢慢加深了解。</p>
<p>唯独前端一直没什么进展。</p>
<p>我一直就是维持在有个前端项目，可以在我本地运行起来的这么个程度。</p>
<p>第一次转机出现在第二年年末，我去做低码平台的项目。</p>
<p>当时前端资源紧缺，很多细节让前端来改实在是有些慢了。我就看了下vue2的语法，还有前端的基础入门，就上手改一下样式和bug之类的。</p>
<p>当时算是有了个基本的了解，大概前端是怎么个运行逻辑是知道了。</p>
<p>第二次转机出现在上研究生之后，我参与了一个学校的项目，主攻前端。得益于大模型的发展，学习速度非常快。</p>
<p>再加上有cursor之类的编程工具协助，我很快就能独立开发出非常美观的前端界面了。</p>
<p>当然我也是看了些课程，以便了解前端的基础语法。这里主要是ts和vue3不懂，看了下尚硅谷的b站课程。效率不是很高，但我觉着也算是懂了不少吧。</p>
<p>上学之后也有些其他的经历，比如用python做数分的项目，尝试写了些微信小游戏和小程序。</p>
<p>就我个人而言，我觉得自己确实也算是真正成为一个合格的全栈开发了。</p>
<p>能独立完成前端、后端、移动端、数据库和运维部署的所有工作，作为打工人已经没什么太多可求的了。</p>
<p>我有段时间的QQ签名改成了一人成军，意思就是形容全栈可以一个人完成所有的开发工作。</p>
<p>写代码确实是很有意思的事情。</p>
<p>接触的东西多了以后，我开始有个想法：软件开发的各类工具只是表象，底层有两个东西，一是技术思维，二是业务知识。</p>
<p>技术思维有两种，一是直觉性的，看到一个东西就能反应过来应该怎么做，二是思考后得出的。</p>
<p>变为全栈之后，对我的技术直觉有了显著的提升。大多数的功能或架构，都能说上几句话，或者是在短短的时间内了解和掌握了。</p>
<p>我常常过于信任直觉性的思维，二忽视思考的结论，这是不对的。</p>
<p>业务知识是对具体业务场景的了解。技术总是趋向于无限增长的，总想得到最优解。但业务不是，业务知识充斥着边界和特例。这些边界和特例会反过来限制技术，让技术在到达某个界限后，就趋向于停止。</p>
<p>只有业务发展了，才会对技术有需求。否则技术发展更多的是一种学习研究性质的工作，不是用来解决具体问题的，没有落地的地方。</p>
<p>技术应该有前瞻性，但不应该过度，否则会对其他的资源造成挤压。</p>
<h2 id="前后的对比">前后的对比</h2>
<p>然后再聊聊我学了前端之后的理解。</p>
<p>前端我理解中更像是用代码在布设各种陷阱，设置好了之后等用户点击触发，再改变页面的逻辑。前端的数据来源之一是用户，用户在某个组件填写的内容，得直到点击发送按钮时才会用上。</p>
<p>后端则是从收到请求之后，运行各种复杂逻辑进行计算。</p>
<p>区别在于后端不需要布设多个组件进行组件的联动，后端收到的用户请求中就是所有的信息，其他信息得从数据库或其他持久化数据源用获取。后端更多的是数据的流转和计算。</p>
<p>这其实解释了为什么前端总是响应式的，前端的回调逻辑远多于后端。</p>
<h2 id="未来发展">未来发展</h2>
<p>现在讲究大前端，会写web，适当学一下就能写移动端和桌面端。</p>
<p>挺好笑的就是前端现在有点TS一统天下的味道了，而TS的语法总觉得和Java或者Python一个味道。</p>
<p>或者说未来大家的编程语言都会变成越来越像吧。</p>
<p>就像Java缺少了很多语法糖，而Python则充斥着各种语法糖，Go学了Python，也搞了很多类似的语法。</p>
<p>现在Java 21出来了，也在往这方向靠。</p>
<p>新时代的编程语言似乎在趋向于统一，都在往高级编程语言的方向进化。这也是这么多年来，无数程序员编码过程中的实践而产生的经验了。</p>
<p>编程语言这东西没必要卡这么死，大家到最后其实都差不多。</p>
<p>搞全栈不太好的地方就是样样都会，但很难样样都精通。以后可能最好还是走中间人或者管理的方向会比较好，毕竟啥都懂的人也是少数，要取长补短嘛。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title>秋招的总结</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E7%A7%8B%E6%8B%9B%E7%9A%84%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="经历">经历</h2>
<p>最开始是准备简历和找招聘信息，这部分就略过不谈。</p>
<p>麻烦的还是面试的准备，前期刷了leetcode的hot100，然后搞了一份80字面试宝典一点点看。</p>
<p>这些处理完已经到9月中旬了，这才慢慢投了一些厂子。</p>
<p>到十月国庆假期之后，才有一些笔试邀请过来。这时候已经是第二批次的秋招了，说实话互联网大厂的希望不大。</p>
<p>不过我也投了一个国企，还意外做了个行测。没怎么准备这种题目，说实话还是挺有意思的，感觉像智商测试。</p>
<p>等了一个月，到十月末，是华为给了面试的机会。</p>
<p>推荐人说粤港澳的面试安排有些混乱，想着在香港的同学线下跑去面试也不方便，也干脆给我安排走线上了。</p>
<p>一面在下午4点。</p>
<p>一开始是自我介绍，然后面试官挑项目经历问了些问题。</p>
<p>问了JNI是什么，为什么项目要用到JNI。回答提了一下Java的特性，JNI的用法和原理。</p>
<p>接着就继续从项目挑技术点问，中途话题被我带到了信创，就聊了不少信创的事情，感觉快变成纯聊天了。</p>
<p>一面大概是被安排了要问基础的问题，聊了一会儿之后面试官一拐话题说要继续问基础。</p>
<p>手撕挺简单的，给两个二进制字符串求和。这里我一边念题目一边说想法，然后再实现。</p>
<p>调试的时候出了一个bug，我说了一句Java不能多值返回就是麻烦，听到面试官笑了。</p>
<p>最后让我解释了一下调试时出现的问题原因，一面就结束了。</p>
<p>二面延后到了6点。</p>
<p>因为有些推迟了，面试官上来说直接做道题吧。</p>
<p>是一道分割整数数组的题，要求分割成三个数组，顺序不能变，数组和依次增大。问有几种解法。</p>
<p>还是一样，一边念题目一边说想法。写完面试官问了下几个优化的点。</p>
<p>然后就开始问项目，应该是想了解应聘者的技术思维吧。每个技术都问了下为什么这么做，有没有优化空间。</p>
<p>倒是都答上来了，有些比较复杂的回答就先把场景说明清楚。</p>
<p>中间提了项目中一些比较新奇的技术点，面试官也挺感兴趣的，就聊了挺久。</p>
<p>比较刁钻的就是问了下kafka有什么缺点。我一开始说不上来，就先扯了一句说它不信创，有些客户觉得可能影响项目的信创认证。然后才从技术角度回答了一下，主要是从不去中心化，对zk的强依赖（新版本用kraft去掉了），以及做消息防丢之后性能比较差这三个方面来说。</p>
<p>二面也顺利结束。</p>
<p>三面主管面是在9点。</p>
<p>上来主管先道歉，说拖了这么久，我说没关系。</p>
<p>跳过了项目拷打，主管说有工作经历相信技术上不会有问题。</p>
<p>先问为什么要重新去深造，会不会在华为工作以后也因为深造而离职。说上了研究生之后就像泄了气的皮球，没什么继续读书的兴趣。</p>
<p>接着问为什么选华为，我说我家里人都是花粉。面试官直接笑出声。</p>
<p>然后比较正式地回答是聊了下之前工作时做信创的经历，比较认可华为云自下而上从硬件层开始做信创的方案，认为公司有意愿去做其他公司不敢做的事，愿意在基础产品上投入。</p>
<p>举了个例子，之前在华为的服务器做压测，性能指标一直上不去。最后把JDK从openjdk换成华为的毕昇JDK，触发了软硬件协同，性能指标就一下子提上去了。</p>
<p>最后是关于压力，让我举个抗压的例子。先举了一个，不满意，然后再举。我说我为了读研究生考了7次雅思，第6次的时候崩溃大哭，但是收拾好心情继续去考了，最后终于过了。面试官边笑边说可以了。</p>
<p>反问环节，我说华为云内部是否很重视信创，给了肯定的回答。</p>
<p>结束时主管说希望还能再见到我，心理有预感已经过了。</p>
<p>晚上11点45准时收到面试的评价。</p>
<p>总体来说面试体验挺好的，虽然有些小插曲，但华为的员工们态度都很不错。</p>
<p>华为的面试之后，也就没有其他的面试流程了，秋招的拼搏阶段也算画上了句号。</p>
<h2 id="复盘">复盘</h2>
<p>如果要想一下还有什么能提高的，我觉得首先是自我介绍。</p>
<p>我发现很难在一两分钟内把自己所做过的所有事情都讲明白，一方面是经历比较丰富，一方面也是自己挑不到重点。</p>
<p>所以自我介绍还是得磨一磨，围绕项目把技术亮点重点说明，简单的经历就汇在一起用一句话带过。</p>
<p>第二个是下次春招要提前投递，这次秋招吃了不少的亏，主要是没有提前进行投递，导致没赶上9月的一批岗位。</p>
<p>最后是算法题，倒不是写不出来，就是我写得有点慢，这得再写一些题目才行。</p>
<h2 id="杂谈">杂谈</h2>
<p>仔细想想其实没面几家，算不上海投，算不上准备很充分，但大部分时候我也不就是这样轻轻松松就上了么。</p>
<p>就我个人而言，找工作这事情目前还不是特别急的一件事，秋招主要也是想打打基础。这么想的话就算这次最终结果不尽人意，可能也是可以接受的吧。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>找工作</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊低时延</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E8%81%8A%E8%81%8A%E4%BD%8E%E6%97%B6%E5%BB%B6/</url>
    <content><![CDATA[<h2 id="关于开发语言">关于开发语言</h2>
<p>市面上绝大多数低时延相关的产品，都会选择C++作为开发语言。不得不说，C++在处理这种场景有天然的优势，接近底层的好处就是可以做到硬件级别的优化。</p>
<p>我们公司的消息总线就更为离谱了，全面使用C语言进行开发，性能快到极致。</p>
<p>在Java这层，想利用硬件的优化，只能使用JNI的技术来调用C函数了。这会导致Java“一次编译处处运行”的能力不再生效，部署时要考虑的事情也会相应增多。</p>
<p>话又说回来，为了解决不同场景下要加载不同JNI的问题，我也是专门写了一个JNI加载框架。</p>
<p>同时，也经常会提到的一件事，就是Java的内存管理问题。JVM垃圾回收的随机性，会导致低时延业务可能随时中断，这是不可接受的。</p>
<p>市面上，对于Java的GC，最好的解决方式是使用ZingJDK。可惜是商业收费的，一般用不了。</p>
<h2 id="关于架构">关于架构</h2>
<p>公司对于低时延场景，做的架构我觉得并没有特别优秀。或者说并没有到让人有眼前一亮的感觉的那种地步。</p>
<p>我们的架构还是分了各种通道，把用户隔离到各个通道中。每个通道享有各自的CPU、线程以及内存数据库等信息。</p>
<p>通道本质是个数据隔离。</p>
<p>这种做法下，每个通道内的消息永远由一个线程来执行。那么这个通道内所有的操作，其实都可以做到无锁化了，因为自始至终都仅有一个线程进行读写操作。</p>
<p>这种方式下，运行时扩容几乎就是不可能的事情。同时，也对数据的分布有了一定的要求，假如某一个通道的用户成交数量特别多，也会影响到整个系统的吞吐量。理想状态下，用户应该是均匀分布在各个通道的。</p>
<h2 id="关于技术">关于技术</h2>
<p>低时延的技术栈中，最重要的一点就是无锁化。有锁就快不起来。</p>
<p>另外，内存技术也是挺重要的。Java就需要去操作堆外内存了，这确实是一般人接触不到的部分。</p>
<p>我专门写了一个给开发者的文档放在了公司的仓库里，大概整理了一些技术要点。</p>
<p>想了想，主要就三块：</p>
<p>1、内存技术。包括堆内堆外，CPU缓存，GC调优等。</p>
<p>2、序列化技术。包括Java对象的快速访问，协议编解码等。</p>
<p>3、并发技术。包括原子操作、disruptor、无锁队列等。</p>
<p>这些技术需要在构建低时延项目时时时刻刻关注，并写到代码中。</p>
<p>当然还有一个，就是测试框架和性能分析工具。比如Arthus、JMH等，这些也是需要掌握的技术点。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title>聊聊管理</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E8%81%8A%E8%81%8A%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h2 id="经历">经历</h2>
<p>从我工作以来，我一直在和管理打交道。</p>
<p>最初入职的时候，听了很多培训课。这些培训课上大多会教学一些工作方式，比如敏捷开发；也会教一些项目管理的基础知识。听了这些培训课，我对管理有了一些初步的认识，但那时候还没想太多。</p>
<p>接着是参加工作的第一年，大概知道了程序员以后要么转型技术管理，要么走技术专家的路线。</p>
<p>也是参加工作的第一年，在基本熟悉了工作内容后，领导很直接地分给了我一个大任务，要我去负责开发平台。作为平台的责任人，免不了向上汇报和向下管理。但是当时的情况下，向下也就一个实习生，另外就是一个专门做Java插件开发的程序员。这要谈管理，也管不上什么东西，但确实需要我作为中间人，去分配任务，监控进度了。</p>
<p>再往后是开发平台一期结束，开始规划低码平台，也就是二期的开发平台，这正好是我参加工作的第二年。低码平台用的是敏捷开发，我作为被管理的一方，参与了到里面。到这时候才算是正式入了管理的门。敏捷开发的节奏很快，每天都有明确的任务需求，这难免会让人感到压力巨大；不过工作的充实感很足，每天不需要迷茫，能充分发挥每个人的能力。这份经历对我影响很大。</p>
<p>第三年的时候，我开始鼓捣底层框架。低时延的技术也是这时候开始由我负责。不过很有趣的是，到这一年，反而没人到我手下工作了，我光杆司令一个。我一个人挑起了低时延组件的大梁，平时基本就是自己规划工作内容，自己写日报，最后定期和上级领导汇报进度。这段时间工作强度明显加大，也参加到了业务的第一线。</p>
<p>最后终于也是突破了底线，让我去了业务现场做支持。持续了六周，等我23年国庆后回到深圳，恍惚间觉得自己和还在公司里的这些同事有了天差地别。</p>
<p>有了在业务第一线的经历，我也终于名正言顺地升上了部门副经理。24年，考虑到我今年会离职去留学，领导分了三个同事到我手下，一方面是分担我的工作，另一方面是把我之前的工作成果沉淀下来，免得后面无人能维护我的代码。</p>
<p>而这时候，我也算正式升到管理岗，一方面要负责开发的工作，另一方面也需要管控工作进度，还要考虑下属的能力培养。慢慢的也有了一些自己的心得。</p>
<h2 id="领导力的来源是什么？">领导力的来源是什么？</h2>
<p>我觉得这是个很现实的问题。这里的领导力，就是你说的话到底算不算数，算几分数。</p>
<p>大多数时候，职级就是最现实的领导力来源。高职级的人能管控下属的绩效考评，就是等同于给了一定的权利来发布命令、指导工作。下属会倾向于获得更高的绩效来听取命令。</p>
<p>第二，我觉得是责任的承担问题。如果一个项目有负责人，那么他下属的所有行为他都要担责。而下属也会在听取命令时，想着：反正出问题了最后负责的不是我，就能一定程度上为自己开脱。</p>
<p>第三，是领导的个人能力。如果说领导能提出建设性意见，这是最能服众的一种手段了。下属遇到困难无法解决，而领导能上手解决问题，或是提供指导，这种类似师徒的观念，在中国人的心目中是最有效的建立上下级的方式。</p>
<p>第四，在于下级自身。人都有性格，有些人性格上认真负责，那么就应该给予重用，或者是通过言语的方式提供一定的鼓励或其他情绪价值；有些人怕事，内向，那么就应该做好思想工作，或是通过流程制度、团队建设的方式是来将其融入团队内部；有些人不负责，或是能力不够，应当给予批评，并指名改进的方向，屡教不改的，应该移出团队。</p>
<p>对于最后一种人，若是因为有复杂情况不能处理的，应该坦诚说明情况。不可因为此人影响到整体。这类人过多，则领导自己应该考虑跑路。</p>
<p>总体来说，要有领导力，首先应该有一定的技术水平，这是基础。水平高，则多多举行技术沙龙、代码评审、方案评审等，能服众，也能培养团队；水平低，则和技术骨干搞好关系，虚心听取意见，也是可以的。其次，要摆平心态，即不干扰下属工作，保持距离感；也要适度检查进度，施加压力。最后，是要鼓励和批评并举，好的要夸，坏的要批，保持自己的原则，让他人从心底里服从。</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>管理</tag>
      </tags>
  </entry>
  <entry>
    <title>路由权限问题导致的一次离奇Bug</title>
    <url>/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E8%B7%AF%E7%94%B1%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E6%AC%A1%E7%A6%BB%E5%A5%87Bug/</url>
    <content><![CDATA[<h2 id="起因">起因</h2>
<p>最近重新写了一个项目，本地运行时一直没什么问题，但是部署到服务器上时出现了打开前端页面一片空白的情况。</p>
<img src="/%E5%B7%A5%E4%BD%9C/work/%E6%9D%82%E8%B0%88/%E8%B7%AF%E7%94%B1%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E6%AC%A1%E7%A6%BB%E5%A5%87Bug/image-20250321191917050.png" class="" title="image-20250321191917050">
<p>大概表现就是如图中的情况，打开控制台看到有三个请求，分别是获取index.html，获取js和css，但是响应中是一片空白。</p>
<h2 id="环境">环境</h2>
<p>部署是在校内的服务器，外网无法访问。</p>
<p>前后端都部署在同一个服务器上，都使用docker构建镜像后部署。</p>
<p>前端是在docker中进行打包，并且装了nginx来渲染页面。</p>
<h2 id="排查">排查</h2>
<h3 id="查看nginx配置">查看nginx配置</h3>
<p>遇到这个情况，我第一反应是路由转发有问题，导致前端一直在请求什么东西卡死了。</p>
<p>所以去翻了下nginx的配置，确实发现路由转发还写的是老的服务器。</p>
<p>笑死，太简单了。</p>
<p>修改config文件，git commit，git push，然后重新部署镜像。</p>
<p>结果还是一模一样。</p>
<p>看来并不是转发的问题。</p>
<h3 id="查看nginx日志">查看nginx日志</h3>
<p>没辙，只能去翻下docker日志。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker logs [container]</span><br></pre></td></tr></table></figure>
<p>由于做了日志映射，nginx的日志会打印在docker的日志里。</p>
<p>翻了下有一条报错，是没获取到logo文件。</p>
<p>笑死，被我找到了。</p>
<p>于是改了下logo的读取方式，保证能读到logo文件。</p>
<p>git commit，git push，然后重新部署镜像。</p>
<p>打开页面，发现还是不行。</p>
<p>不信邪，再翻了下日志，已经没这个报错了。</p>
<p>看来也不是logo文件读不到的问题。</p>
<h3 id="查看docker脚本">查看docker脚本</h3>
<p>再去看了下docker的脚本，可能是端口映射的问题。</p>
<p>查看后发现也没什么问题。</p>
<p>但是想了想，也许是网络问题，修改了启动命令，加上了<code>--network=host</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -it --rm --network=host your_image curl http://localhost:8000</span><br></pre></td></tr></table></figure>
<p>这样docker会直接使用宿主机的网络配置，也就是没有端口映射这一说了。</p>
<p>某些情况下这样性能会好一些。</p>
<p>但改了之后还是没解决。</p>
<h3 id="查看docker内部文件">查看docker内部文件</h3>
<p>在看看nginx的运行日志吧。</p>
<p>先进入docker的镜像内部，这里用shell，因为镜像没装bash，不然用bash更方便些。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it [container] sh</span><br></pre></td></tr></table></figure>
<p>找了下nginx的日志，发现没什么异常。</p>
<p>再找了下前端的静态文件，也没看出来什么问题。</p>
<p>不信邪，试试在docker内ping了一下后端，发现也能ping通。</p>
<p>那看来网络是没什么问题了。</p>
<h3 id="查看本地打包的文件">查看本地打包的文件</h3>
<p>本地打包后的文件，我试着用serve来运行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npx serve -s dist</span><br></pre></td></tr></table></figure>
<p>运行后打开localhost，发现页面是正常的。</p>
<p>看来本地文件没问题。</p>
<h3 id="在服务器上打包">在服务器上打包</h3>
<p>重新登录服务器，在服务器上用npx serve来运行后端的文件。</p>
<p>提示没有npx。</p>
<p>行吧，那先安装npm。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install npm</span><br></pre></td></tr></table></figure>
<p>再执行，说node版本太低，只有12。</p>
<p>那再升级node。先装个nvm。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash</span><br></pre></td></tr></table></figure>
<p>然后让nvm生效。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source ~/.nvm/nvm.sh</span><br></pre></td></tr></table></figure>
<p>最后nvm安装node 18，再切换到18。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvm install 18</span><br><span class="line">nvm use 18</span><br></pre></td></tr></table></figure>
<p>用node的命令查了下，确实是18了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>
<p>终于完事，再用npx serve启动。</p>
<p>发现打开是404。</p>
<p>？？？</p>
<p>看了下是服务器上没build后的静态文件。</p>
<p>行，那先安装。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install</span><br><span class="line">npm run build</span><br></pre></td></tr></table></figure>
<p>在本地用浏览器打开，居然也是一片空白。</p>
<p>？？？</p>
<p>至少复现了是吧。</p>
<p>看来不是网络问题，就是前端打包后的静态文件有问题。</p>
<p>脑袋里面灵光一闪，重新在本地起了下前端，这次不用localhost，用本机的IP来访问。</p>
<p>发现也是空白。</p>
<p>这下在本地复现了。</p>
<h3 id="询问AI">询问AI</h3>
<p>成功复现至少是成功了90%。</p>
<p>目前看下来，关键点在与用localhost能正常访问，而使用其他的IP则不行。</p>
<p>问了下AI，可能是什么原因。</p>
<p>提示说可能是cros，也可能是使用的命令不对，还有可能是防火墙问题。</p>
<p>都试了下，还是没解决问题。</p>
<h3 id="回退版本">回退版本</h3>
<p>最后无奈之下，开始回退版本。</p>
<p>用git命令回退到之前的版本，看看是哪个提交导致了目前的问题。</p>
<p>首先回退到之前改了logo的那次提交，发现不行。</p>
<p>再回退到这个提交的前一个。</p>
<p>启动，居然正常显示了？</p>
<p>ok，锁定是这个提交的改动有问题。</p>
<p>于是逐个逐个回退文件的改动。</p>
<p>回退到修改主页重定向的时候，页面正常显示了。</p>
<p>好，找到问题了。</p>
<h2 id="修复">修复</h2>
<p>分析一下，是路由守卫和主页重定向有冲突。</p>
<p>当时让未登录的用户会重定向到一个文档管理页面，而这个文档管理页面被路由守卫了，需要用户进行登录才可访问。</p>
<p>一来一去，死循环了，于是页面就卡死了。</p>
<p>那么为什么用localhost可以正常访问？</p>
<p>因为有浏览器缓存，会保持用户的登录状态。而其他的路由没有缓存，需要重新登录，于是就会进入死循环。</p>
<p>修改了这个逻辑，添加了一个未登录也可访问的落地页，让用户先在这个页面登录。</p>
<p>修改后重新构建，已经能正常渲染了。</p>
<h2 id="结论">结论</h2>
<p>重新看下来，debug的过程就是要对整个部署流程、前端渲染过程有一定的了解。</p>
<p>我还是有些依赖个人的经验，导致我直接从最大可能的地方入手，进行排查。</p>
<p>当然也确实一下子就找到了一个问题（虽然和最终的问题无关）。</p>
<p>但仔细想想，主要也是对前端不熟悉，很多时候就缺少了些验证手段。</p>
<p>这次都是现査工具现用的。</p>
<p>不过这样解决问题，才能让人有所成长吧？</p>
]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>前端</tag>
      </tags>
  </entry>
</search>
