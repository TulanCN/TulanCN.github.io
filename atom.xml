<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>涂蓝</title>
  
  
  <link href="https://tulancn.github.io/atom.xml" rel="self"/>
  
  <link href="https://tulancn.github.io/"/>
  <updated>2025-03-10T13:52:48.138Z</updated>
  <id>https://tulancn.github.io/</id>
  
  <author>
    <name>Tulan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>SSE协议和流式输出</title>
    <link href="https://tulancn.github.io/2025/03/09/work/SSE%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA/"/>
    <id>https://tulancn.github.io/2025/03/09/work/SSE%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA/</id>
    <published>2025-03-09T03:17:03.000Z</published>
    <updated>2025-03-10T13:52:48.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="流式输出">流式输出</h2><p>大多数的聊天机器人都会用到流式输出。为什么一定要用这能力呢？</p><p>任何的LLM的回答都是逐字逐句生成的，因此使用同步调用一次获取所有的消息，会造成长时间的阻塞。</p><p>尤其是DeepSeek R1这类推理模型，在给出正式的回答前还有大段大段的思考文本，这让用户的等待时间更加长了。</p><p>同时，一个请求的超时时间过长会带来其他副作用，比如用同步调用很难判断是LLM服务挂掉了还是单纯生成内容很长所以一直没回答。</p><p>因此，为了提升用户体验，减少后端一些不必要的麻烦，流式输出在目前的AI应用中越来越重要了。</p><h2 id="SSE-Server-Sent-Events-协议">SSE (Server-Sent Events) 协议</h2><h3 id="SSE协议概念">SSE协议概念</h3><ul><li>SSE（Server-Sent Events）是一种服务器推送技术，允许服务器向客户端发送事件流</li><li>它建立在HTTP协议上，使用标准的HTTP连接，但允许服务器持续向客户端推送数据</li><li>SSE连接是单向的（只能服务器向客户端发送数据），与WebSocket不同（WebSocket是双向通信）</li><li>SSE适用于实时通知、实时日志、聊天应用等场景</li></ul><h3 id="SSE协议技术特点">SSE协议技术特点</h3><ul><li>使用标准HTTP连接，不需要特殊协议或端口</li><li>自动重连功能，断开连接后会自动尝试重新连接</li><li>使用纯文本传输，每条消息格式为<code>data: 消息内容\n\n</code></li><li>支持事件ID和事件类型，便于客户端处理不同类型的消息</li><li>比WebSocket更简单，更容易实现，但功能稍弱</li></ul><h3 id="技术选型">技术选型</h3><p>后端使用的是<code>FastAPI</code>，本身就有很好的流式输出支持。</p><p>前端则是使用了<code>@microsoft/fetch-event-source</code>库，因为这个库允许修改请求头的内容，方便做鉴权。</p><h3 id="项目中SSE的应用">项目中SSE的应用</h3><ol><li><strong>后端实现（FastAPI）</strong><ul><li>使用<code>FastAPI</code>的<code>StreamingResponse</code>实现流式响应</li><li>通过异步生成器<code>serialize_generator</code>生成SSE数据流</li><li>标准SSE格式: <code>data: JSON数据\n\n</code></li><li>使用<code>time.sleep(0.05)</code>控制响应速率，避免客户端接收过快导致丢包</li></ul></li><li><strong>前端实现（Vue 3 + TypeScript）</strong><ul><li>使用<code>@microsoft/fetch-event-source</code>库处理SSE连接</li><li>在<code>frontend/src/utils/request.ts</code>中封装了<code>sseRequest</code>函数</li><li>支持请求头设置、身份验证、错误处理和连接状态管理</li><li>通过<code>parseSSEMessage</code>函数解析接收到的SSE消息</li></ul></li></ol><h2 id="打字机">打字机</h2><h3 id="为什么要做打字机效果">为什么要做打字机效果</h3><p>由于网络波动，后端的推送并不是匀速到达客户端的。如果前端仅仅是收到一条消息就拼接到前端的文本上，那么最终效果就会显得很呆。</p><p>通过在前端添加一个缓冲队列，来让字符匀速显示，会让前端的展示效果显著提升。</p><p>就是俗话说的&quot;质感&quot;。</p><h3 id="核心功能">核心功能</h3><ul><li>实现了文字逐字打印的动画效果</li><li>支持动态调整打字速度</li></ul><h3 id="技术实现">技术实现</h3><ul><li>使用TypeScript实现类封装</li><li>采用缓冲区设计模式存储待显示的文本</li><li>使用定时器控制打字速度</li><li>提供丰富的回调函数支持，如<code>onComplete</code>、<code>onPause</code>等</li></ul><h2 id="总结">总结</h2><p>整体逻辑其实很简单，SSE+前端打字机。</p><p>前端本身就是响应式的，所以代码实现其实不麻烦，直接往文本框里拼接字符就行，甚至有点简单。</p><p>但不管怎么说，SSE协议在AI应用中目前使用应该是最为广泛的，几乎所有项目都得走这个流程。</p>]]></content>
    
    
    <summary type="html">最近在项目中用到了SSE协议，这里简单写下怎么接入的。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="技术协议" scheme="https://tulancn.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>我也是全栈</title>
    <link href="https://tulancn.github.io/2025/02/28/work/%E6%88%91%E4%B9%9F%E6%98%AF%E5%85%A8%E6%A0%88/"/>
    <id>https://tulancn.github.io/2025/02/28/work/%E6%88%91%E4%B9%9F%E6%98%AF%E5%85%A8%E6%A0%88/</id>
    <published>2025-02-28T14:07:08.000Z</published>
    <updated>2025-03-10T13:49:45.421Z</updated>
    
    <content type="html"><![CDATA[<h2 id="经历">经历</h2><p>如果说我是什么时候有这个想法，那我觉得最早应该要追溯到大一的时候了。</p><p>当时刚入学，正在军训。我们有一次思想测验，当时年级里有同学搭了一个网站供我们考试。</p><p>刚上大学的我对这操作惊为天人。</p><p>后来从别人那了解到，这些东西在大二的时候基本都会教。</p><p>可惜，事实是直到大三我都不知道他们是怎么搭建的这网站。</p><p>接着就是实习，才开始对软件开发有了些概念。了解了前端、后端，各种开发语言，各种基础概念。也算是开始学以致用了。</p><p>毕业之后，我开始工作。</p><p>还记得上班的第一天，部门最大的领导过来有个谈话的环节。</p><p>海航总问我们，你们有什么目标吗？</p><p>没人回应。</p><p>稍稍沉默之后，我鼓起勇气回答道：“我想做全栈。”</p><p>我觉得这就是我开始有做全栈的决心的时候。</p><p>时光飞逝，我不断加深着后端的技能。数据库，运维部署，监控，开发框架，缓存，流量治理，网络通讯，这些点在我工作的这些年里我也慢慢加深了解。</p><p>唯独前端一直没什么进展。</p><p>我一直就是维持在有个前端项目，可以在我本地运行起来的这么个程度。</p><p>第一次转机出现在第二年年末，我去做低码平台的项目。</p><p>当时前端资源紧缺，很多细节让前端来改实在是有些慢了。我就看了下vue2的语法，还有前端的基础入门，就上手改一下样式和bug之类的。</p><p>当时算是有了个基本的了解，大概前端是怎么个运行逻辑是知道了。</p><p>第二次转机出现在上研究生之后，我参与了一个学校的项目，主攻前端。得益于大模型的发展，学习速度非常快。</p><p>再加上有cursor之类的编程工具协助，我很快就能独立开发出非常美观的前端界面了。</p><p>当然我也是看了些课程，以便了解前端的基础语法。这里主要是ts和vue3不懂，看了下尚硅谷的b站课程。效率不是很高，但我觉着也算是懂了不少吧。</p><p>上学之后也有些其他的经历，比如用python做数分的项目，尝试写了些微信小游戏和小程序。</p><p>就我个人而言，我觉得自己确实也算是真正成为一个合格的全栈开发了。</p><p>能独立完成前端、后端、移动端、数据库和运维部署的所有工作，作为打工人已经没什么太多可求的了。</p><p>我有段时间的QQ签名改成了一人成军，意思就是形容全栈可以一个人完成所有的开发工作。</p><p>写代码确实是很有意思的事情。</p><p>接触的东西多了以后，我开始有个想法：软件开发的各类工具只是表象，底层有两个东西，一是技术思维，二是业务知识。</p><p>技术思维有两种，一是直觉性的，看到一个东西就能反应过来应该怎么做，二是思考后得出的。</p><p>变为全栈之后，对我的技术直觉有了显著的提升。大多数的功能或架构，都能说上几句话，或者是在短短的时间内了解和掌握了。</p><p>我常常过于信任直觉性的思维，二忽视思考的结论，这是不对的。</p><p>业务知识是对具体业务场景的了解。技术总是趋向于无限增长的，总想得到最优解。但业务不是，业务知识充斥着边界和特例。这些边界和特例会反过来限制技术，让技术在到达某个界限后，就趋向于停止。</p><p>只有业务发展了，才会对技术有需求。否则技术发展更多的是一种学习研究性质的工作，不是用来解决具体问题的，没有落地的地方。</p><p>技术应该有前瞻性，但不应该过度，否则会对其他的资源造成挤压。</p><h2 id="前后的对比">前后的对比</h2><p>然后再聊聊我学了前端之后的理解。</p><p>前端我理解中更像是用代码在布设各种陷阱，设置好了之后等用户点击触发，再改变页面的逻辑。前端的数据来源之一是用户，用户在某个组件填写的内容，得直到点击发送按钮时才会用上。</p><p>后端则是从收到请求之后，运行各种复杂逻辑进行计算。</p><p>区别在于后端不需要布设多个组件进行组件的联动，后端收到的用户请求中就是所有的信息，其他信息得从数据库或其他持久化数据源用获取。后端更多的是数据的流转和计算。</p><p>这其实解释了为什么前端总是响应式的，前端的回调逻辑远多于后端。</p><h2 id="未来发展">未来发展</h2><p>现在讲究大前端，会写web，适当学一下就能写移动端和桌面端。</p><p>挺好笑的就是前端现在有点TS一统天下的味道了，而TS的语法总觉得和Java或者Python一个味道。</p><p>或者说未来大家的编程语言都会变成越来越像吧。</p><p>就像Java缺少了很多语法糖，而Python则充斥着各种语法糖，Go学了Python，也搞了很多类似的语法。</p><p>现在Java 21出来了，也在往这方向靠。</p><p>新时代的编程语言似乎在趋向于统一，都在往高级编程语言的方向进化。这也是这么多年来，无数程序员编码过程中的实践而产生的经验了。</p><p>编程语言这东西没必要卡这么死，大家到最后其实都差不多。</p><p>搞全栈不太好的地方就是样样都会，但很难样样都精通。以后可能最好还是走中间人或者管理的方向会比较好，毕竟啥都懂的人也是少数，要取长补短嘛。</p>]]></content>
    
    
    <summary type="html">最近突然发现自己已经可以算是全栈了，想回顾一下自己的心路历程。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>聊聊AI工具和学习</title>
    <link href="https://tulancn.github.io/2025/02/15/study/%E8%81%8A%E8%81%8AAI%E5%B7%A5%E5%85%B7%E5%92%8C%E5%AD%A6%E4%B9%A0/"/>
    <id>https://tulancn.github.io/2025/02/15/study/%E8%81%8A%E8%81%8AAI%E5%B7%A5%E5%85%B7%E5%92%8C%E5%AD%A6%E4%B9%A0/</id>
    <published>2025-02-15T11:54:17.000Z</published>
    <updated>2025-03-10T13:54:25.192Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>上次nlp的project被同学宣传了一下，后来有人来交流，就被拉去给老师做项目了。</p><p>名义上是当了student assistant，工资也是按照这个待遇来。80港币一小时，说实话还不少。</p><p>项目是关于一个AI论文的平台，希望能借用AI工具来对论文进行编写、修改和润色。功能倒是挺简单的，我觉得主要难点还是在设计和实现上。</p><h2 id="难点">难点</h2><p>我觉得第一个难点是人力的缺失，更准确地说是协作的方式。虽说我后来又找了3个人来，组成了6人小队，但还是觉得人手不够，做事不够快。</p><p>从数量上来说，这点人肯定是够了，但我觉得暂时没找到很好的协作方式。换句话说，也就是没能把这6个人的能力全部发挥出来。</p><p>这也是很痛苦，没什么办法的事情，毕竟项目管理本就是一个很困难的事情。</p><p>第二个难点应该是设计的问题。目前没有产品经理的角色，实际上很多功能的设计上是缺失了有人把关。甚至更严重的是，我们所有人都是身兼多职，既要看产品怎么样，又要看怎么实现。</p><p>这种体验倒是和初创团队差不多了。</p><p>没有专业的设计团队，难免会导致功能上可能少东少西，甚至交互上也会很反人类。</p><p>第三个难点在于测试和验收。目前也没有测试人员，功能的验收是没有人把关的。做得怎么样，怎样算好，有没有bug，这些大家在做完之后都没有反馈的渠道。</p><p>没有结果的反馈，也就很难进一步提高了。</p><p>第四个难点在于缺少标准的制定。管理团队最重要的就是制定标准，标准是协作的基础。人并不可靠，但完善的标准可以让人变可靠。这话对AI也同理。目前我们后台日志打印的方式、异常的抛出、前端的请求方式都没有统一的标准制定出来。这些得尽快解决了。</p><h2 id="预期">预期</h2><p>聊完难点，不妨畅想一下预期。</p><p>我理想中的团队，应该是抱有热情、持续产出、愿意钻研的。他们每天都能提交一定的代码，推进一定的工作。定时上线开会，有问题及时沟通。大胆指出目前工作中不合逻辑的地方，并且提出改进意见。</p><p>显然目前还达不到。</p><h2 id="使用AI工具开发">使用AI工具开发</h2><p>前面感觉都扯远了，这里回到正题，再聊聊AI工具和学习。</p><p>这里的AI工具，应该说特指cursor这类编程工具了。</p><p>比较好笑的是，我居然是这次项目中负责写前端的人。可实际上我并不懂前端，ts基础语法都没认真学过。</p><p>但目前看下来，我甚至都不算是拖后腿的那个人。</p><p>感谢cursor，让我有了这种体验。</p><p>前端我也不是没学，也花了点时间看了下尚硅谷的Vue3前端入门教程。只不过暂时还没看完罢了。</p><p>我觉得过段时间可以把尚硅谷的项目完整做一下，还是挺有意义的。</p><p>整体编写项目前端的过程，让我觉得最重要的还是知道目标，然后提出自己的需求。</p><p>AI工具已经非常智能，只要在输入指令的时候带上那么一点点技术的关键词，基本上就可以帮你实现各种需求了。</p><h2 id="使用AI工具学习">使用AI工具学习</h2><p>但凡事皆有代价。使用AI工具来开发，其实很大程度上属于是用长期的提高和理解，换取暂时的成果。</p><p>使用cursor我写了相当多的代码，但代价就是我还是觉得自己对Vue3一窍不懂，不能写代码。</p><p>感觉是离了cursor不会写代码了。</p><p>这种体验很差，短期看到有美观的页面生成确实让人多巴胺快速分泌，有满足感。</p><p>这种感觉一旦过去，充斥心头的是一种迷茫和空虚。</p><p>频繁使用AI只会让自己变得没有长进。你增长的只有使用AI的能力，而不是做事情的能力。</p><p>这也让我觉得有些恐慌。</p><p>也是第一次有了AI是不是会取代我的工作的焦虑感。</p><p>最讽刺好笑的事情也是在这。如果现在想要快速学习新的知识，借助AI工具也是最快的。</p><p><strong>如果你愿意在每次生成代码之后，让AI工具解释一下它为什么这么写，它会是最好的导师。</strong></p><p>我觉得现在学一个新技术，最难的还是不知道roadmap。</p><p>而AI打破了这个知识搜集的过程，大部分时候它是可以提供一些可靠的roadmap，让你知道自己应该先学什么，后学什么。</p><p>我个人比较喜欢的路径是，先quick start看到成果，然后逐步深入其中的每一个步骤，理解其原理。</p><p>凭借多年的技术直觉，我觉得很多时候自己还是可以问出一些很有用的问题，从而获得最合理的AI答复。</p><p>动手学习确实比单纯听讲要好得多。</p><h2 id="总结">总结</h2><p>最近是接了一个项目，遇到了不少困难。</p><p>然后我也开始写前端了，在编写的过层中我大量使用了AI。</p><p>这让我思考为什么要用AI，AI的能力边界在哪。</p><p>我决定以后要慎重使用AI，在使用完之后多问一句为什么，从而实现在实践的过程中提高自己的技术水平。</p>]]></content>
    
    
    <summary type="html">最近在跟着老师做项目，尝试梳理下自己的一些想法。</summary>
    
    
    
    <category term="学习" scheme="https://tulancn.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习总结" scheme="https://tulancn.github.io/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>股市投机的原则</title>
    <link href="https://tulancn.github.io/2024/12/13/life/%E8%82%A1%E5%B8%82%E6%8A%95%E6%9C%BA%E7%9A%84%E5%8E%9F%E5%88%99/"/>
    <id>https://tulancn.github.io/2024/12/13/life/%E8%82%A1%E5%B8%82%E6%8A%95%E6%9C%BA%E7%9A%84%E5%8E%9F%E5%88%99/</id>
    <published>2024-12-13T08:49:54.000Z</published>
    <updated>2025-03-10T13:55:47.433Z</updated>
    
    <content type="html"><![CDATA[<h2 id="A股的底层逻辑是博弈">A股的底层逻辑是博弈</h2><p>这是对A股市场中股价波动的解释。在A股市场中，几乎没有人是通过分红的复利来实现财富增长和价值投资的。</p><p>那么，所谓的政策利好其实也只是给赌徒们指明了一个方向：下一波我们炒这个。</p><p>各类大资金做局，通过政策指引等方式制造热点，让散户和其他游资集中到某个股票中，然后大资金们出手给小资金，小资金出售给散户。</p><p>这里分两种情况来讨论：</p><p>第一种：新热点出现导致某个版块普涨。某些政策出台后，会对某些版块产生明显的利好。这时候短线资金会集中到这个版块中，不同资金会随机寻找版块中的某个股票买入，导致版块中的股票呈现出不同的涨幅。</p><p>某些股票涨幅大，那么就会吸引更多的散户和其他大资金来买入，最终表现就是封板。</p><p>一个版块中可能有多支股票都是涨停的，那么第二天就会继续在这些股票中寻找能继续封版的股票，也就是所谓的一进二，二进三等。</p><p>假如有其他的热点出现，可能这些昨天涨停的票今天都会跌。</p><p>假如市场上的其他人不认账，那这些票可能今天也会继续跌下去。</p><p>还有种可能是其他人继续追高，在昨天形势较好的股票中选择某几个继续大量买入，这时候就会出现连板。</p><p>连板中，会有些票会掉队，因为市场上参与的资金是有限的，击鼓传花的游戏在某一个时刻会因为没有其他人来买而结束。</p><p>资金会集中向头部的股票，直到头部的股票价格过高，没有人愿意再买了。</p><p>如果热点足够吸引人，还会有补涨。就是头部的连板票带动了市场中其他版块的活跃资金也参与到本版块中，其他的活跃资金可能因为前排的连板票买不到而选择去买入同版块还没炒起来的股票。这种被其他资金选择的票可能也会连板，并且在头部的连板票破板时，成为市场上资金新的宠儿。</p><p>头部的连板票，一般称为龙头；补涨的票，称为补涨龙。还有些票，一直随着版块在偷偷涨，但没有涨停，这种称为中军，一般是市值较大的白马股。</p><p>第二种：版块的资金回流。龙头崩了之后，势必会带动大量的资金一起抛售，这时候股价跌停都是正常的。</p><p>但是在跌停时，可能有资金认为这票还能涨，于是在低位进行接盘。当有足够多的资金认为还能涨时，就会出现弱转强，也就是资金的回流。</p><p>比如昨天龙头跌停，预期是今天继续跌停。但是实际上开盘是正，并且股价起飞，那么就可以认为有人觉得这票还能涨。如果弱转强的共识足够，那么就能把本来短板的龙头重新抬起来继续涨。</p><p>弱转强是非常常见的，同时也是相当有效的赚钱手段。</p><p>这里讲了两种博弈的方式，其实简单概括，就是先信卖给后信。</p><h2 id="设立止损目标">设立止损目标</h2><p>在赚钱时，也应该设立止损目标，比如利润回撤到3%就清仓。</p><p>无论如何，少赚总比不赚好。如果利润回撤了，就说明肯定有更好的清仓时机，应该去思考什么时候清仓更合适，而不是死扛把利润都亏空了。</p><p>在亏钱时，也要设立止损目标。止损是个麻烦事儿，大部分人总会妄想自己后面可以重新赚回来。但止损时应该想的是自己为什么当时会去买入这个股票，说明需要优化买入时机。</p><h2 id="不做自己不了解的行业">不做自己不了解的行业</h2><p>自己不了解的行业，可能会导致决策失误，进而导致亏钱。</p><p>只做自己了解的行业是对自己负责。</p><h2 id="不做太小的票">不做太小的票</h2><p>如果一个票的市值过小，可能随意一个游资都能在这票坐庄。</p><p>庄股是最恶心的，上涨和下跌没有任何规律可言。</p><h2 id="尽量做股性活跃的票">尽量做股性活跃的票</h2><p>股性活跃，指的是这个版块有利好时，大部分资金都会首先选择买入这个股票。这种股票在长期活跃的版块都有存在。</p><p>可以说大家可能对老龙都有记忆吧，每次有利好都优先把以前连板过的票拉出来再炒一次。</p><h2 id="少碰kdj在20-80之间的票">少碰kdj在20-80之间的票</h2><p>kdj指标说明了短期一支股票的超买和超卖的情况。如果一个股票的kdj在20-80之间，大概率说明这票最近没什么人在炒。</p><p>没人炒的票持有了也很难获得大量收益。</p><h2 id="遵循自己的规则">遵循自己的规则</h2><p>设立自己的交易规则，严格遵守规则，并在复盘时适时调整规则。</p><p>交易时间一定要按照自己的交易规则来进行交易，东买一个西买一个总有一天赚的都要亏回去。</p><p>如果一次交易是亏钱的，说明交易规则有问题，想办法调整并避免以后还出现类似的问题。这种态度才是正确的。</p>]]></content>
    
    
    <summary type="html">股海浮沉，总结了几条对自己有帮助的原则，希望自己能继续遵守。</summary>
    
    
    
    <category term="生活" scheme="https://tulancn.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="投资" scheme="https://tulancn.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>NLP的project复盘</title>
    <link href="https://tulancn.github.io/2024/11/22/study/NLP%E7%9A%84project%E5%A4%8D%E7%9B%98/"/>
    <id>https://tulancn.github.io/2024/11/22/study/NLP%E7%9A%84project%E5%A4%8D%E7%9B%98/</id>
    <published>2024-11-22T06:57:31.000Z</published>
    <updated>2025-03-10T13:56:09.342Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>这是第一门需要协作的大作业，过程中着实暴露了很多问题。我觉得是需要复盘来明确这些问题，以免在下次的作业中再有类似的情况发生。</p><p>项目要求是利用大模型的技术，结合课上所学的NLP相关知识，来开发一个对话模型。最终这个系统能做到让用户通过自然语言来查询某个领域的数据。</p><h2 id="过程">过程</h2><h3 id="第一次会议">第一次会议</h3><p>一开始可能是大家还不熟，我作为脸皮最厚的主动出来破冰。</p><p>这就像无领导小组讨论第一件事就是选领导；分布式等价节点一致性算法第一件事就是选主节点；Project第一个跳出来的人也会成为组织的核心。</p><p>之后就基本围绕着我的思路，开始选题，分配预研任务。我确定了一下开会的频率和任务的大致分配方向，以及日常的沟通方式，代码提交的仓库，保证这个项目推进必要的一些因素都已具备，第一次会议就算结束。</p><p>打算是分三周，第一周预研，第二周产出第一个demo，第三周产出最终的。</p><h3 id="第二次会议之前">第二次会议之前</h3><p>我这边主要是要预研RAG的基础框架和前端界面。</p><p>说实在的我也没多上心，粗看了一下AnythingLLM，跑了下本地模型发现展示的效果还可以。然后接入本地模型、通义千问和其他的一些模型试了下，认为这个框架基本可用，就算完事了。</p><p>数据爬取的任务倒是做得还可以，能拉到三个网站的数据。</p><p>需求分析决定了后续的提示词怎么写，这部分最终产出不是很标准，但也算有模有样，可以列入工作内容的一部分。</p><h3 id="第二次会议">第二次会议</h3><p>原先预订是第二次会议前要有产出的demo，所以第二次的会议上我就展示了一下AnythingLLM。其他的一些沟通已经没多少印象了，大概就是确定要做什么之后，直接进入模型微调的阶段了。</p><h3 id="第三次会议">第三次会议</h3><p>原先预定是在第二周产出一个demo，但是用AnythingLLM这个demo产出比我想得要快太多了…</p><p>然后第二周的目标在周二就算提前完成，摸了会儿鱼一直拖到第三周才进行第三次会议。</p><p>这第三次会议上演示了一下纯使用AnythingLLM的成果，客观来说包装一下作为汇报用的结果还真可以。</p><p>不过还是想着再做些事情，于是会后我又花了点时间去写了下插件。</p><h3 id="第三次会议后">第三次会议后</h3><p>由于我也没怎么写过python的工程，先花了点时间看了下python的工程结构。</p><p>插件开发需要模型支持，就想着先把模型从AnythingLLM搬到了阿里云的百炼平台上，花了一个小时吧。</p><p>看了下模型怎么自定义插件的文档，本来还想找找阿里云有没有提供案例，结果发现没有。</p><p>那没辙，先理解再说。</p><p>翻了下就是自己部署一个web服务，然后提供OpenAPI 3.0的接口文档和一个告知模型在什么情况下需要调用插件的prompt。那就简单了，实际的功能代码有现成的，我只需要把这些能力集成到web服务里就行。</p><p>于是开始翻怎么用python写web服务，发现有个quart的框架，快速写了demo，结论是可行。</p><p>找了下阿里云有免费的试用服务器，租了一个4核8G的服务器，ping了它的公网IP，通了。那这服务器也好说。</p><p>部署服务到云服务器，一调用发现不通。怀疑是权限问题，去控制台找了下权限控制的功能，开通端口，再调用通了。这部署也算完成。</p><p>用AI生成了OpenAPI 3.0的接口文档，接着写prompt，最后在百炼上创建一个插件，这样就算集成了。</p><p>调试了一下大模型调用插件的效果，发现还不错，至此完成了插件的功能。</p><p>最终的效果给同组的同学展示了一下，都说很可以。给他们开通了子账号的权限，每个人都能调整模型的prompt和看到最终的效果。</p><p>随后的时间就是准备pre和最终的report。</p><h2 id="复盘">复盘</h2><h3 id="问题分析暴露了思维的差异">问题分析暴露了思维的差异</h3><p>简单分析一下，在模型侧，要通过一些手段来让模型了解某个领域的数据。那么很自然就会想到专家模型，想到微调，接着答案就呼之欲出——RAG。</p><p>对，其实能做到RAG，这个项目基本已经完成了。</p><p>那么就涉及到数据来源的问题，这里就出现了第一次的思维差异。我倾向于额外添加插件的能力，能让模型获取到更具有时效性的信息。而其他人似乎并没有意识到这个能力的必要性，认为这个能力优先级不高，能先处理好RAG就可以了。</p><p>其次就是这个选题的方向是什么，大家一开始都没什么点子，于是我提出用头脑风暴的方式来发散思维。最终确定是做一个关于招聘信息的助手。</p><p>到最后，我干脆直接拉出日程表，列了下整个工作的日程和计划，也拟定了一些里程碑目标出来。大家也没多说什么，一下子就同意了。</p><h3 id="工作方式的妥协">工作方式的妥协</h3><p>如果是企业中接到一个项目，可能我第一反应是确定好日程计划，然后拉人开会，对齐拉通保证大家思维的一致性，留好联系方式，有什么问题及时调整。</p><p>但是实际在这个project的执行过程中，一来大家都挺陌生，不知道对方几斤几两；二来工具不齐，想做项目管理多多少少有些麻烦。最后只能妥协，用腾讯文档作为项目管理的一环，github作为配置库，以及任务分配全靠自觉。</p><p>所幸大家都还算给面子，仗着年纪大脸皮厚大家还算愿意听我讲话。</p><p>还有就是远程办公，在微信群沟通确实效率过于低下了，我个人会更喜欢用远程会议的方式来快速沟通。而且大家也不是集中在一处专心做这个project，互相之间配合和协调也是个问题。</p><p>最终妥协的成果，就是把任务提前分隔成较为独立的子任务，每个人认领其中一部分。然后我作为最终的统筹，收集各个成员的产出，并拼凑为一个较为合理的产物。</p><p>就我个人而言，这些都不算什么工作量，但是对于其他人而言可能会有些困难，毕竟没什么管理经验。所以我来担任也算是比较合理的。</p><h3 id="留好成长的空间">留好成长的空间</h3><p>整个过程中一直在强调要沟通，每个人的提交都能让其他人在本地运行。本意是想让每个人都参与进来，能看到project的当前的效果。</p><p>但第一个迭代这个事情做得不是很好。所以第二个迭代我就全面上云，让每个人都能参与进来。</p><p>我觉得一个项目的推进过程中，项目中的每个人都应该是有所成长的。作为领导，一定会注意经验的复用和下属的培养。</p><p>对于这个project来说，就是要给愿意学的人，留好空间，把想学的东西放在每个人随时都能够得到的地方。</p>]]></content>
    
    
    <summary type="html">管理亦是一门妥协的艺术。不要以企业的标准来要求学生。</summary>
    
    
    
    <category term="学习" scheme="https://tulancn.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习总结" scheme="https://tulancn.github.io/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>回炉重造是种什么样的感觉？</title>
    <link href="https://tulancn.github.io/2024/11/20/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/"/>
    <id>https://tulancn.github.io/2024/11/20/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/</id>
    <published>2024-11-20T05:32:12.000Z</published>
    <updated>2025-03-10T13:55:54.636Z</updated>
    
    <content type="html"><![CDATA[<h2 id="就读体验">就读体验</h2><p>整体来说，在polyu的就读体验还算不错。</p><p>各种流程都会有较为详细的指引。比如入学、选课、课程的考试之类的日常流程，都有邮件会提醒，邮件中会有很详细的说明，足够每个人完成这些。</p><p>每个学生也都会收到不少附赠的资源，比如学生的云电脑有两块免费的4090ti可用。在学校想训练自己的大模型，或是做一些微调都足够用了。</p><p>同学倒是也都挺实在的。毕竟排名是港三之外吧，挺少见到本科985的同学，遇到的985也大多是转方向来读计算机的。像我这种工作4年再来读书的确实是少数的少数。这也导致了遇到的同学大多很佛系，不太在意成绩，大多是一个能过就行的态度。某种意义上倒也挺符合对港留子的刻板印象的。</p><p>虽说绝大部分人都是抱着一个拿到学位就算成功的态度，但同学中也有少数比较卷的，大部分是local，目标都是继续深造读博。</p><p>学校的课也不算太水，NLP、AI concept和Big Data都会介绍目前最前沿的技术。对于我这种没接触过AI算法的人来说，确实有点头大。不过也算学到了新东西，倒也不亏。</p><p>本科毕业之后，可能大家都已经有了自己的规划。对于读书这事，目的也各不相同。</p><p>这港硕的一年，就像是把一群各有自己想法的人聚集到了一块儿，每次遇到陌生同学，聊几句就会发现对方过着和你截然不同的人生。</p><p>从我个人角度，满分100，我给港理工打90。10分扣在不是港三，但这事也怨我，早点申请可能也就到港三去了。</p><h2 id="回炉重造的成果">回炉重造的成果</h2><p>挨过了社会的毒打，重新回到校园，以为会是狼入羊群嘎嘎乱杀，结果是发现牛混到了羊群里，居然要重新学怎么吃草。</p><p>技术栈差别很大，真的很大。我原本是搞工程方向的人，但是研究生也不得不去学算法，学AI的技术了。</p><p>大模型的风确实刮到了各种地方，现在是个学科只要挂上机器学习的名头就能变成一个新学科，一个新方向。</p><p>风来了，那么也只能顺着风的方向去飞。借着学校的课程，我也开始在AI这块入了个门。</p><p>到NLP的小组作业，也算是小小地喷发了一会儿。</p><p>我久违地写了点代码，然后把服务部署到了阿里云的云服务器上，最后接入通义千问大模型。搞出来的效果让同组的人都惊呆了。</p><p>其他组大多是在大模型的上层做了RAG，但我的思路是在RAG之外要给模型提供插件来获取实时信息，否则这个项目的成果完全不可用。</p><img src="/2024/11/20/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/image-20241121203740450.png" class="" title="image-20241121203740450"><p>做完的时候有种感觉，就是自己好像确实学了不少新玩意儿。</p><p>这次回炉重造，最初的目标就是能开拓一些新的知识点，希望能学python，学数据分析，学AI训练，学会写前端。</p><p>我觉得还是有些进步的，至少python会写了，数分也入门了，大模型的训练、微调也会了。目前还差点前端，打算是考试期间学点微信小程序的前端，先入门一下。</p><p>也慢慢明白自己擅长和不擅长的地方，对未来的规划也更加明确了。</p><p>回炉重造初显成效。</p><h2 id="看过猪跑很重要">看过猪跑很重要</h2><p>我当时下定决心要读研究生，这句话对我影响很大：“看过猪跑很重要”。</p><p>应该是阿里的毕玄在一次采访中说的。大概意思是公司的业务发展中，总会随着业务量出现各种新的问题。这时候能了解其他人的解法，是非常有参考价值的。</p><p>拿阿里来说，当时国内没有什么公司能作为参考，他们会去找谷歌的案例。但是找到的案例可能是10年前的，对于当时的业务量，足以够用。</p><p>而业务快速成长，遇到的困难也越来越多。到某一天，突然发现谷歌也没处理过现在阿里遇到的问题了。那这时候怎么办？</p><p>唯有自己解决了？</p><p>非也。这时候，答案在学术界。</p><p>时代变化，公司可能已经成长为巨头，此时不能直接照抄人家的答案，你也得作为开拓者参与最前沿的技术。</p><p>这时候各种国际会议、学术论文会进入你的视野，从学术角度找方案来落地才是最切实可行的。为什么说&quot;看过猪跑很重要&quot;，学习的知识来源是实践，而模仿是实践中效率最高的方式。</p><p>公司的业务变化，模仿的对象也要变化。当接近了金字塔的顶尖，所有人都不得不参与到名为学术的圈子里。</p><p>而这时候，你也得产出一些成果，可能是学术会议上的论文、各种分享会上的演讲，你也会变成别人眼中奔跑的猪。</p><p>我想读研究生，就是希望能先打个基础，以后做到这个程度的时候不会有短板。</p><h2 id="回炉重造的感受">回炉重造的感受</h2><p>自由、时间充裕、需要自控力。这三点是我最大的想法。</p><p>不用上班之后确实时间很多，也很自由，但是想做些什么有意义的事情，得靠自控力。</p><p>我每年都有立个目标和年末总结的习惯。</p><p>今年的目标，有两个：上学和变全栈。上学算是完成了，全栈还需要一点点时间，不过我相信我绝对没什么问题。</p><p>当时脑袋里萌发出读研的想法，我觉得这个决定可能会影响我一生，于是我马上订了去广州的高铁去找中介，并且立马签了合同。</p><p>现在已经初现倪端，我接触的技术范围大大超过了工作时。</p><p>我始终觉得方法比实际的努力更重要，因此我学习更注重学会学习方法，走通学习新知识的路，而不是学会这个知识本身。</p><p>在这方面，研究生读得还挺值得的。</p>]]></content>
    
    
    <summary type="html">港硕第一学期即将结束，赶due的期间摸鱼写个博客。</summary>
    
    
    
    <category term="生活" scheme="https://tulancn.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="杂谈" scheme="https://tulancn.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>秋招的总结</title>
    <link href="https://tulancn.github.io/2024/11/01/work/%E7%A7%8B%E6%8B%9B%E7%9A%84%E6%80%BB%E7%BB%93/"/>
    <id>https://tulancn.github.io/2024/11/01/work/%E7%A7%8B%E6%8B%9B%E7%9A%84%E6%80%BB%E7%BB%93/</id>
    <published>2024-11-01T07:08:20.000Z</published>
    <updated>2025-03-10T13:57:29.416Z</updated>
    
    <content type="html"><![CDATA[<h2 id="经历">经历</h2><p>最开始是准备简历和找招聘信息，这部分就略过不谈。</p><p>麻烦的还是面试的准备，前期刷了leetcode的hot100，然后搞了一份80字面试宝典一点点看。</p><p>这些处理完已经到9月中旬了，这才慢慢投了一些厂子。</p><p>到十月国庆假期之后，才有一些笔试邀请过来。这时候已经是第二批次的秋招了，说实话互联网大厂的希望不大。</p><p>不过我也投了一个国企，还意外做了个行测。没怎么准备这种题目，说实话还是挺有意思的，感觉像智商测试。</p><p>等了一个月，到十月末，是华为给了面试的机会。</p><p>推荐人说粤港澳的面试安排有些混乱，想着在香港的同学线下跑去面试也不方便，也干脆给我安排走线上了。</p><p>一面在下午4点。</p><p>一开始是自我介绍，然后面试官挑项目经历问了些问题。</p><p>问了JNI是什么，为什么项目要用到JNI。回答提了一下Java的特性，JNI的用法和原理。</p><p>接着就继续从项目挑技术点问，中途话题被我带到了信创，就聊了不少信创的事情，感觉快变成纯聊天了。</p><p>一面大概是被安排了要问基础的问题，聊了一会儿之后面试官一拐话题说要继续问基础。</p><p>手撕挺简单的，给两个二进制字符串求和。这里我一边念题目一边说想法，然后再实现。</p><p>调试的时候出了一个bug，我说了一句Java不能多值返回就是麻烦，听到面试官笑了。</p><p>最后让我解释了一下调试时出现的问题原因，一面就结束了。</p><p>二面延后到了6点。</p><p>因为有些推迟了，面试官上来说直接做道题吧。</p><p>是一道分割整数数组的题，要求分割成三个数组，顺序不能变，数组和依次增大。问有几种解法。</p><p>还是一样，一边念题目一边说想法。写完面试官问了下几个优化的点。</p><p>然后就开始问项目，应该是想了解应聘者的技术思维吧。每个技术都问了下为什么这么做，有没有优化空间。</p><p>倒是都答上来了，有些比较复杂的回答就先把场景说明清楚。</p><p>中间提了项目中一些比较新奇的技术点，面试官也挺感兴趣的，就聊了挺久。</p><p>比较刁钻的就是问了下kafka有什么缺点。我一开始说不上来，就先扯了一句说它不信创，有些客户觉得可能影响项目的信创认证。然后才从技术角度回答了一下，主要是从不去中心化，对zk的强依赖（新版本用kraft去掉了），以及做消息防丢之后性能比较差这三个方面来说。</p><p>二面也顺利结束。</p><p>三面主管面是在9点。</p><p>上来主管先道歉，说拖了这么久，我说没关系。</p><p>跳过了项目拷打，主管说有工作经历相信技术上不会有问题。</p><p>先问为什么要重新去深造，会不会在华为工作以后也因为深造而离职。说上了研究生之后就像泄了气的皮球，没什么继续读书的兴趣。</p><p>接着问为什么选华为，我说我家里人都是花粉。面试官直接笑出声。</p><p>然后比较正式地回答是聊了下之前工作时做信创的经历，比较认可华为云自下而上从硬件层开始做信创的方案，认为公司有意愿去做其他公司不敢做的事，愿意在基础产品上投入。</p><p>举了个例子，之前在华为的服务器做压测，性能指标一直上不去。最后把JDK从openjdk换成华为的毕昇JDK，触发了软硬件协同，性能指标就一下子提上去了。</p><p>最后是关于压力，让我举个抗压的例子。先举了一个，不满意，然后再举。我说我为了读研究生考了7次雅思，第6次的时候崩溃大哭，但是收拾好心情继续去考了，最后终于过了。面试官边笑边说可以了。</p><p>反问环节，我说华为云内部是否很重视信创，给了肯定的回答。</p><p>结束时主管说希望还能再见到我，心理有预感已经过了。</p><p>晚上11点45准时收到面试的评价。</p><p>总体来说面试体验挺好的，虽然有些小插曲，但华为的员工们态度都很不错。</p><p>华为的面试之后，也就没有其他的面试流程了，秋招的拼搏阶段也算画上了句号。</p><h2 id="复盘">复盘</h2><p>如果要想一下还有什么能提高的，我觉得首先是自我介绍。</p><p>我发现很难在一两分钟内把自己所做过的所有事情都讲明白，一方面是经历比较丰富，一方面也是自己挑不到重点。</p><p>所以自我介绍还是得磨一磨，围绕项目把技术亮点重点说明，简单的经历就汇在一起用一句话带过。</p><p>第二个是下次春招要提前投递，这次秋招吃了不少的亏，主要是没有提前进行投递，导致没赶上9月的一批岗位。</p><p>最后是算法题，倒不是写不出来，就是我写得有点慢，这得再写一些题目才行。</p><h2 id="杂谈">杂谈</h2><p>仔细想想其实没面几家，算不上海投，算不上准备很充分，但大部分时候我也不就是这样轻轻松松就上了么。</p><p>就我个人而言，找工作这事情目前还不是特别急的一件事，秋招主要也是想打打基础。这么想的话就算这次最终结果不尽人意，可能也是可以接受的吧。</p>]]></content>
    
    
    <summary type="html">总结下这次秋招，没投几个简历，没费多大劲。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="找工作" scheme="https://tulancn.github.io/tags/%E6%89%BE%E5%B7%A5%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>大模型技术到底带来了什么</title>
    <link href="https://tulancn.github.io/2024/10/19/work/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%88%B0%E5%BA%95%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88/"/>
    <id>https://tulancn.github.io/2024/10/19/work/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%88%B0%E5%BA%95%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88/</id>
    <published>2024-10-19T08:33:05.000Z</published>
    <updated>2025-03-10T13:56:48.151Z</updated>
    
    <content type="html"><![CDATA[<h2 id="正文">正文</h2><p>时间到2024年，以LLM为首的AI热潮似乎开始冷却。但是工具已经开始普及，大部分人已经开始尝试和AI一起工作。</p><p>我首先想提的是国内大模型的水平。目前接触下来，国产的AI在下限方面基本已经满足了我们的日常生活需要。也就是说，平时一些简单的任务已经可以让AI去完成，大部分问题都能收到一个令人满意的回答。对于大部分人的日常工作来说，已经足够。</p><p>如果要用一个角色来形容AI目前的水平，我觉得是一个知识面很广，能力很强，在经过适当调教能很好地完成任务的实习生。</p><p>这其实已经对我的日常工作方式有相当强烈地冲击了。举例来说，平日有些费时费力的总结报告，现在可以让AI来填写。一些技术文档全篇很长，而我需要知道的又只是其中的一个小点，那就可以让AI快速阅读之后我对其提问来获取答案。这种场景下，我的需求和问题都很明确，答案也有现成的，只是让AI在特定范围内进行一个快速的搜索，像是把LLM当做一个非常强大的搜索引擎，这种时候就非常好用。</p><p>还有种场景是内容的格式改写，比如数据改写为JSON格式。人工做很费力，但是AI能听懂指令快速生成结果。这就很好用。</p><p>那么工作的重点就变了。以前我的重点是把任务人工完成，要出力；现在我的重点是理清思路，转化为AI可以完成的任务，然后让AI先做一遍，我再检查一遍。这种思路确实就和分配任务给实习生是一样的。</p><p>所以，这就引出了LLM最适合的工作场景之一：<strong>重复性的、有明确工作规范和成果验收的工作</strong>。</p><p>另外，与AI协作的时候，很多人会感觉自己的能力也提高了。有一种场景，比如需要写一些自己平时不擅长的代码，像是后端程序员刚开始接触一门新的语言。这时候程序员可能是知道要做什么，但是苦于不知道怎么实现，因此需要一些额外的时间去学习。有了AI之后，这个学习成本降低了非常多，并且没有让人排斥的搜寻资料的过程。很多时候，我们要做的就是打开LLM输入界面，然后写出需求，等到LLM的回答，然后开始干活。得益于技术水平的提高，现在的LLM基本都很聪明，它们的回答大多数时候都是有用的。</p><p>感觉自己能力的提高后，会让人变得自信，然后就愿意去做一些以前不能做的事情。</p><p>但究其根本，不是人的能力提高了，而是<strong>学习的成本降低</strong>了。</p><p>这就是LLM最适合的第二个工作场景：<strong>快速让人在一个知识领域达到入门水平</strong>。</p><p>经过一些调教，我相信LLM在教育这方面大有可为。</p><p>然后我就要提GitHub Copilot。作为代码提示工具，有了LLM加持后，它聪明得让人欣喜。有人评价是，有了Copilot之后，编码的方式就变成了：写好注释，写好框架代码，然后停下来，等待Copilot填充。这确实是我的真实写照。</p><p>我觉得这就是大模型带来的最大影响：<strong>评价一个问题的难易程度，是取决于它有多少的部分能被LLM执行</strong>。</p><p>在一个任务中，我们总是倾向于让LLM做更多，而自己做更少。为什么这么说？第一个原因，LLM执行任务非常快，快到人类无法比拟的程度了；第二个原因，LLM执行任务的成本极低，几乎相当于没有成本。</p><p>但我们遇到的问题在最初往往并不是LLM可以直接解决的问题，因此我们要把问题转化为一个个LLM可以执行的最小单元。这考验了一个人思考问题、拆解问题和描述问题的能力，而显而易见的结论就是，这种能力越强的人，与LLM协作的能力也越强。</p><p>反过来，这其实也让我们每个人先专注于分析问题，而不是埋头就做。某种意义上来说，也算是反哺自身，让人去思考得更深入。</p><p>那么，我可以抛出一个命题：<strong>与大模型协作的能力越强，这个人的工作能力就越强</strong>。就像上文说的，一个人只有能分析拆解好问题，才能更好地让LLM完成工作。巧合的是，你把前面这句话中的LLM换成同事、下属也是一样成立的。原先AI部的同事就和我说过，常带实习生，或者手下有几个人的技术骨干，往往用Copilot也特别顺手。</p><p>在肉眼可见的未来，大家的工作中必定绕不开LLM，那么今早培养好自己相关的能力，可能也是条出路吧。</p><h2 id="总结">总结</h2><p>目前在工作和学习中，与大模型协作是非常常见的场景。</p><p>LLM的工作成本低，工作速度快，因此很适合进行一些重复性强、严格控制输入输出的工作。</p><p>LLM的语料资源丰富，能有效降低知识的学习门槛。</p><p>未来，人的工作能力可能很大程度上取决于他和AI配合能力的高低。</p>]]></content>
    
    
    <summary type="html">时至今日，LLM对我日常的工作和学习已经产生的极大的影响。聊聊我的思考。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>面试笔记-Java基础</title>
    <link href="https://tulancn.github.io/2024/10/16/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Java%E5%9F%BA%E7%A1%80/"/>
    <id>https://tulancn.github.io/2024/10/16/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Java%E5%9F%BA%E7%A1%80/</id>
    <published>2024-10-16T07:04:36.000Z</published>
    <updated>2025-03-10T14:00:22.699Z</updated>
    
    <content type="html"><![CDATA[<h2 id="语法基础">语法基础</h2><h3 id="Java语言特点">Java语言特点</h3><p>一次编译处处运行，天然具有跨平台的能力。只要不用JNI。</p><p>开源社区资源丰富，活跃。</p><p>适合企业级开发，多方面：有Spring为主流的开源框架，大型项目的构建和维护的成本较低。语言的规范性强。</p><h3 id="基本类型和包装类型">基本类型和包装类型</h3><p>byte、char、boolean、short、int、float、long、double</p><p>基本类型不是对象，包装类型是对象。使用时有自动的拆装箱机制。但编码过程中如果可以用基本类型的建议还是用基本类型。</p><p>区别在于对象是有对应的Class类，这些类信息会记录在JVM的ClassLoader中。对象有对象头。</p><p>字节码的方法签名，基本类型是BCJFI之类的大写字母，对象是L加全限定类名。</p><h3 id="instance-of">instance of</h3><p>检测对象是否是某个类型的实例。可以用来检测对象是否实现了某个接口。</p><p>HashMap中有使用到，用来检测当前节点的实现是链表还是红黑树。</p><h3 id="重写和重载">重写和重载</h3><p>重写建议加@Override注解，标明该方法是重写方法。</p><p>重写发生在子类重写了父类的同名且参数完全一致的方法，或者是实现了某个接口的方法。有重写就一定是有extend或者impliment。</p><p>重载是同名方法用不同的参数实现。同名方法的方法签名是不一样的。</p><h3 id="equals和">equals和==</h3><p>==是比较两个变量所指向的内存地址是否相同，其实是个指针操作。基本类型就相当于值比较。</p><p>equals是Object类的一个方法，Object类中的实现就是==。一般不同的类会有不同的实现，String的实现就是逐个比较字符值是否相等。</p><h3 id="四种引用">四种引用</h3><p>强引用：使用最多的引用，默认就是强引用。</p><p>软引用：缓存会用。可能会被回收，优先级在弱引用之后。</p><p>弱引用：young GC时必定会回收。</p><p>虚引用：这个引用不会影响GC，需要有其他引用方式指向这个对象。</p><h3 id="Cleaner">Cleaner</h3><p>Cleaner机制用到了虚引用。Cleaner继承了虚引用，GC后，所有的cleaner会被回收到一个pending队列，reference handler线程会调用这个pending队列中的对象，会检测下是不是Cleaner对象，是的话就直接调用Cleaner的clean方法。</p><h3 id="Exception和Error">Exception和Error</h3><p>都是Throwable的实现类。</p><p>运行时异常不用显式地catch。被检查异常需要catch或向上抛出。</p><p>Error是非常严重的错误，可能宕机。但是不需要显式抛出。</p><h2 id="数据结构">数据结构</h2><h3 id="HashMap">HashMap</h3><p>线程不安全。</p><p>put：hash之后找到数组中的对应位置，如果为空直接塞；不为空说明哈希冲突，检查一下当前的数据结构，按照数据结构来添加这个对象，可能是替换也可能是新增。</p><h3 id="LinkedList">LinkedList</h3><p>双向链表，线程不安全。</p><h3 id="阻塞队列">阻塞队列</h3><p>阻塞队列的经典实现：ArrayBlockQueue，LinkedBlockQueue</p><p>用了大小堆的priority queue</p><p>阻塞队列的锁就是线程池的锁。所以阻塞队列的性能也一定程度上决定了线程池的性能。举例：Disruptor、参考Disruptor实现了自己的阻塞队列。</p><p>阻塞队列可以当做对象池来用。</p><h2 id="JVM">JVM</h2><h3 id="JVM内存模型">JVM内存模型</h3><p>线程独占的：栈，本地方法栈，程序计数器</p><p>线程共享的：堆，方法区</p><p>栈：存储局部变量，操作栈，动态链接，方法出口。调用一个方法时入栈，方法返回出栈。</p><p>本地方法栈：Native方法的栈</p><p>程序计数器：当前程序执行的字节码位置。也就是打印异常堆栈时看到的执行到第几行出错。执行到native方法时，程序计数器清空，因为不是在执行字节码了。</p><p>堆：存储对象实例，线程共享。会垃圾回收。</p><p>方法区：虚拟机加载的类信息，常量，静态变量，JIT优化后的代码。总之就是些全局的信息。</p><h3 id="内存可见性">内存可见性</h3><p>也就是为什么要volatile关键字。</p><p>线程执行时，会拷贝一份线程间的共享变量至线程的工作内存。拷贝的数据可能已经被其他线程修改了，导致执行结果错误。</p><p>volatile会在共享变量修改时，强制同步一份副本至所有涉及到的线程的工作空间。</p><h3 id="类加载和卸载">类加载和卸载</h3><p>加载字节码文件到内存-&gt;验证并解析为Class类，创建静态变量执行静态代码块-&gt;实例化-&gt;GC</p><h3 id="三种加载器">三种加载器</h3><p>JAVA_HOME/lib: Bootstrap ClassLoader</p><p>JAVA_HOME/lib/ext: Extension ClassLoader</p><p>Application ClassLoader</p><h3 id="双亲委派">双亲委派</h3><p>加载器加载一个类时，先委托给父类加载器。父类无法加载才会自己加载。</p><p>主要是为了避免同一个类被多个加载器重复加载。已经避免Java的核心类被修改。</p><h3 id="回收算法G1">回收算法G1</h3><p>高频率回收，减少每次的停顿。</p><p>分老年代和年轻代。分块region，年轻代和老年代都由若干个分块组成。</p><p>年轻代使用并行的复制和收集算法。</p><p>mix-GC会回收一部分老年代。</p><p>标记清除算法：STW进行初始标记，确实GC root可直达的对象，伴随一次young GC。然后GC线程和应用线程并行进行并发标记，尽可能标记出存活对象，使用SATB记录对象的引用关系。最终标记，STW，修改并发标记的错误。然后多线程进行GC。</p><h3 id="ZGC">ZGC</h3><p>低延时垃圾收集器。</p><h3 id="Full-GC">Full GC</h3><p>当老年代满时会进行，耗时长。需要避免。</p><h3 id="对象分配原则">对象分配原则</h3><p>新对象优先在eden区，如果大于survivor的二分之一就认定为大对象，直接晋升老年代。</p><p>对象没存活过一次young GC，年龄+1，到达一定年龄（默认15）就晋升老年代。</p><p>Survivor区中同年龄对象的总和大小超过一半，这个年龄以及这个年龄以上的对象进入老年代。</p><h3 id="对象的创建过程">对象的创建过程</h3><p>先去常量池找类信息，然后加载类信息，找不到就报ClassNotFound。</p><p>为对象分配内存，将除了对象头之外的内存块初始化为0。</p><p>设置对象头。</p><h3 id="对象结构">对象结构</h3><p>对象头12字节，数组16字节。</p><p>对象信息，基础类型直接在对象内存存储。</p><p>Java会自动排列对象中的Field顺序以更好地满足8字节对齐。</p><h3 id="对象头的内容">对象头的内容</h3><p>4字节的hashcode</p><p>2字节的分代年龄</p><p>1字节偏向锁</p><p>1字节锁标志</p><p>4字节的对象类型指针，指向Class类信息</p><p>数组的话还有4字节的数组长度</p><h3 id="常见的调优工具">常见的调优工具</h3><p>jps：展示所有的java进程</p><p>jstat：查看虚拟机运行状态</p><p>jmap：主要用于dump</p><p>jstack：生成线程快照</p><p>jinfo：实时查看和修改JVM参数</p><p>MAT：dump文件分析</p><p>visualVM：自带可视化界面</p><p>arthas：阿里开源的运行时诊断工具</p><h2 id="多线程">多线程</h2><h3 id="怎么创建线程">怎么创建线程</h3><p>只有new Thread()才算创建了一个新线程。其他的方式比如实现Runnable接口Callable接口之类的都没有新线程产生。</p><p>Runnable接口Callable接口本质是一个task，需要提交给线程才能执行。</p><h3 id="如何停止一个线程">如何停止一个线程</h3><p>最佳是用退出标志，完成当前方法后当前线程终止。</p><p>推荐调用interrupt，会抛出interrupt异常。</p><p>stop可以强行终止，不推荐。</p><h3 id="notify和notifyAll有什么区别">notify和notifyAll有什么区别</h3><p>notify可能死锁，notifyAll不会。</p><p>假如有多个线程正在wait，会要求notify唤醒的任意一个线程可以处理接下来的逻辑，否则就会死锁。</p><p>如果无法正确处理，则应该继续notify下一个，并让自己进入wait状态。</p><p>notifyAll唤醒所有线程，但是争抢锁还是无序的。</p><h3 id="sleep和wait有什么区别">sleep和wait有什么区别</h3><p>sleep在线程类中，wait在Object类。</p><p>sleep不释放锁，会让出cpu。</p><p>wait会释放锁，并且让出cpu。调用wait后，会释放线程持有的所有对象锁，然后进入对象的等待区。只有针对此对象调用notify或notifyAll后，才会获取对象锁进入运行状态。</p><h3 id="volatile">volatile</h3>]]></content>
    
    
    <summary type="html">Java基础是纯纯的八股文了，但还是要过一遍。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="面试" scheme="https://tulancn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>面试笔记-Spring</title>
    <link href="https://tulancn.github.io/2024/10/16/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Spring/"/>
    <id>https://tulancn.github.io/2024/10/16/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Spring/</id>
    <published>2024-10-16T03:43:17.000Z</published>
    <updated>2025-03-10T14:00:33.126Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spring篇">Spring篇</h2><p>Spring是一个Java开发框架，主要是解决企业级开发的一些痛点。一开始可能主要是用于Web应用的开发，但目前实践中它已经在国内Java后端开发这方面一统江湖。</p><p>它把各种业务逻辑都抽象封装为Bean，Spring负责项目启动时把这些Bean创建出来，进行业务开发的时候只需要通过Spring提供的API或其他方式，获取到对应的Bean就可以执行各种复杂业务操作。</p><h3 id="为什么是Spring">为什么是Spring</h3><p>轻量。</p><p>IOC，控制反转。业务开发不用关注对象创建之类的事情，只需要编码，并给出依赖，框架会自动帮你找到对应的实现类。</p><p>AOP，面向切面编程。</p><p>事务管理。</p><p>异常处理。</p><h3 id="Autowired和Resource的区别">Autowired和Resource的区别</h3><p>Autowired是Spring提供的注解，Resource是javax的注解。Spring是支持了javax提供的标准注解，是标准的一个实现。</p><p>假如换了框架（一般不会），Autowired必定不可用，Resource可能还能用。</p><p>Autowired默认按照type类装配，默认要求对象必须存在且唯一。可以用Qualifier来指定BeanName。</p><p>Resource注解提供了type和name两个注解字段。name的优先级高于type。</p><h3 id="依赖注入的方式">依赖注入的方式</h3><p>构造器、setter、接口。反射注入</p><h3 id="Spring-MVC">Spring MVC</h3><p>Spring MVC是Spring的一个模块，针对web应用的场景。</p><p>V不是普遍意义上的前端，而是用jsp或其他方式渲染的一个页面。</p><p>M是逻辑层，做计算和数据库操作。C是控制层，负责接收网络请求。</p><p>Spring在Servlet的基础上实现，定义了一个统一的请求接收入口：DispatcherServlet。DispatcherServlet会根据url和请求类型分发请求到用户编码的Controller中，然后执行用户的逻辑。</p><p>常用注解：@RequestMapping、@RequestBody、@ResponseBody</p><h3 id="AOP">AOP</h3><p>把一些业务无关，在系统层面共通的逻辑封装起来，从而减少代码冗余，有利于代码的扩展性和维护性。比如参数校验、日志采集、权限控制。</p><p>Spring的AOP是基于动态代理实现的。对于已经实现了接口的，用JDK动态代理，创建一个接口的实现类然后代理。没有实现的，用CGlib，创建一个类的子类然后代理。</p><p>也可以用AspectJ实现自己的AOP逻辑。</p><p>Spring的AOP属于运行时增强，AspectJ的AOP是编译时增强。AspectJ是字节码操作，性能稍高。</p><h3 id="关注点和横切关注点">关注点和横切关注点</h3><p>关注点是某个特定的业务功能，横切关注点是多个业务都会用到的系统功能，比如日志、参数校验、权限。</p><h3 id="什么是通知advice">什么是通知advice</h3><p>方法执行前和后要做的逻辑处理。</p><p>before</p><p>after</p><p>after-returning</p><p>after-throwing</p><p>around</p><p>这个结果处理和Spring WebFlux中的回调很像。</p><h3 id="IOC">IOC</h3><p>控制反转，把创建对象的权利移交给框架。</p><p>对象不需要程序自己去new，而是通过依赖注入从框架中获取。</p><p>IOC让组件保持松散的耦合，从而创造了可以进行AOP编程的余地。</p><h3 id="Spring-Bean生命周期">Spring Bean生命周期</h3><p>Servlet：实例化、初始化、接收请求、销毁。</p><p>Bean：</p><p>1、配置扫描，创建BeanDefinition，构建BeanFactory。</p><p>2、实例化：启动时的第一步。当BeanFactory被请求一个未实例化的Bean时，会调用createBean方法实例化一个Bean。</p><p>3、依赖注入：实例化之后的对象在BeanWrapper中，Spring通过BeanDefinition的配置进行依赖注入。这里会先找这个Bean的依赖所对应的BeanFactory，然后提供一个实例化Bean进行依赖注入。</p><p>4、处理Aware接口：BeanNameAware、BeanFactoryAware、ApplicationContextAware</p><p>5、BeanPostProcessor的postProcessBeforeInitialization方法</p><p>6、InitializingBean的afterPropertiesSet</p><p>7、BeanPostProcessor的postProcessAfterInitialization方法</p><p>8、scope为singleton的缓存在容器，prototype的返回最开始请求的客户端。</p><p>9、销毁，调用DisposableBean的afterPropertiesSet</p><h3 id="Bean的作用域">Bean的作用域</h3><p>1、singleton：单例</p><p>2、prototype：每个Bean一个实例</p><p>3、request：每个网络请求一个实例</p><p>4、session：每个session一个实例</p><p>5、globe-session</p><h3 id="Spring的设计模式">Spring的设计模式</h3><p>简单工厂模式：Bean的创建</p><p>单例模式：单例的Bean</p><p>代理模式：AOP的实现</p><p>适配器：Adapter，Spring中以Adapter结尾的一般都是适配器模式。比如AdvisorAdapter</p><p>观察者模式：Spring事件</p><p>模版模式：JdbcTemplate</p><h3 id="ApplicationContext和BeanFactory">ApplicationContext和BeanFactory</h3><p>BeanFactory是基础接口，只提供最基础的Bean管理功能，在spring-beans包中。</p><p>ApplicationContext继承了BeanFactory，并且扩展了事务管理、国际化、AOP。</p><p>BeanFactory是延迟加载，而ApplicationContext是启动时实例化所有的Bean。</p><h3 id="Spring的单例Bean是线程安全的吗">Spring的单例Bean是线程安全的吗</h3><p>是否线程安全和单例无关。Spring本身没有对Bean做任何并发的保护，这也不是Spring应该关心的东西。是否线程安全由开发者来保证。</p><h3 id="循环依赖怎么解决">循环依赖怎么解决</h3><p>三级缓存</p><p>第一级缓存是初始化完成的Bean；第二级是完成了实例化，但是没有完成依赖注入的Bean；第三级是没实例化的Bean，存放其BeanFactory。</p><p>假设有两个Bean A、B，AB循环依赖</p><p>1、Bean都是由BeanFactory创建，A的BeanFactory会先实例化A，放入二级缓存，随后进行依赖注入。</p><p>2、A的BeanFactory通过依赖找到了B，先从一级缓存找，一路找到三级缓存，最后找到了B的BeanFactory。这时候B没有创建，所以用B的BeanFactory创建B。BeanFactory会先创建一个B的实例，这样在二级缓存就有了一个B的实例，然后进行依赖注入。</p><p>3、B在依赖注入的时候会在二级缓存找到A，这时会直接获取A的实例注入B，这样就完成B的依赖注入。B完成创建后放入一级缓存，然后把B通过BeanFactory的方法返回给A，A就可以继续进行依赖注入。</p><h3 id="Spring事务隔离级别">Spring事务隔离级别</h3><p>同数据库的级别：读未提交、读已提交、可重复读、串行化</p><h3 id="Spring事务传播级别">Spring事务传播级别</h3><p>PROPAGATION_REQUIRED：有事务就加入，没有就创建</p><p>PROPAGATION_SUPPORTS：有就加入，没有就不加事务</p><p>PROPAGATION_MANDATORY：有就加入，没有就抛异常</p><p>PROPAGATION_REQUIRES_NEW：永远创建一个新的事务执行</p><p>PROPAGATION_NOT_SUPPORTED：永远不以事务执行</p><p>PROPAGATION_NEVER：有事务就抛异常</p><p>PROPAGATION_NESTED：有事务就创建嵌套事务，没有就创建</p><h3 id="Spring事务实现">Spring事务实现</h3><p>编程式事务、声明式事务。</p><p>PlatformTransactionManager中定义了事务的开始、提交、回滚等操作。不同数据库会有不同实现。</p><h3 id="Spring事务管理优点">Spring事务管理优点</h3><p>抽象了统一的接口。支持声明式事务管理。</p><p>可以和Spring多数据源结合。</p><h3 id="事务三要素">事务三要素</h3><p>数据源：事务的真正处理者。</p><p>事务管理器：处理事务的打开、提交、回滚。</p><p>事务应用和配置：表明哪些方法参与事务，事务的隔离级别，传播级别，超时时间。</p><h3 id="事务注解的本质">事务注解的本质</h3><p>@Transactional仅仅是一些元数据，这里通过AOP的方式，将元信息传递事务管理器，事务管理器再提交给数据源实现具体的事务。</p><p>其实就相当于在方法前后加了一些事务的代码。</p><h2 id="Spring-Boot篇">Spring Boot篇</h2><h3 id="为什么是Spring-Boot">为什么是Spring Boot</h3><p>独立运行：内嵌了tomcat、Jetty。不需要打成war包部署到容器。可以打成独立的Jar包运行。</p><p>配置简化，自动装配：能根据当前路径下的类、jar来自动配置bean。</p><p>无代码生成：配置过程中没有代码生成，没有xml配置文件，都是基于条件注解完成。</p><p>监控：默认就提供了很多监控端点。</p><p>Spring Boot大量使用了注解来驱动开发。</p><h3 id="核心注解">核心注解</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@SpringBootConfiguration</span><br><span class="line">@EnableAutoConfiguration</span><br><span class="line">@ComponentScan</span><br></pre></td></tr></table></figure><h3 id="如何理解starters">如何理解starters</h3><p>一个把所有依赖都集成在一起的依赖包，简化引入的成本。</p><h3 id="如何在启动时执行一些特殊的逻辑">如何在启动时执行一些特殊的逻辑</h3><p>ApplicationRunner，CommandLineRunner。</p><p>ApplicationRunner有一个实现，是在启动时把程序的pid打印到一个文件中，方便运维。</p><h3 id="监视器-actuator">监视器 actuator</h3><p>actuator会对外暴露一些端点，可以通过配置的方式管理这些端点（endpoint）。这是能让用户来访问和监控程序当前的运行状态。配合运维平台使用。</p><h3 id="异常处理">异常处理</h3><p>ControllerAdvice，可以用来处理所有的异常，封装为统一的异常信息返回。</p><h3 id="配置加载顺序">配置加载顺序</h3><p>Spring Boot的配置加载顺序和其优先级一致。</p><p>1、命令行，–大于-D</p><p>2、Java系统属性，System.getProperties。</p><p>3、环境变量</p><p>4、yml文件</p><p>5、默认配置</p><h3 id="application和bootstrap文件">application和bootstrap文件</h3><p>老版本Spring Cloud Alibaba的Nacos只能使用bootstrap文件，后面版本修改了。</p><h3 id="自动装配">自动装配</h3><p>自动装配就是把第三方的Bean装载到Spring的容器里。以前是需要开发人员写xml才能把这些Bean装载到容器的。</p><p>原理：第三方组件定义了Configuration类，在其中声明了需要装载的Bean对象，同时也在这个类里定义了一些自动装配的规则。Spring在启动时通过META-INF/spring.factories文件找到对应的配置类，然后对这些配置类进行动态加载。</p><h2 id="Spring-Cloud篇">Spring Cloud篇</h2><h3 id="为什么是Spring-Cloud">为什么是Spring Cloud</h3><p>是用于构建分布式应用的开源框架。基于Spring Boot，提供与外部系统集成的能力。国内有很多二开的框架，比如Spring Cloud Alibaba，TSF，Spring Cloud Huawei。</p><h3 id="什么是微服务">什么是微服务</h3><p>一种架构。将单一功能的应用程序划分为一组小的服务，每个服务独立运行，服务之间相互协调、配合，最终实现一个业务功能。</p><p>服务之间使用轻量级的通讯机制（通常是http，但是dubbo之类的也可以）。</p><p>需要有一个中心来集中化管理这些服务。</p><h3 id="服务熔断和降级">服务熔断和降级</h3><p>分布式的场景下，某个服务出现异常，当检测到这种情况后，可以切断对该服务的调用。等到服务正常以后，再恢复服务。这就是熔断。</p><p>降级是是指服务熔断以后，如果还有对该服务的调用，直接失败。</p><h3 id="eureka-zookeeper-nacos">eureka zookeeper nacos</h3><p>Eureka的高可用机制比较完善，可以保证服务随时可用。</p><p>zookeeper对于多节点的数据一致性处理比较完善，可以用于主从选举。zk其实为了分布式协调而设计的，比如分布式锁、选举都可以用zk来做。</p><p>nacos提供了可视化界面，同时支持服务注册发现和配置下发，一个人干了两个人的活。</p><h3 id="Spring-Boot-Spring-Cloud">Spring Boot Spring Cloud</h3><p>Spring Boot是专注于开发单个微服务。</p><p>Spring Cloud是关注分布式系统的，分布式系统可以是多个Spring Boot开发的微服务的集合，Spring Cloud用于提供微服务之间调用、微服务的配置获取、服务注册、路由等。</p><h3 id="负载均衡">负载均衡</h3><p>某个服务可能有多个实例，调用该服务时，每个请求会分发到不同的实例处理，有助于提高服务的吞吐量。</p><h3 id="Feign">Feign</h3><p>Feign是一个HTTP请求客户端，提供了声明式的调用方式。主要是通过JDK动态代理实现。它整合了负载均衡的能力（Spring Cloud LoadBalance）</p>]]></content>
    
    
    <summary type="html">这里记录一下面试的准备过程中关于Spring的笔记。问Java不问Spring简直不可能好吧。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="面试" scheme="https://tulancn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>面试笔记-数据库</title>
    <link href="https://tulancn.github.io/2024/10/14/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <id>https://tulancn.github.io/2024/10/14/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E5%BA%93/</id>
    <published>2024-10-14T05:48:06.000Z</published>
    <updated>2025-03-10T14:00:06.526Z</updated>
    
    <content type="html"><![CDATA[<h2 id="知识点">知识点</h2><h3 id="三范式">三范式</h3><p>第一范式：列不可再分；</p><p>第二范式：表中的每一行都可以唯一区分，通过主键实现；</p><p>第三范式：（用于避免数据冗余，减少内存占用，实践中常被忽视）表的非主键字段不能依赖于其他非主键字段；比如学生表，里边有班级名称字段和辅导员名称字段，那么班级和辅导员会大量重复，应当拆分出班级表和辅导员表。</p><h3 id="MySQL的存储引擎">MySQL的存储引擎</h3><p>MyISAM、InnoDB、Memory</p><p>MyISAM：全表锁，没有事务和外键，单表执行性能高，并发性能差，空间占用小。</p><p>InnoDB：行锁，有事务，支持自增序列，支持外键，并发性能高，空间占用大。</p><p>Memory：纯内存。</p><h3 id="InnoDB和MyISAM">InnoDB和MyISAM</h3><p>InnoDB支持事务，默认是每一条SQL都封装为一个事务。MyISAM没有事务。</p><p>InnoDB有外键，MyISAM没有。</p><p>InnoDB是行锁，MyISAM是表锁，InnoDB并发场景性能会好一些。</p><p>InnoDB是聚集索引，必须有主键。在表上建立的其他索引，都是指向主键。通过其他索引查询时，先经过索引查到主键，再通过主键查找数据。MyISAM是非聚集索引，主键和索引都是直接指向数据指针，主键和索引相互独立。</p><p>InnoDB不保存表的行数，计算行数时要全表扫描。MyISAM保存了表的行数。</p><h3 id="数据库事务">数据库事务</h3><p>ACID：atomic、consistency、isolation、durability</p><p>原子性：一个事务内的多个操作可以看成一个原子操作，即要么成功要么失败。事务中任意一个操作失败了都会回滚到没有开始事务之前的状态。</p><p>一致性：事务操作的结果和业务规则是一致的。即事务成功时，可以达成操作者目的。</p><p>隔离性：多个事务之间互相数据隔离，彼此没有影响。</p><p>持久性：事务完成后会持久化到数据库。</p><h3 id="索引是什么">索引是什么</h3><p>官方：一种帮助MySQL快速获取数据的数据结构。</p><p>类似目录，默认是B+树实现。</p><h3 id="索引的优缺点">索引的优缺点</h3><p>优点：提升查询速度。</p><p>缺点：索引也有空间占用，更新速度变慢，因为表更新的时候索引也要更新。</p><h3 id="SQL优化">SQL优化</h3><p>原则：避免全表扫描，查询时尽量走索引。少于三张表的查询允许关联，关联不了就走子查询。</p><p>1、尽量不要用select *</p><p>2、减少子查询，用少于三张表的关联查询替代</p><p>3、少用in和not in，因为绝对可以用exists和not exists替代</p><p>4、where子句中慎用!=，走不到索引</p><p>5、少用or，走不到索引</p><p>6、少用null判断，走不到索引</p><h3 id="drop、delete和truncate">drop、delete和truncate</h3><p>drop和truncate不能回滚，不在事务中。delete是在事务中，提交时才生效。</p><p>drop删的最多，会删表结构，可以重新建同名表，及时生效不在事务中。</p><p>truncate其次，对比drop是少删表结构，仅删除数据，还是不在事务中。</p><p>delete再次，仅删除表数据，会在事务中，事务提交后才生效。</p><h3 id="视图">视图</h3><p>理解为虚拟表。类似函数封装的概念。</p><p>可以封装复杂查询的结果。</p><p>可以用来做权限隔离，比如仅展示某几个字段给特定用户。</p><p>底层表有改动，比如拆分了，可以建一个视图，避免上层应用修改SQL。</p><h3 id="并发事务的问题">并发事务的问题</h3><p>脏读：一个事务读到了另一个事务修改了但未提交的数据。</p><p>修改丢失：两个事务同时修改了同一个值，后一个覆盖了前一个。比如两个事务同时做x-1，先读x再减一，并发之后可能结果是x-1而不是x-2。</p><p>不可重复读：一个事务未结束时，读到了另一个事务B修改了并提交的最新值。</p><p>幻读：一个事务查询一批数据的过程中，这批数据被另一个事务新增或删除了一些数据（比如新增了几条数据），于是查询到了新的数据。</p><p>不可重复读重点在修改，幻读重点在新增或删除。重点在行锁和表锁区别。</p><h3 id="事务隔离级别">事务隔离级别</h3><p>MySQL的InnoDB默认是可重复读</p><p>读未提交：脏读，不可重复读，幻读</p><p>读已提交：不可重复读，幻读</p><p>可重复读：幻读（解决了单行的修改，但没解决表级别的增删）</p><p>串行化：事务逐个执行，库锁</p><p>大部分数据库是读已提交级别的事务（比如postgre）。</p><p>mysql额外用了next key Lock，用行锁和间隙锁在可重复读的场景下避免了幻读。具体做法就是，锁了一行数据的前一条和后一条中间的范围。比如5、10、15三条数据，当10被事务读的时候，如果有一个事务插入一条数据8，则会触发间隙锁，插入8的事务会阻塞。这里和聚簇索引也有关系。</p><h3 id="大表优化">大表优化</h3><p>方向：单体变分布式-拆，限制结果数量</p><p>1、查询时限制范围，分页</p><p>2、读写分离，拆到多个机器上</p><p>3、垂直拆分，把字段拆到不同的表中</p><p>4、水平拆分，根据某些逻辑把数据分到不同的片区。比如地区信息做异地多活。</p><h3 id="分库分表后的ID处理">分库分表后的ID处理</h3><p>可转化为全局唯一ID问题：与消息中间件的消息防丢差不多。</p><p>uuid、雪花、美团的leaf。</p><h3 id="MySQL的一条查询SQL执行过程">MySQL的一条查询SQL执行过程</h3><p>8.0没有查询缓存。</p><p>1、语法分析：包括解析SQL语法的正确性，涉及到的表和字段是否存在</p><p>2、准备阶段：会对查询进行逻辑优化，比如选择索引，去除不必要的子查询之类的。逻辑优化后还有物理优化，会根据统计信息和成本计算模型来确定具体的执行计划</p><p>3、执行查询：由执行引擎和存储引擎交互产出查询结果</p><p>4、结果返回：去重排序之类的处理，最终结果返回给客户端</p><h3 id="varchar和char的区别">varchar和char的区别</h3><p>varchar可变长度，char不可变，定长。</p><p>比如varchar(30)的字段存一个字节长度为3的字符，实际空间占用可能为5或者6字节左右，因为有一定的空间用于存储其字段长度。</p><p>char(30)的字段存同样的字符，那么固定占用30字节，后面空的会补零。</p><p>char读写快，空间占用大。varchar省空间，读写慢。</p><h3 id="int-11-的11含义">int(11)的11含义</h3><p>不影响字段的存储范围，仅影响查询的展示效果。</p><h3 id="MySQL的索引类型">MySQL的索引类型</h3><p>主键索引：必须唯一，不可为空</p><p>普通索引：允许重复和空</p><p>唯一索引：值必须唯一，可以为空</p><p>全文索引：只能在文本字段创建，用于加速like查询</p><p>空间索引</p><p>前缀索引</p><p>单列和组合索引：最左匹配原则，优先用组合索引</p><h3 id="什么场景不适合索引">什么场景不适合索引</h3><p>1、经常更新的列</p><p>2、内容大量重复的列</p><p>3、表记录太少（不清楚具体是多少）</p><p>4、写远大于读的表</p><h3 id="MVCC">MVCC</h3><p>多版本并发控制。用来解决读写冲突，是无锁并发。事务分配事务号（单向递增），每个修改保存一个版本。读只读老版本的数据，修改在新版本。可以同时避免脏读和不可重复读。</p><p>实现：</p><p>1、每行数据有一个版本链</p><p>2、事务id，单调递增</p><p>3、可见性判断，根据事务级别来判断是否可见</p><p>4、过期数据清理</p><p>级别和判断逻辑：</p><p>读已提交：单行数据版本号小于当前事务版本号，并且此事务已提交，则可以看到</p><p>可重复读：创建一致性视图，包含事务开始时所有可读的事务号。</p><p>缺点，做不到串行化执行，在解决写冲突的时候还是要用锁或者重做</p><h3 id="MySQL锁">MySQL锁</h3><p>读锁和写锁（共享和排他）。</p><p>按照粒度，可以划分为表锁和行锁。MyISAM是表级别的读写锁，InnoDB支持行锁。</p><h3 id="锁升级">锁升级</h3><p>行锁只能在索引上，没索引自动升级成表锁。</p><p>没走索引时也会升级成表锁。比如非唯一索引相同的内容超过表的一半，优化器会选择不走索引。</p><h3 id="乐观锁和悲观锁">乐观锁和悲观锁</h3><p>悲观锁：倾向于一行数据总是会被同时修改，所以修改前加上排他锁</p><p>乐观锁：倾向于一行数据不一定会被同时修改。加上版本号，类似MVCC，修改前读取版本号，修改后版本号+1，在更新版本号时做版本号检查，如果版本号和预期不符，说明此时有其他人修改了数据，否则就直接更新。乐观锁一般配合自旋，形成一个类似CAS的操作。</p><h3 id="避免死锁">避免死锁</h3><p>获取锁一定要加超时时间；</p><p>按照固定顺序获取资源；</p><p>事务尽量简短；</p><p>事务隔离级别低一些；</p><p>避免事务中的用户交叉；</p><h3 id="索引注意事项">索引注意事项</h3><p>1、where中使用!=、&lt;&gt;、or会导致放弃使用索引</p><p>2、符合索引要复合最左前缀原则</p><p>3、where中进行字段表达式运算、函数运算可能导致索引失效</p><p>4、Like使用是%不能在前，模糊匹配可以用全文索引</p><p>5、字段是字符串类型，必须加引号，否则索引失效</p><h3 id="主键-索引">主键 索引</h3><p>主键是唯一索引，唯一索引不一定是主键</p><p>主键不允许空，唯一索引可以为空</p><p>一个表只能有一个主键，但可以有多个唯一索引</p><p>主键是约束，而唯一索引是冗余的数据结构</p><h3 id="MySQL的高可用">MySQL的高可用</h3><p>MySQL分库分表。</p><p>意义不是很大，一般是整个系统都做高可用。</p><h2 id="总结">总结</h2><p>MySQL的MVCC机制是一个非常标准的实现，可以和我之前做的缓存框架结合起来，很多道理都是共通的。</p>]]></content>
    
    
    <summary type="html">这里记录一下面试的准备过程中关于数据库的笔记。原先工作中对数据库的使用实在是太少了...不过还好大部分东西都还记得，复习一下就很快理解了。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="面试" scheme="https://tulancn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>面试笔记-网络协议</title>
    <link href="https://tulancn.github.io/2024/10/14/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
    <id>https://tulancn.github.io/2024/10/14/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/</id>
    <published>2024-10-14T05:41:52.000Z</published>
    <updated>2025-03-10T14:00:16.272Z</updated>
    
    <content type="html"><![CDATA[<h3 id="HTTP响应码">HTTP响应码</h3><p>200 - 成功</p><p>301 - 永久重定向    302 - 临时重定向</p><p>4开头是客户端问题</p><p>400 - 客户端请求有问题  404 - 找不到对应资源，url错了</p><p>5开头是服务器问题</p><p>500 - 服务器崩了  504 - badgateway</p><h3 id="Forward和Redirect">Forward和Redirect</h3><p>Forward是服务器把请求转发给其他服务器或应用处理，处理完原路返回给客户端</p><p>Redirect是服务器直接返回指令，让客户端重新请求其他服务器 （去买牛肉，到店了发现店面贴着告示，说牛肉店搬到另一条街了，所以要去新的地址买）</p><h3 id="GET和POST">GET和POST</h3><p>用途不同，GET用来获取资源，POST用来提交数据，体现在浏览器的标签只能收藏GET请求，不能收藏POST请求</p><p>参数：GET一般把参数直接拼在URL，POST在消息头或消息体</p><p>编码：GET和URL一致，POST无所谓，编码按照约定来</p><h3 id="TCP和UDP">TCP和UDP</h3><p>TCP先建立连接才能通讯，可靠，传输性能一般</p><p>UDP无连接，不可靠，传输性能高</p><p>TCP是点对点，UDP支持广播</p><p>但UDP也不是绝对不可靠，HTTP3的底层换成了QUIC协议，是基于UDP实现的</p><h3 id="HTTP和HTTPS">HTTP和HTTPS</h3><p>HTTP用80端口，HTTPS用443</p><p>HTTPS多了加密，有性能开销，且加密证书需要额外购买</p><h3 id="HTTP、TCP和Socket">HTTP、TCP和Socket</h3><p>Socket是网络协议的API，由应用层的程序或编程语言提供</p><p>用Socket可以实现一个HTTP协议的客户端或服务端</p><p>HTTP是应用层的协议，基于TCP来实现</p><p>TCP是网络层协议</p><h3 id="HTTP的长连接和短连接">HTTP的长连接和短连接</h3><p>本质是TCP的长连接和短连接。消息头里有个字段是keep-alive，如果为true，则一次请求后之前建立的TCP连接还会保留，不会进行四次挥手，下次再有请求就复用这个连接。</p><p>在同一个客户端会有大量访问的情况下能提升性能，但是对服务器的连接数有要求。所以有了NIO，比如Netty，能支持大量的客户端连接。</p><p>保持长连接的时间由服务端进行控制。tomcat有配置。</p><h3 id="TCP三次握手">TCP三次握手</h3><p>服务端在某个端口开启监听，客户端通过ip+port向服务器发起连接请求。</p><p>第一次：客户端-&gt;服务端，syn=1，seq=x</p><p>第二次：服务端-&gt;客户端，syn=1，seq=y，ack=x+1。第二次表示客户端到服务端的链路已经通了，这时候要验证服务端到客户端的链路是否通。</p><p>第三次：客户端-&gt;服务端，seq=x+1, ack=y+1。告知服务端，你发送的消息我也能收到。</p><p>为什么要三次：因为是双工通讯，要确认消息序号的起始值。</p><h3 id="TCP四次挥手">TCP四次挥手</h3><p>主动断开的一方，发送FIN，告知不再发送消息；对端接收到，返回ack；</p><p>此时对端还可以发送消息，因为对端可能还有消息没传完。</p><p>对端传完之后对端发送FIN，告知不再发送消息；主动断开的一方返回ack，连接彻底断开。</p><h3 id="TCP粘包">TCP粘包</h3><p>本质是因为TCP是传输字节流，字节流是没有边界概念的。</p><p>包的概念是怎么来的？字节流实际在TCP传输的过程中是会分成多个数据包依次传输，这里的数据包切割方式和上层应用无关，因此这些数据包很可能和上层应用的协议包对不上。比如上层应用发了两个请求，但是底层会划分为3个数据包来传输。</p><p>TCP的分包是由滑动窗口来控制的。</p><p>解决方式，都是在应用的协议层解决：</p><p>1、最常用，在协议包里定义协议头，协议头是固定格式的，在协议头里再定义一个协议体长度的变量。HTTP等协议都是如此。</p><p>2、把协议固定长度，所有协议包的长度都一致。</p><p>3、特殊分隔符号。</p><h3 id="TCP可靠性">TCP可靠性</h3><p>最重要的就是序列号和确认号（ack）：包里带seq，接收端检测包的完整性，完整则返回ack。</p><p>超时重传：发送端发了包以后开始计时，如果一定时间内没收到ack，则重传。</p><p>重排序：多个数据包在传输过程中可能乱序，tcp收到后对数据包重排序，保证上层读取的字节流是和发送端传的一致。</p><p>丢弃重复包：比如超时重传等情况会造成重复包，tcp会丢弃这些重复的。</p><p>流量控制：滑动窗口来控制流量，避免发送过快接收端无法处理。（行情客户端遇到过）</p><h3 id="OSI七层模型">OSI七层模型</h3><p>应用层：HTTP、FTP</p><p>表示层：加解密</p><p>会话层：RPC</p><p>传输层：TCP、UDP</p><p>网络层：IP、IPv6</p><p>数据链路层：物理寻址层。交换机等</p><p>物理层：硬件</p><p>各种RPC框架一般是涵盖了会话层以下的所有能力，业务框架可能还会涵盖表示层。</p><h3 id="浏览器输入一个网址后发生了什么">浏览器输入一个网址后发生了什么</h3><p>1、域名-&gt;IP的转换，会经过浏览器缓存、系统缓存、hosts配置文件、路由器缓存，搜索域名对应的服务器。</p><p>2、建立TCP连接</p><p>3、发送HTTP的GET请求</p><p>4、请求经过路由器转发到服务器</p><p>5、服务器处理请求，返回网页文件（HTML）</p><p>6、浏览器渲染html（渲染过程中执行了js，可能产生新的HTTP请求）</p><h3 id="如何跨域">如何跨域</h3><p>浏览器执行js的时候，如果产生新的HTTP请求，且新的请求和当前网址不一致，则发生了跨域，会被拒绝。</p><p>CORS可以，但是需要服务器和浏览器都支持才行。</p><p>使用NGINX反向代理，浏览器不用做任何支持，更合适。原理也是CORS，只是在nginx这一层改了请求。</p><h3 id="HTTP-1-0-1-1-2-0-3-0">HTTP 1.0 1.1 2.0 3.0</h3><p>1.0是无状态无连接，也就是每次请求都建立一次tcp连接。</p><p>1.1添加了connection:keep-alive，可以建立长连接。但是要求服务器必须对应所有请求的顺序返回响应。</p><p>2.0 添加了数据流，gRPC有使用。服务器可以并行传输数据，因为每个流有自己的streamid和序号。但所有流用的是一个TCP连接。</p><p>2.0 还做了头部压缩，通过让服务器和客户端都缓存请求头的field表来实现。</p><p>3.0 底层使用QUIC，不再使用TCP，QUIC是基于UDP实现的。在UDP上实现了TCP的可靠传输能力。</p><h3 id="HTTP与TCP-IP">HTTP与TCP/IP</h3><p>HTTP是应用层的报文协议，一般数据传输是用TCP/IP实现。</p><p>TCP传输的是字节流，没有对包的格式做要求。在此基础上，HTTP定义了请求包的格式。</p><p>理论上可以把HTTP的包用其他传输协议来发送。</p><h3 id="HTTP长连接短连接">HTTP长连接短连接</h3><p>本质是TCP的长连接和短连接。HTTP的1.1定义了Connection:keep-alive的请求头字段，避免每次请求都要三次握手和四次挥手。</p><h3 id="长连接和短连接的优缺点">长连接和短连接的优缺点</h3><p>长连接对于活跃的客户端，能减少连接和断连的成本。但是客户端一多，服务器资源比较浪费，可以用NIO来避免这个问题，一个线程处理多个TCP连接。</p><p>短连接对服务端的管理比较简单，但是qps上去之后在连接和断连上会浪费很多时间和带宽。</p><h3 id="域名解析过程">域名解析过程</h3><p>从开销最小的地方开始找，没有就去更远的地方找。</p><p>1、本机：浏览器缓存、操作系统缓存、hosts文件，</p><p>2、本地配置的DNS服务器，可能是学校、企业的，如果缓存中有，直接返回。</p><p>3、本地配置的DNS服务器没有，则其会向更高的根域名服务器查询，获得对应的权威域名服务器地址，然后再请求权威域名服务器获得IP。获得IP后，本地的DNS服务器会返回给本机，并缓存该域名，下一次再查询就直接从本地的DNS服务器可以查到。</p><p>4、浏览器、操作系统也可能会缓存这个域名。</p>]]></content>
    
    
    <summary type="html">这里记录一下面试的准备过程中关于网络协议的笔记。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="面试" scheme="https://tulancn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>JRE环境使用Arthas</title>
    <link href="https://tulancn.github.io/2024/09/20/work/tips/JRE%E7%8E%AF%E5%A2%83%E4%BD%BF%E7%94%A8Arthas/"/>
    <id>https://tulancn.github.io/2024/09/20/work/tips/JRE%E7%8E%AF%E5%A2%83%E4%BD%BF%E7%94%A8Arthas/</id>
    <published>2024-09-20T11:12:39.000Z</published>
    <updated>2025-03-10T14:00:46.667Z</updated>
    
    <content type="html"><![CDATA[<h2 id="场景">场景</h2><p>实际工作中常遇到一种情况，线上环境出现异常，但是环境安装的是JRE。</p><p>JRE环境下没有了JDK提供的各类工具，根本无法排查问题。如果重装JDK，那么同时也得重启项目，而项目一旦重启，问题的环境就已经丢失，下一次再遇到同样的问题就可遇不可求了。</p><h2 id="解决方案">解决方案</h2><p>使用轻量级的程序附加工具jattach可以做到将Arthas的Jar包attach到特定的进程上。</p><p>网上有类似的解析。最关键的一点是Arthas只需要将一个jar附加到JVM中就可以运行了。</p><p>这里提供一个脚本：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># 获取当前脚本所在的目录</span><br><span class="line">script_dir=$(cd &quot;$(dirname &quot;$&#123;BASH_SOURCE[0]&#125;&quot;)&quot; &amp;&amp; pwd)</span><br><span class="line"></span><br><span class="line"># 用户输入进程ID</span><br><span class="line">read -p &quot;请输入进程ID: &quot; pid</span><br><span class="line"></span><br><span class="line"># 用户输入可选参数host，提供默认值</span><br><span class="line">read -p &quot;请输入主机地址和端口号（格式：IP 端口，默认为 127.0.0.1 3658）: &quot; host</span><br><span class="line">host=$&#123;host:-&quot;127.0.0.1 3658&quot;&#125;</span><br><span class="line"></span><br><span class="line"># 检查当前目录下是否存在jattach文件</span><br><span class="line">if [[ ! -e &quot;$script_dir/jattach&quot; ]]; then</span><br><span class="line">  # 查找以jattach-linux开头的tgz压缩包</span><br><span class="line">  jattach_tgz=$(find &quot;$script_dir&quot; -maxdepth 1 -type f -name &quot;jattach-linux-*.tgz&quot;)</span><br><span class="line"></span><br><span class="line">  if [[ -z &quot;$jattach_tgz&quot; ]]; then</span><br><span class="line">    echo &quot;当前目录下未找到名为jattach的文件或符合条件的jattach-linux-*.tgz压缩包。&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  # 判断系统架构</span><br><span class="line">  system_arch=$(uname -m)</span><br><span class="line">  case $system_arch in</span><br><span class="line">    &quot;aarch64&quot;|&quot;arm64&quot;)</span><br><span class="line">      arch=&quot;arm64&quot;</span><br><span class="line">      jattach_file=&quot;jattach-linux-arm64.tgz&quot;</span><br><span class="line">      ;;</span><br><span class="line">    &quot;x86_64&quot;|&quot;amd64&quot;)</span><br><span class="line">      arch=&quot;x64&quot;</span><br><span class="line">      jattach_file=&quot;jattach-linux-x64.tgz&quot;</span><br><span class="line">      ;;</span><br><span class="line">    *)</span><br><span class="line">      echo &quot;当前系统架构不支持自动解压jattach工具。&quot;</span><br><span class="line">      exit 1</span><br><span class="line">  esac</span><br><span class="line"></span><br><span class="line">  # 检查对应的jattach压缩包是否存在</span><br><span class="line">  if [[ ! -f &quot;$script_dir/$jattach_file&quot; ]]; then</span><br><span class="line">    echo &quot;当前目录下未找到与系统架构匹配的$jattach_file压缩包。&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  # 解压缩对应架构的jattach工具到当前脚本目录，并使用绝对路径</span><br><span class="line">  tar -xzvf &quot;$script_dir/$jattach_file&quot; -C &quot;$script_dir&quot;</span><br><span class="line"></span><br><span class="line">  # 检查解压后jattach是否成功生成</span><br><span class="line">  if [[ ! -e &quot;$script_dir/jattach&quot; ]]; then</span><br><span class="line">    echo &quot;解压失败或未能在当前目录找到解压后的jattach文件。&quot;</span><br><span class="line">    exit 1</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># 使用jattach命令加载arthas-agent.jar，使用绝对路径</span><br><span class="line">&quot;$script_dir/jattach&quot; $pid load instrument false &quot;$script_dir/arthas-agent.jar&quot; &amp;&amp; \</span><br><span class="line"></span><br><span class="line"># 运行arthas客户端，同样使用绝对路径</span><br><span class="line">java -jar &quot;$script_dir/arthas-client.jar&quot; $host</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最关键的就是脚本中最后的两句</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 使用jattach命令加载arthas-agent.jar，使用绝对路径</span><br><span class="line">&quot;$script_dir/jattach&quot; $pid load instrument false &quot;$script_dir/arthas-agent.jar&quot; &amp;&amp; \</span><br><span class="line"></span><br><span class="line"># 运行arthas客户端，同样使用绝对路径</span><br><span class="line">java -jar &quot;$script_dir/arthas-client.jar&quot; $host</span><br></pre></td></tr></table></figure><p>这其实是一个命令，分成了两行。第一个命令是将<code>arthas-agent.jar</code>加载到某个pid的程序中，第二个命令是运行arthas的界面。</p><p>脚本提供了自动安装jattach的能力，只需要将jattach的安装包与此脚本方式在arthas的目录内，然后运行此脚本即可。</p>]]></content>
    
    
    <summary type="html">Arthas是线上故障排查、性能调优常用的工具。这里提供一个在JRE环境也可以使用Arthas的方式。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="优秀实践" scheme="https://tulancn.github.io/tags/%E4%BC%98%E7%A7%80%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>工作中印象最深刻的一件事</title>
    <link href="https://tulancn.github.io/2024/09/16/work/%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%8D%B0%E8%B1%A1%E6%9C%80%E6%B7%B1%E5%88%BB%E7%9A%84%E4%B8%80%E4%BB%B6%E4%BA%8B/"/>
    <id>https://tulancn.github.io/2024/09/16/work/%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%8D%B0%E8%B1%A1%E6%9C%80%E6%B7%B1%E5%88%BB%E7%9A%84%E4%B8%80%E4%BB%B6%E4%BA%8B/</id>
    <published>2024-09-16T12:02:30.000Z</published>
    <updated>2025-03-10T13:56:43.120Z</updated>
    
    <content type="html"><![CDATA[<h2 id="技术之外的东西">技术之外的东西</h2><p>如果是放在还没参加工作时，看到这个问题“你在项目中遇到过的印象最深刻的一件事”，我大概率就是：胡诌一个很难的技术问题，然后说这问题解决的过程有些困难，但是经过我艰苦卓绝地努力，还是完成了，最后觉得自己很有成就感巴拉巴拉……</p><p>但是放到今天，再看这问题，我就倾向于带一些技术之外的东西进去。</p><p>这能聊的就多了。</p><p>比如有个不怎么开窍的实习生，怎么教都教不会，最后是我自己帮他写了代码。我反思之后，觉得自己带人的方式有些问题，从此之后就换了一种方式教人。如果实习生能力差，就选取一些时间上限制不那么多的任务；如果愿意挑战，就分一些预研性质的任务，让他产出方案。<br>这样能说的就多多了，我相信也是大部分面试官可以感同身受的。</p><p>当然上面只是个例子，最主要的一点就是，我觉得和同事相处的方式、选取某种技术的决断、一些任务优先级的取舍，这些都可以是印象深刻的事情。对于这些事情，技术固然包含在其中，但提升了这些事难度的、给人深刻印象的，恰恰就是技术之外的东西。</p><h2 id="印象最深的一件事">印象最深的一件事</h2><p>然后就提到我自己参加工作后印象最深的一件事，应该就是写公司业务协议序列化框架的纯Java版本了。</p><p>准确说起来，这块的代码我没有写多少。我主要是负责这个任务的分配、监督和技术指导，编码由组内的一个同事负责。</p><p>前期预研时，阅读了Protobuf的源码，然后实现时是参考了C++的实现。</p><p>简单来说，就是参考C++的代码，从Protobuf中找到对应的可用代码，然后移植到我们的框架中。</p><p>包体的解析逻辑有大量的可用实现，但是Java对象属性的获取和设置的逻辑，我们是用Unsafe重新写了一遍。</p><p>整个过程顺利得不可思议，原计划两个月的任务，最后一个月就完成了。</p><p>但是问题就出在这个完成之后，我们发现还有一些性能优化的空间。</p><p>这个同事有些钻牛角尖，希望能把整个代码重构，然后做性能优化。但是我组织了他。</p><p>这就是我印象最深的地方了，我经过了取舍，决定把重构和优化的工作往后无限期推迟，让他先基于目前的版本给出详细的文档。</p><p>我们大部分同事都不具备给项目收尾的能力，就是一个模块，写到什么程度，我们就应该停止迭代，转而发布正式版。</p><p>这个界定是有些困难的，作为开发者，你永远不会满意，永远会觉得还有优化空间。</p><p>但工作都是由优先级的，我们只能接受不完美的现实，把有限的精力投入更高优先级的事项中去。</p><p>这就是我从这件事情里学到的。</p>]]></content>
    
    
    <summary type="html">在准备秋招面试，看到这个常见的面试题，突然有感而发。工作之后，发现这个问题只从技术角度看，实在是有些肤浅，或许可以提出更多的东西。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Netty的FastThreadLocal带来了什么？</title>
    <link href="https://tulancn.github.io/2024/09/13/work/java/Netty%E7%9A%84FastThreadLocal%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <id>https://tulancn.github.io/2024/09/13/work/java/Netty%E7%9A%84FastThreadLocal%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/</id>
    <published>2024-09-13T06:49:51.000Z</published>
    <updated>2025-03-10T13:59:46.997Z</updated>
    
    <content type="html"><![CDATA[<h2 id="和Netty的缘分">和Netty的缘分</h2><p>要聊能力前，先聊聊我和Netty的缘分。</p><p>最初接触Netty，是在一个和它完全不相关的项目。需求是要基于C++同事提供的网络通讯中间件写一个Java的网络通讯框架，有人实现了第一版，随后就由我接手了这框架。</p><p>在那个时候就有人告诉我，整个系统链路的性能瓶颈是在这个网络通讯框架上。</p><p>不过在当时也是才疏学浅，一开始定位方向就错了。我在那时候是觉得这框架卡在了服务端的处理上，使用了BIO而不是NIO的方式进行通讯，造成大量的线程空转，以致于拉低了吞吐量。</p><p>接着就开始研究NIO，也就自然而然地学习了Reactor，以及Netty。</p><p>得益于公司提供的极客时间企业会员，我在极客时间上把Netty的课程学了一遍，然后就慢慢了解了Netty的使用方式以及一些实现细节。</p><p>但学完之后却是完全没用上。直到后来做行情客户端、做公司业务协议的服务器时，才用上这部分知识。</p><p>最后，更是把Netty的能力拆分，用到了我自己写的交易框架上。</p><h2 id="FastThreadLocal快在哪？">FastThreadLocal快在哪？</h2><p>聊一个技术，总是得聊聊实现。</p><p>先说结论：<code>FastThreadLocal</code>比起JDK自带的<code>ThreadLocal</code>，少了一次Hash的计算，这就是它快的地方。</p><p>然后再来聊聊其中的实现。</p><p>JDK自带的<code>ThreadLocal</code>，为了做线程隔离，是在每个线程中都创建了一个Hash表。</p><p>这个Hash表的Key是<code>ThreadLocal</code>对象，Value是具体的值。</p><p>它的get()过程是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1、Thread.currentThread()获取到当前线程</span><br><span class="line">2、从Thread对象的hash表中获取当前ThreadLocal对应的Object并返回</span><br></pre></td></tr></table></figure><p>在从hash表获取Object的过程中，不可避免会有一次hash计算。</p><p>而<code>FastThreadLocal</code>则不一样。Netty创建了一个<code>FastThreadLocalThread</code>，继承JDK的<code>Thread</code>类，使用一个<code>Object[]</code>替换了其中的Hash表。</p><p>核心思路就是，创建<code>FastThreadLocal</code>对象时，给其分配一个全局的ID（或者说index）。<br>这样的话，它的get()过程就可以优化为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1、Thread.currentThread()获取到当前线程</span><br><span class="line">2、检查当前线程是不是FastThreadLocalThread，是的话走fastGet();否则走JDK原生的get()</span><br><span class="line">3、fastGet()会从FastThreadLocalThread的Object[]，通过创建FastThreadLocal获得的全局ID，直接用数组随机访问的方式获取值</span><br></pre></td></tr></table></figure><p>从结果上看，一个hash表取值的过程就优化为了数组随机访问，这就是最大的提升。</p><h2 id="带来了什么？">带来了什么？</h2><p>终于讲到重点了。<br>FastThreadLocal把访问线程本地变量的时间，从一次hash计算的时间优化到了一次数组随机访问的时间。从时间上看，大约是4-10ns的操作优化为了小于1ns的操作。</p><p>这带来了一些影响：<br>1、线程级别的资源，可以自行回收而不依赖JVM的GC。比如Netty中有一个工具类，存储着ArrayList和StringBuilder之类的对象，这些对象都存放于FastThreadLocal中。每次使用时，不需要new，而是从工具类中获取当前线程之前使用过的对象，使用完毕后手动清空这些对象即可。<br>2、在1的基础上，构建了Recycler，以及ObjectPool。这些是Netty中Pooled的Buffer的最核心实现。</p><p>也就是说，线程级别的资源访问成本变低了，而线程数量又可控的情况下，我们可以把某些资源每个线程都分配一个。</p><p>同时，在线程自己的视角，所有的资源都只被当前线程使用，线程安全，不需要做任何并发安全的编码，有效提升性能。</p><p>虽然运行时的内存占用上去了，但是不会有更多的垃圾对象产生，这就让JVM的GC压力变得特别小。</p><h2 id="感想">感想</h2><p>Netty不愧是Java编程的教科书，这个FastThreadLocal在我看来，几乎是Java编程思想的集大成之作，完美发挥了Java的长处，尽可能避免了其短处。<br>我虽然工作中已经有使用Netty，但我觉得更底层的细节其实我还是不太清楚。<br>不谈FastThreadLocal，Netty还有很多优秀的实现值得参考，比如它的’0拷贝’、堆外内存的池化和回收机制。这值得我继续深入研究。</p>]]></content>
    
    
    <summary type="html">在之前的工作中，每次和人吹牛逼我都会提到：Netty的FastThreadLocal是一个最基础最核心的技术。为什么这么说呢，这次我专门开一个篇章来聊聊。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>JNI调用的优化（第二版)</title>
    <link href="https://tulancn.github.io/2024/08/08/work/java/JNI%E8%B0%83%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88/"/>
    <id>https://tulancn.github.io/2024/08/08/work/java/JNI%E8%B0%83%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%89%88/</id>
    <published>2024-08-08T02:28:13.000Z</published>
    <updated>2025-03-10T13:59:38.569Z</updated>
    
    <content type="html"><![CDATA[<p>源头是这篇博客：<a href="http://blog.hakugyokurou.net/?p=1758">http://blog.hakugyokurou.net/?p=1758</a></p><p>讲到了最正式的文档也就是bug系统中的一条记录：<a href="https://bugs.openjdk.org/browse/JDK-7013347">https://bugs.openjdk.org/browse/JDK-7013347</a></p><p>另外在stackoverflow上有人爆料了这个能力：<a href="https://stackoverflow.com/questions/36298111/is-it-possible-to-use-sun-misc-unsafe-to-call-c-functions-without-jni/36309652#36309652">https://stackoverflow.com/questions/36298111/is-it-possible-to-use-sun-misc-unsafe-to-call-c-functions-without-jni/36309652#36309652</a></p><p>处于验证的目的，我写了jmh对其进行测试。</p><p>不过测试结果倒是有提升，但也仅仅是20ns。</p><p>聊胜于无，就目前的场景（单次调用800ns）来看，并没有必要做这个优化。</p><p>带来的不稳定因素反而是更大的问题。</p>]]></content>
    
    
    <summary type="html">这一次验证了critical native调用。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="性能调优" scheme="https://tulancn.github.io/tags/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title>聊聊低时延</title>
    <link href="https://tulancn.github.io/2024/05/19/work/%E8%81%8A%E8%81%8A%E4%BD%8E%E6%97%B6%E5%BB%B6/"/>
    <id>https://tulancn.github.io/2024/05/19/work/%E8%81%8A%E8%81%8A%E4%BD%8E%E6%97%B6%E5%BB%B6/</id>
    <published>2024-05-19T06:26:55.000Z</published>
    <updated>2025-03-10T13:57:03.820Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于开发语言">关于开发语言</h2><p>市面上绝大多数低时延相关的产品，都会选择C++作为开发语言。不得不说，C++在处理这种场景有天然的优势，接近底层的好处就是可以做到硬件级别的优化。</p><p>我们公司的消息总线就更为离谱了，全面使用C语言进行开发，性能快到极致。</p><p>在Java这层，想利用硬件的优化，只能使用JNI的技术来调用C函数了。这会导致Java“一次编译处处运行”的能力不再生效，部署时要考虑的事情也会相应增多。</p><p>话又说回来，为了解决不同场景下要加载不同JNI的问题，我也是专门写了一个JNI加载框架。</p><p>同时，也经常会提到的一件事，就是Java的内存管理问题。JVM垃圾回收的随机性，会导致低时延业务可能随时中断，这是不可接受的。</p><p>市面上，对于Java的GC，最好的解决方式是使用ZingJDK。可惜是商业收费的，一般用不了。</p><h2 id="关于架构">关于架构</h2><p>公司对于低时延场景，做的架构我觉得并没有特别优秀。或者说并没有到让人有眼前一亮的感觉的那种地步。</p><p>我们的架构还是分了各种通道，把用户隔离到各个通道中。每个通道享有各自的CPU、线程以及内存数据库等信息。</p><p>通道本质是个数据隔离。</p><p>这种做法下，每个通道内的消息永远由一个线程来执行。那么这个通道内所有的操作，其实都可以做到无锁化了，因为自始至终都仅有一个线程进行读写操作。</p><p>这种方式下，运行时扩容几乎就是不可能的事情。同时，也对数据的分布有了一定的要求，假如某一个通道的用户成交数量特别多，也会影响到整个系统的吞吐量。理想状态下，用户应该是均匀分布在各个通道的。</p><h2 id="关于技术">关于技术</h2><p>低时延的技术栈中，最重要的一点就是无锁化。有锁就快不起来。</p><p>另外，内存技术也是挺重要的。Java就需要去操作堆外内存了，这确实是一般人接触不到的部分。</p><p>我专门写了一个给开发者的文档放在了公司的仓库里，大概整理了一些技术要点。</p><p>想了想，主要就三块：</p><p>1、内存技术。包括堆内堆外，CPU缓存，GC调优等。</p><p>2、序列化技术。包括Java对象的快速访问，协议编解码等。</p><p>3、并发技术。包括原子操作、disruptor、无锁队列等。</p><p>这些技术需要在构建低时延项目时时时刻刻关注，并写到代码中。</p><p>当然还有一个，就是测试框架和性能分析工具。比如Arthus、JMH等，这些也是需要掌握的技术点。</p>]]></content>
    
    
    <summary type="html">低时延平台作为公司的战略产品，一直是交易系统中核心的核心。在对接低时延平台的过程中，我也有了一些想法。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>聊聊管理</title>
    <link href="https://tulancn.github.io/2024/04/29/work/%E8%81%8A%E8%81%8A%E7%AE%A1%E7%90%86/"/>
    <id>https://tulancn.github.io/2024/04/29/work/%E8%81%8A%E8%81%8A%E7%AE%A1%E7%90%86/</id>
    <published>2024-04-29T06:42:33.000Z</published>
    <updated>2025-03-10T13:57:08.540Z</updated>
    
    <content type="html"><![CDATA[<h2 id="经历">经历</h2><p>从我工作以来，我一直在和管理打交道。</p><p>最初入职的时候，听了很多培训课。这些培训课上大多会教学一些工作方式，比如敏捷开发；也会教一些项目管理的基础知识。听了这些培训课，我对管理有了一些初步的认识，但那时候还没想太多。</p><p>接着是参加工作的第一年，大概知道了程序员以后要么转型技术管理，要么走技术专家的路线。</p><p>也是参加工作的第一年，在基本熟悉了工作内容后，领导很直接地分给了我一个大任务，要我去负责开发平台。作为平台的责任人，免不了向上汇报和向下管理。但是当时的情况下，向下也就一个实习生，另外就是一个专门做Java插件开发的程序员。这要谈管理，也管不上什么东西，但确实需要我作为中间人，去分配任务，监控进度了。</p><p>再往后是开发平台一期结束，开始规划低码平台，也就是二期的开发平台，这正好是我参加工作的第二年。低码平台用的是敏捷开发，我作为被管理的一方，参与了到里面。到这时候才算是正式入了管理的门。敏捷开发的节奏很快，每天都有明确的任务需求，这难免会让人感到压力巨大；不过工作的充实感很足，每天不需要迷茫，能充分发挥每个人的能力。这份经历对我影响很大。</p><p>第三年的时候，我开始鼓捣底层框架。低时延的技术也是这时候开始由我负责。不过很有趣的是，到这一年，反而没人到我手下工作了，我光杆司令一个。我一个人挑起了低时延组件的大梁，平时基本就是自己规划工作内容，自己写日报，最后定期和上级领导汇报进度。这段时间工作强度明显加大，也参加到了业务的第一线。</p><p>最后终于也是突破了底线，让我去了业务现场做支持。持续了六周，等我23年国庆后回到深圳，恍惚间觉得自己和还在公司里的这些同事有了天差地别。</p><p>有了在业务第一线的经历，我也终于名正言顺地升上了部门副经理。24年，考虑到我今年会离职去留学，领导分了三个同事到我手下，一方面是分担我的工作，另一方面是把我之前的工作成果沉淀下来，免得后面无人能维护我的代码。</p><p>而这时候，我也算正式升到管理岗，一方面要负责开发的工作，另一方面也需要管控工作进度，还要考虑下属的能力培养。慢慢的也有了一些自己的心得。</p><h2 id="领导力的来源是什么？">领导力的来源是什么？</h2><p>我觉得这是个很现实的问题。这里的领导力，就是你说的话到底算不算数，算几分数。</p><p>大多数时候，职级就是最现实的领导力来源。高职级的人能管控下属的绩效考评，就是等同于给了一定的权利来发布命令、指导工作。下属会倾向于获得更高的绩效来听取命令。</p><p>第二，我觉得是责任的承担问题。如果一个项目有负责人，那么他下属的所有行为他都要担责。而下属也会在听取命令时，想着：反正出问题了最后负责的不是我，就能一定程度上为自己开脱。</p><p>第三，是领导的个人能力。如果说领导能提出建设性意见，这是最能服众的一种手段了。下属遇到困难无法解决，而领导能上手解决问题，或是提供指导，这种类似师徒的观念，在中国人的心目中是最有效的建立上下级的方式。</p><p>第四，在于下级自身。人都有性格，有些人性格上认真负责，那么就应该给予重用，或者是通过言语的方式提供一定的鼓励或其他情绪价值；有些人怕事，内向，那么就应该做好思想工作，或是通过流程制度、团队建设的方式是来将其融入团队内部；有些人不负责，或是能力不够，应当给予批评，并指名改进的方向，屡教不改的，应该移出团队。</p><p>对于最后一种人，若是因为有复杂情况不能处理的，应该坦诚说明情况。不可因为此人影响到整体。这类人过多，则领导自己应该考虑跑路。</p><p>总体来说，要有领导力，首先应该有一定的技术水平，这是基础。水平高，则多多举行技术沙龙、代码评审、方案评审等，能服众，也能培养团队；水平低，则和技术骨干搞好关系，虚心听取意见，也是可以的。其次，要摆平心态，即不干扰下属工作，保持距离感；也要适度检查进度，施加压力。最后，是要鼓励和批评并举，好的要夸，坏的要批，保持自己的原则，让他人从心底里服从。</p>]]></content>
    
    
    <summary type="html">想起来写这个事情，是正好从上海出差回家的时候，回想起这两年的经历，让我深有感触。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="管理" scheme="https://tulancn.github.io/tags/%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>双重锁和CAS</title>
    <link href="https://tulancn.github.io/2024/02/18/work/java/%E5%8F%8C%E9%87%8D%E9%94%81%E5%92%8CCAS/"/>
    <id>https://tulancn.github.io/2024/02/18/work/java/%E5%8F%8C%E9%87%8D%E9%94%81%E5%92%8CCAS/</id>
    <published>2024-02-18T05:47:01.000Z</published>
    <updated>2025-03-10T13:58:17.532Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引子">引子</h2><p>在做一些变量的初始化时，我会有如下的实现：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 缓存存储对象的类型</span><br><span class="line"> */</span><br><span class="line">private volatile Class&lt;?&gt; rowType;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 获取缓存存储对象的类型</span><br><span class="line"> *</span><br><span class="line"> * @return 缓存存储对象的类型</span><br><span class="line"> */</span><br><span class="line">public Class&lt;?&gt; rowType() &#123;</span><br><span class="line">    if (rowType == null) &#123;</span><br><span class="line">        synchronized (this) &#123;</span><br><span class="line">            if (rowType == null) &#123;</span><br><span class="line">                // todo 这里是初始化rowType的逻辑</span><br><span class="line">             </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return rowType;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种写法，我最初是在Protobuf生成的代码中看到的，后来查阅了一下，这种逻辑叫双重锁。</p><p>或者说，叫双重检查模式，是一种软件的设计模式。</p><p>而我在写一些其他的代码时，往往也会使用类似这种模式的方式。用多了以后，我觉得可以分析一下其中的道理。</p><h2 id="分析">分析</h2><p>双重锁的逻辑是两次检查：首先验证锁定条件(第一次检查)，只有通过锁定条件验证才真正的进行加锁逻辑并再次验证条件(第二次检查)。</p><p>那么，如果中间的锁定操作，我们改成一个计算过程，在最后赋值之前做二次检查，是否也是可以的呢？</p><p>答案是肯定的。下面给个伪代码说明：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">int a = 0;</span><br><span class="line">int b = a;</span><br><span class="line">// 第一次检查</span><br><span class="line">if (a == b) &#123;</span><br><span class="line">  // 上锁</span><br><span class="line">  lock.lock();</span><br><span class="line">  // 第二次检查</span><br><span class="line">  if (a == b) &#123;</span><br><span class="line">  // 计算操作</span><br><span class="line">int c = b + 1；</span><br><span class="line">  // 赋值</span><br><span class="line">  a = c;</span><br><span class="line">  &#125;</span><br><span class="line">  lock.unLock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可是这样就太重了，要知道，有些时候，加锁的成本也很高。使用双重锁仅仅是能避免锁定中的操作多次重复，但是没有从根本上避免锁，所有的操作还是在锁中进行的，这就没有很好地发挥多线程的优势。</p><p>那么优化一下，把这个锁去掉，只在计算结束后进行一次检查，是否可行呢？答案也是肯定的，这样就变成了乐观锁+自旋锁的结合。伪代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">int a = 0;</span><br><span class="line">// 自旋</span><br><span class="line">for (;;) &#123;</span><br><span class="line">int b = a;</span><br><span class="line">// 计算操作</span><br><span class="line">int c = b + 1；</span><br><span class="line">// 第一次检查</span><br><span class="line">if (b == a) &#123;</span><br><span class="line">// 赋值</span><br><span class="line">a = c;</span><br><span class="line">// 第二次检查</span><br><span class="line">if (a == c) &#123;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到锁被去掉了，这样并发时性能会远优于加锁。这就是CAS机制。</p><p>但是这里的CAS机制还不够，并不能保证极端情况下的线程安全。因为还有指令重排序的问题。</p><p>为了解决指令重排序的问题，需要在特定的变量上添加volatile注解。</p><p>在高性能场景下，CAS是一种非常优秀的机制，有以下优点：</p><ol><li>高效性：CAS 操作不需要加锁，因此可以避免加锁操作所带来的性能开销。</li><li>原子性：CAS 操作是原子的，因此可以保证操作的一致性。</li><li>无阻塞：CAS 操作不会阻塞线程，因此可以避免线程的切换和上下文切换带来的开销。</li></ol><h2 id="总结">总结</h2><p>双重锁的方式，一般是用于初始化的场景，是用来避免某个代码块执行两次的。</p><p>而在此基础上我们推演出自旋锁+乐观锁的方式，这样能实现无锁并发，这就是CAS机制。</p>]]></content>
    
    
    <summary type="html">这次来聊聊多线程场景的二次确认机制。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="多线程" scheme="https://tulancn.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>龙年第一天</title>
    <link href="https://tulancn.github.io/2024/02/18/life/%E9%BE%99%E5%B9%B4%E7%AC%AC%E4%B8%80%E5%A4%A9/"/>
    <id>https://tulancn.github.io/2024/02/18/life/%E9%BE%99%E5%B9%B4%E7%AC%AC%E4%B8%80%E5%A4%A9/</id>
    <published>2024-02-18T05:22:14.000Z</published>
    <updated>2025-03-10T13:55:59.523Z</updated>
    
    <content type="html"><![CDATA[<p>昨晚8点从德清出发，到杭州转乘卧铺高铁，今早6点45到深圳北。从深圳北出站，坐5号线地铁到家，放下了行李，洗了个脸，匆匆忙忙出门上班。</p><p>早上8点，到工位坐下。原来从老家到工位，也不过12个小时的距离。</p><p>回顾去年，我最大的一件事，就是选择去香港留学。找了中介，考了雅思；至于这个选择最大的动力来源，就是我的女朋友。工作上，出差去北京中信证券，去惠州集中开发；深入业务线，搞懂了不少东西；也当了小领导，分配和规划任务，和其他人对接。</p><p>去年确实是做了不少事。</p><p>过年期间，也试着去学开车。这事情上手之后确实不难。也拜访了女朋友的家里，还在她家吃了两顿饭，见了她的亲朋好友。最后一天上午，我收到了第一份offer，来自港理工。这个年圆满收工。</p><p>那今年的话，我就得准备好去读书了。工作中，手上的事情也要慢慢放下，或者分配给别人，或者直接收尾。</p><p>今年想做的事情有好多，我要学粤语，要健身，要学python，想去旅游，想赚钱……人生总是这么丰富多彩，有些事情，一旦开始，就踩不住刹车了。</p><p>我真的非常感激我的女朋友，没有她的支持，我一定不会有动力去改变。我和她规划了好多好多的未来，这些都等着我们去实现。</p><p>最后，希望在新的一年，我能拿到更好的offer，能在工作上有更多的创新，能减肥成功，能学好粤语。</p>]]></content>
    
    
    <summary type="html">今天是龙年上班的第一天，正月初九。</summary>
    
    
    
    <category term="生活" scheme="https://tulancn.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="杂谈" scheme="https://tulancn.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
</feed>
