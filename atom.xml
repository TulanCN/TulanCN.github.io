<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>涂蓝</title>
  
  
  <link href="https://tulancn.github.io/atom.xml" rel="self"/>
  
  <link href="https://tulancn.github.io/"/>
  <updated>2025-09-28T08:06:50.137Z</updated>
  <id>https://tulancn.github.io/</id>
  
  <author>
    <name>Tulan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>中小模型优化</title>
    <link href="https://tulancn.github.io/2025/09/28/work/tips/%E4%B8%AD%E5%B0%8F%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/"/>
    <id>https://tulancn.github.io/2025/09/28/work/tips/%E4%B8%AD%E5%B0%8F%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96/</id>
    <published>2025-09-28T07:09:56.000Z</published>
    <updated>2025-09-28T08:06:50.137Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>理想情况下，我们购买大公司的算力服务或模型服务，用差不多的提示词调下接口，然后拿着可靠的返回值继续我们的业务逻辑。</p><p>但实际工作中，并没有那么多的钱能让我们去买这些算力或模型服务，而且往往是打着数据安全的旗号来的。</p><p>最后大部分公司里，可能就是拿着来之不易的一点点经费，自己摸索部署了一个小小的模型来开发对接。</p><p>很不幸，虽然我在的公司挺大的，但所在的部门经费有限。</p><p>考虑到项目成本和合同收益，让我发挥出了垃圾佬的本性，对着小模型鼓捣了半天，也算是有了些成果。</p><p>主打一个花小钱办大事，用不那么聪明的模型来干活。</p><h2 id="场景">场景</h2><p>应该算是典型的质检验收场景，大概就是安装设备的师傅会拍照上传到平台，平台要用多模态的AI来识别这个照片是否合格。</p><p>不同的设备安装合格的要求不一样，有些复杂有些简单，因此模型的智力水平会大大影响结果。</p><h2 id="常见的问题与解决方案">常见的问题与解决方案</h2><p>先聊聊小模型常见的问题吧。</p><h3 id="格式限制不生效">格式限制不生效</h3><p>这应该是很常见的问题了。提示词里限制了模型返回JSON格式，但模型就是自说自话返回了大段大段的废话。</p><p>解决方法有多个，这些方法可以一起用上。</p><ol><li>宽松校验：不严格校验模型返回的格式，而是进行关键内容提取，只要内容里有JSON就提取出来，认为模型是返回成功了。因为模型很多时候只是说了些废话，但最终还是能正常返回一个JSON格式的答案。所以只要能提取出最终的JSON，这问题就解决了。</li><li>重试：很多时候模型只是小概率返回非预期的回答，此时重试一下可能就好了。</li><li>调整温度：温度太高了导致模型开始自由发挥，此时适当调低温度也是可行的，比如从0.75调整到0.5。</li><li>模型总结：进行多轮对话，前面是聊业务，在最后一轮让模型把结果总结成JSON格式，大部分时候也是能产生较好的效果。</li></ol><h3 id="答非所问">答非所问</h3><p>在调试过程中，我使用的模型常常会回答&quot;我是个文本模型，不支持图像识别&quot;。</p><p>可实际上它是支持图像识别的。感觉是模型训练时有数据污染导致的，这问题是概率性触发。</p><p>解决方法：</p><ol><li>调整TopP和温度：TopP和温度太低时似乎这问题会出现概率变高。</li><li>调整系统提示词：告知模型你具有图像识别的能力。</li><li>重试：多次尝试大部分时候能正常返回。</li></ol><h3 id="识别不准确">识别不准确</h3><p>在某些场景下，发现模型不能正常识别到图片的内容，开始胡言乱语。</p><p>解决方法：</p><ol><li>调整系统提示词：需要判断是否是系统提示词出现了问题，可能是业务场景涉及到某些专业知识，而模型并没有直接识别到是此类场景，可以调整下系统提示词简要说明行业背景。</li><li>调整用户提示词：有些是用户提示词的描述不够准确，比如&quot;电线&quot;的概念较为宽泛，而模型不太能处理此类描述。一个好的办法是先把图片送给模型，<strong>让模型来描述图片的内容，然后挑选模型自己的描述来重构提示词</strong>。</li><li>拆分任务：多个任务放在一次问答里返回时效果不太好，因此更建议把任务拆分成一个个小的子任务，让模型分别处理。这问题在大参数量模型上较少出现，但在小参数量模型上会变得较为突出。</li></ol><h3 id="模型输出较慢">模型输出较慢</h3><p>在硬件系统太差的情况下，小模型的输出会很慢，此时建议直接换硬件。</p><p>实在不行的话只能限制下模型的输出token，在提示词中尽可能减少需要模型回答的内容。</p><p>比如“仅返回是或否”等。</p><h2 id="总体优化方向">总体优化方向</h2><p>小模型的缺点在于先验知识较少，指令遵循能力较差，返回的内容不可控。</p><p>因此，为了提高准确度，只能进行一些特定的优化。说白了就是<strong>拿时间换准确性</strong>。</p><p>一种方式是使用类似思维链的能力，在提示词中引导模型一步一步思考，先查什么后查什么，最后总结一个结果。</p><p>大部分时候这种方式能让模型在输出一大段对话后给出一个相对可靠的结论。</p><p>还有种方式是用代码来替换模型的部分操作，尽可能拆分任务。这就得具体问题具体讨论了，可以参考后面的实践。</p><h2 id="实践">实践</h2><p>需求：检测图片中是否存在XX设备，网线插入的网线口是否和工单中说明的一致，图片里是否有二维码。这三个都符合则合格。</p><p>在做这个需求的时候，显然需要拆分任务。</p><p>我先开始是拆成了三个任务：检测设备、检查网线口、检查二维码。</p><p>首先遇到的问题是格式限制不生效的问题。我参考其他人的提示词，要求模型返回JSON格式。但实际发现模型完全不会遵循这个指令，只会输出大段的思考过程，然后总结一个JSON的结果出来。</p><p>考虑到这是三个任务都是返回个是或否就足够的，我重新优化了一下提示词。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">仅判断图片中是否存在类似&quot;XXX箱&quot;的物体，不做其他判断。输出：存在输出1；不存在输出2。仅输出数字，不得包含其他内容。</span><br></pre></td></tr></table></figure><p>修改之后大部分时候是可以返回纯数字了，但偶尔还是会返回思考内容。</p><p>于是我更进一步，限制了模型的max_token，直接卡死在1。如此一来，只需要检查是否是返回了数字1或2即可。</p><p>这是被阿里的一个二元模型所启发的。</p><p>之后就遇到了另一个问题，这三个任务有难有简单，检查网线口的任务复杂程度比另外两个要高。</p><p>这个任务限制模型返回1或2后，模型反而完不成任务了。</p><p>因此只能继续调试，我发现输出大段思考过程后，模型确实能做出相对正确的判断。</p><p>所以就做了结果提取的能力，让模型在第一轮对话里进行思考，再进行第二轮对话，让其总结内容返回1或2。</p><p>这样就提高了一定的准确性。</p><p>重试的机制也加了，配合max_token调整为1，在前两个简单任务中表现相当不错。</p><p>在复杂任务里，重试则分为两部分。总结会重试3次，3次失败之后会回退到前面的图片识别。图片识别则是重试2次，2次失败后认定图片有问题，将其纳入人工干预的范畴。</p><p>对于总结这事，本来是考虑另外有个8B的文本模型来进行总结，但因为资源紧张就没落地。</p>]]></content>
    
    
    <summary type="html">工作中使用了一些中小型的模型，也进行了多次优化以提高准确性。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>对于当前大模型的直觉认知</title>
    <link href="https://tulancn.github.io/2025/09/05/work/%E6%9D%82%E8%B0%88/%E5%AF%B9%E4%BA%8E%E5%BD%93%E5%89%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9B%B4%E8%A7%89%E8%AE%A4%E7%9F%A5/"/>
    <id>https://tulancn.github.io/2025/09/05/work/%E6%9D%82%E8%B0%88/%E5%AF%B9%E4%BA%8E%E5%BD%93%E5%89%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9B%B4%E8%A7%89%E8%AE%A4%E7%9F%A5/</id>
    <published>2025-09-05T07:06:21.000Z</published>
    <updated>2025-09-05T09:55:19.682Z</updated>
    
    
    <summary type="html">工作中会发现很多人并不会合理地使用大模型，因此这里记录下自己的一些技巧。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>linux学习记录</title>
    <link href="https://tulancn.github.io/2025/09/03/work/%E8%BF%90%E7%BB%B4/linux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    <id>https://tulancn.github.io/2025/09/03/work/%E8%BF%90%E7%BB%B4/linux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</id>
    <published>2025-09-03T09:05:56.000Z</published>
    <updated>2025-09-03T09:37:01.924Z</updated>
    
    <content type="html"><![CDATA[<p>如果说一个开发人员对linux不够熟悉，可能就永远止步于中级开发了。</p><p>原来写Java比较多，Spring在部署上已经给了一套良好的解决方案，能协助构建Fat Jar，用简单的<code>java -jar</code>命令就能启动程序。</p><p>也就导致我一直对linux的了解没那么深入。</p><p>目前的工作中，采用K8S这一套体系，所有的项目都打包成docker镜像再进行后续的部署。</p><p>这种情况下，如何编写docker file构建镜像，如何进行服务编排就是新的要求了。</p><p>docker file中的语法类似shell命令，能使用linux的一些基础命令比如cp、mv、rm、mkdir等。</p><p>毕竟docker是基于linux的镜像构建的嘛，支持这些命令也正常。</p><p>所以突然有个机会能把linux的命令重新学一下，我觉得还挺好的。</p><h2 id="基础命令">基础命令</h2><h3 id="1-文件操作命令">1. 文件操作命令</h3><h4 id="目录导航">目录导航</h4><ul><li><code>pwd</code> - 显示当前工作目录</li><li><code>ls</code> - 列出目录内容<ul><li><code>ls -l</code> 详细列表</li><li><code>ls -a</code> 显示隐藏文件</li><li><code>ls -h</code> 人类可读大小</li></ul></li><li><code>cd</code> - 切换目录<ul><li><code>cd ~</code> 回家目录</li><li><code>cd -</code> 返回上一个目录</li><li><code>cd ..</code> 上级目录</li></ul></li></ul><h4 id="文件操作">文件操作</h4><ul><li><code>mkdir</code> - 创建目录<ul><li><code>mkdir -p</code> 创建多级目录</li></ul></li><li><code>touch</code> - 创建空文件或更新时间戳</li><li><code>cp</code> - 复制文件/目录<ul><li><code>cp -r</code> 递归复制目录</li><li><code>cp -v</code> 显示复制过程</li></ul></li><li><code>mv</code> - 移动或重命名文件</li><li><code>rm</code> - 删除文件<ul><li><code>rm -r</code> 递归删除目录</li><li><code>rm -f</code> 强制删除</li><li><code>rm -i</code> 交互式删除</li></ul></li></ul><h4 id="文件查看">文件查看</h4><ul><li><code>cat</code> - 连接并显示文件内容</li><li><code>more</code> - 分页显示文件内容</li><li><code>less</code> - 更好的分页显示（可上下滚动）</li><li><code>head</code> - 显示文件开头<ul><li><code>head -n 10</code> 显示前10行</li></ul></li><li><code>tail</code> - 显示文件末尾<ul><li><code>tail -n 20</code> 显示后20行</li><li><code>tail -f</code> 实时跟踪文件变化</li></ul></li></ul><h3 id="2-权限管理">2. 权限管理</h3><h4 id="权限基础">权限基础</h4><p>Linux文件权限分为三类：</p><ul><li>用户(User) - 文件所有者</li><li>组(Group) - 文件所属组</li><li>其他(Other) - 其他用户</li></ul><p>每种权限有三种类型：</p><ul><li>读® - 4</li><li>写(w) - 2</li><li>执行(x) - 1</li></ul><h4 id="权限命令">权限命令</h4><ul><li><code>chmod</code> - 修改文件权限<ul><li>数字方式: <code>chmod 755 filename</code></li><li>符号方式: <code>chmod u+x filename</code></li></ul></li><li><code>chown</code> - 修改文件所有者<ul><li><code>chown user:group filename</code></li></ul></li><li><code>chgrp</code> - 修改文件所属组</li></ul><h4 id="特殊权限">特殊权限</h4><ul><li>SUID (Set User ID) - 以文件所有者身份执行</li><li>SGID (Set Group ID) - 以文件所属组身份执行</li><li>Sticky Bit - 目录中只有文件所有者能删除文件</li></ul><h3 id="3-文本处理">3. 文本处理</h3><h4 id="文本搜索">文本搜索</h4><ul><li><code>grep</code> - 文本搜索<ul><li><code>grep -i</code> 忽略大小写</li><li><code>grep -n</code> 显示行号</li><li><code>grep -v</code> 反向匹配</li><li><code>grep -r</code> 递归搜索</li></ul></li></ul><h4 id="文本处理工具">文本处理工具</h4><ul><li><code>awk</code> - 文本处理语言<ul><li><code>awk '&#123;print $1&#125;'</code> 打印第一列</li></ul></li><li><code>sed</code> - 流编辑器<ul><li><code>sed 's/old/new/g'</code> 全局替换</li></ul></li><li><code>cut</code> - 截取文本<ul><li><code>cut -d: -f1</code> 以冒号分隔取第一字段</li></ul></li><li><code>sort</code> - 排序</li><li><code>uniq</code> - 去重</li></ul><h3 id="4-帮助文档">4. 帮助文档</h3><ul><li><code>man</code> - 查看命令手册<ul><li><code>man ls</code> 查看ls命令帮助</li></ul></li><li><code>--help</code> - 查看命令简要帮助<ul><li><code>ls --help</code></li></ul></li><li><code>info</code> - 查看info格式文档</li></ul><h3 id="5-管道">5. 管道</h3><p>管道操作符<code>|</code>，通过管道我们能将多个命令组合起来，起到更好的效果。</p><p>注意，管道是同时起了多个进程，前一个进程的实时输出会自动输入到下一个进程里，而不是前一个执行完了才执行下一个。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -aux | grep java</span><br></pre></td></tr></table></figure><h2 id="系统管理">系统管理</h2><h3 id="1-用户和组管理">1. 用户和组管理</h3><h4 id="用户管理命令">用户管理命令</h4><ul><li><code>useradd</code> - 添加用户<ul><li><code>useradd -m</code> 创建家目录</li><li><code>useradd -s</code> 指定shell</li><li><code>useradd -g</code> 指定主组</li></ul></li><li><code>usermod</code> - 修改用户属性<ul><li><code>usermod -aG</code> 添加附加组</li><li><code>usermod -L</code> 锁定用户</li><li><code>usermod -U</code> 解锁用户</li></ul></li><li><code>userdel</code> - 删除用户<ul><li><code>userdel -r</code> 删除用户及家目录</li></ul></li></ul><h4 id="密码管理">密码管理</h4><ul><li><code>passwd</code> - 设置密码<ul><li><code>passwd -l</code> 锁定密码</li><li><code>passwd -u</code> 解锁密码</li><li><code>passwd -d</code> 删除密码</li></ul></li><li><code>chage</code> - 修改密码过期信息<ul><li><code>chage -l</code> 查看密码信息</li><li><code>chage -M</code> 设置最大天数</li></ul></li></ul><h4 id="组管理">组管理</h4><ul><li><code>groupadd</code> - 添加组</li><li><code>groupmod</code> - 修改组</li><li><code>groupdel</code> - 删除组</li><li><code>gpasswd</code> - 组密码管理</li></ul><h4 id="权限提升">权限提升</h4><ul><li><code>su</code> - 切换用户<ul><li><code>su -</code> 完全切换环境</li><li><code>su -c</code> 以其他用户执行命令</li></ul></li><li><code>sudo</code> - 以超级用户权限执行<ul><li><code>/etc/sudoers</code> 配置文件</li><li><code>visudo</code> 安全编辑sudoers</li></ul></li></ul><h3 id="2-进程管理">2. 进程管理</h3><h4 id="进程查看">进程查看</h4><ul><li><code>ps</code> - 进程状态<ul><li><code>ps aux</code> 查看所有进程</li><li><code>ps -ef</code> 完整格式列表</li><li><code>ps -o</code> 自定义输出格式</li></ul></li><li><code>top</code> - 实时进程监控<ul><li>交互命令: k(杀死), r(renice), h(帮助)</li></ul></li><li><code>htop</code> - 增强版top（需要安装）</li><li><code>pstree</code> - 树状显示进程</li></ul><h4 id="进程控制">进程控制</h4><ul><li><code>kill</code> - 发送信号给进程<ul><li><code>kill -9</code> 强制终止</li><li><code>kill -15</code> 正常终止</li><li><code>kill -l</code> 列出所有信号</li></ul></li><li><code>pkill</code> - 按名称杀死进程</li><li><code>killall</code> - 杀死所有同名进程</li><li><code>nice</code> - 设置进程优先级</li><li><code>renice</code> - 修改运行中进程优先级</li></ul><h4 id="后台作业">后台作业</h4><ul><li><code>&amp;</code> - 后台运行</li><li><code>jobs</code> - 查看后台作业</li><li><code>fg</code> - 前台运行</li><li><code>bg</code> - 后台继续运行</li><li><code>nohup</code> - 忽略挂起信号运行</li></ul><h3 id="3-系统监控">3. 系统监控</h3><h4 id="系统状态">系统状态</h4><ul><li><code>uptime</code> - 系统运行时间</li><li><code>w</code> - 显示登录用户及进程</li><li><code>who</code> - 显示登录用户</li><li><code>last</code> - 显示登录历史</li></ul><h4 id="内存监控">内存监控</h4><ul><li><code>free</code> - 内存使用情况<ul><li><code>free -h</code> 人类可读格式</li><li><code>free -m</code> 以MB显示</li></ul></li><li><code>vmstat</code> - 虚拟内存统计<ul><li><code>vmstat 1</code> 每秒刷新</li></ul></li></ul><h4 id="磁盘监控">磁盘监控</h4><ul><li><code>df</code> - 磁盘空间使用<ul><li><code>df -h</code> 人类可读格式</li><li><code>df -i</code> inode使用情况</li></ul></li><li><code>du</code> - 目录空间使用<ul><li><code>du -sh</code> 汇总显示</li><li><code>du -h --max-depth=1</code> 一级目录</li></ul></li></ul><h4 id="性能监控">性能监控</h4><ul><li><code>iostat</code> - CPU和磁盘I/O统计</li><li><code>mpstat</code> - CPU使用统计</li><li><code>sar</code> - 系统活动报告<ul><li>需要安装sysstat包</li></ul></li><li><code>dstat</code> - 多功能系统监控</li></ul><h3 id="4-日志管理">4. 日志管理</h3><h4 id="系统日志">系统日志</h4><ul><li><code>/var/log/messages</code> - 主要系统日志</li><li><code>/var/log/secure</code> - 安全相关日志</li><li><code>/var/log/cron</code> - 计划任务日志</li><li><code>/var/log/boot.log</code> - 启动日志</li></ul><h4 id="日志查看工具">日志查看工具</h4><ul><li><code>tail</code> - 查看日志尾部</li><li><code>less</code> - 分页查看日志</li><li><code>grep</code> - 搜索日志内容</li><li><code>journalctl</code> - systemd日志查看<ul><li><code>journalctl -f</code> 实时跟踪</li><li><code>journalctl -u</code> 按服务查看</li><li><code>journalctl --since</code> 时间范围</li></ul></li></ul><h3 id="5-系统信息">5. 系统信息</h3><h4 id="硬件信息">硬件信息</h4><ul><li><code>uname</code> - 系统信息<ul><li><code>uname -a</code> 所有信息</li></ul></li><li><code>lscpu</code> - CPU信息</li><li><code>lsblk</code> - 块设备信息</li><li><code>lspci</code> - PCI设备信息</li><li><code>lsusb</code> - USB设备信息</li></ul><h4 id="系统版本">系统版本</h4><ul><li><code>cat /etc/redhat-release</code> - CentOS版本</li><li><code>cat /etc/os-release</code> - 系统发行版信息</li></ul><h2 id="网络配置">网络配置</h2><h3 id="1-网络接口管理">1. 网络接口管理</h3><h4 id="传统网络命令">传统网络命令</h4><ul><li><code>ifconfig</code> - 接口配置（已逐渐被淘汰）<ul><li><code>ifconfig eth0 up</code> 启用接口</li><li><code>ifconfig eth0 down</code> 禁用接口</li></ul></li><li><code>route</code> - 路由管理<ul><li><code>route -n</code> 数字格式显示路由表</li><li><code>route add</code> 添加路由</li><li><code>route del</code> 删除路由</li></ul></li></ul><h4 id="现代网络命令（iproute2）">现代网络命令（iproute2）</h4><ul><li><code>ip</code> - 多功能网络工具<ul><li><code>ip addr</code> 查看IP地址</li><li><code>ip link</code> 查看网络接口</li><li><code>ip route</code> 查看路由表</li><li><code>ip neigh</code> 查看ARP表</li></ul></li><li><code>ss</code> - socket统计（替代netstat）<ul><li><code>ss -tuln</code> 查看监听端口</li><li><code>ss -t</code> 查看TCP连接</li><li><code>ss -u</code> 查看UDP连接</li></ul></li></ul><h3 id="2-网络配置文件">2. 网络配置文件</h3><h4 id="网络配置文件位置">网络配置文件位置</h4><ul><li><code>/etc/sysconfig/network-scripts/</code> - 网络脚本目录</li><li><code>ifcfg-eth0</code> - 以太网接口配置文件</li><li><code>route-eth0</code> - 接口路由配置文件</li></ul><h4 id="配置文件示例">配置文件示例</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># /etc/sysconfig/network-scripts/ifcfg-eth0</span></span><br><span class="line">DEVICE=eth0</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.1.100</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.1.1</span><br><span class="line">DNS1=8.8.8.8</span><br><span class="line">DNS2=8.8.4.4</span><br><span class="line">ONBOOT=<span class="built_in">yes</span></span><br></pre></td></tr></table></figure><h3 id="3-防火墙配置（firewalld）">3. 防火墙配置（firewalld）</h3><h4 id="firewalld基础概念">firewalld基础概念</h4><ul><li>区域(zone): 预定义的规则集合</li><li>服务(service): 预定义的服务规则</li><li>端口(port): 自定义端口规则</li></ul><h4 id="firewall-cmd命令">firewall-cmd命令</h4><ul><li><code>firewall-cmd --state</code> 查看防火墙状态</li><li><code>firewall-cmd --get-active-zones</code> 查看活动区域</li><li><code>firewall-cmd --list-all</code> 查看所有规则</li><li><code>firewall-cmd --reload</code> 重载配置</li></ul><h4 id="常用操作">常用操作</h4><ul><li>添加服务: <code>firewall-cmd --add-service=http</code></li><li>添加端口: <code>firewall-cmd --add-port=8080/tcp</code></li><li>永久生效: <code>--permanent</code> 参数</li><li>移除规则: <code>--remove-service</code> 或 <code>--remove-port</code></li></ul><h3 id="4-网络诊断工具">4. 网络诊断工具</h3><h4 id="连通性测试">连通性测试</h4><ul><li><code>ping</code> - ICMP连通性测试<ul><li><code>ping -c 4</code> 发送4个包</li><li><code>ping -i 2</code> 间隔2秒</li></ul></li><li><code>traceroute</code> - 路由追踪<ul><li><code>traceroute example.com</code></li></ul></li><li><code>mtr</code> - 更好的路由追踪工具</li></ul><h4 id="端口扫描">端口扫描</h4><ul><li><code>nmap</code> - 网络扫描工具<ul><li><code>nmap -sS</code> TCP SYN扫描</li><li><code>nmap -sU</code> UDP扫描</li><li><code>nmap -O</code> 操作系统检测</li></ul></li><li><code>telnet</code> - 测试端口连通性<ul><li><code>telnet host port</code></li></ul></li></ul><h4 id="网络抓包">网络抓包</h4><ul><li><code>tcpdump</code> - 命令行抓包工具<ul><li><code>tcpdump -i eth0</code> 指定接口</li><li><code>tcpdump port 80</code> 指定端口</li><li><code>tcpdump -w file.pcap</code> 保存到文件</li></ul></li><li><code>wireshark</code> - 图形化抓包工具</li></ul><h3 id="5-DNS和主机名">5. DNS和主机名</h3><h4 id="DNS配置">DNS配置</h4><ul><li><code>/etc/resolv.conf</code> - DNS解析配置</li><li><code>/etc/hosts</code> - 本地主机名解析</li><li><code>nslookup</code> - DNS查询工具</li><li><code>dig</code> - 更强大的DNS查询工具<ul><li><code>dig example.com</code> 查询A记录</li><li><code>dig MX example.com</code> 查询MX记录</li></ul></li></ul><h4 id="主机名管理">主机名管理</h4><ul><li><code>hostname</code> - 查看或设置主机名</li><li><code>hostnamectl</code> - 系统主机名控制</li><li><ul><li><code>hostnamectl set-hostname</code> 设置主机名</li></ul></li></ul><h3 id="6-网络服务">6. 网络服务</h3><h4 id="SSH服务">SSH服务</h4><ul><li><code>ssh</code> - 安全远程登录<ul><li><code>ssh user@host</code></li><li><code>ssh -p port user@host</code> 指定端口</li></ul></li><li><code>scp</code> - 安全文件传输<ul><li><code>scp file user@host:path</code></li></ul></li><li><code>ssh-keygen</code> - SSH密钥生成</li></ul><h4 id="其他网络工具">其他网络工具</h4><ul><li><code>curl</code> - URL传输工具</li><li><code>wget</code> - 网络下载工具</li><li><code>netcat</code> - 网络瑞士军刀</li></ul><h2 id="磁盘管理">磁盘管理</h2><h3 id="1-磁盘基础概念">1. 磁盘基础概念</h3><h4 id="磁盘设备命名">磁盘设备命名</h4><ul><li><code>/dev/sda</code> - 第一块SCSI/SATA磁盘</li><li><code>/dev/sdb</code> - 第二块SCSI/SATA磁盘</li><li><code>/dev/sda1</code> - 第一块磁盘的第一个分区</li><li><code>/dev/vda</code> - 虚拟化环境中的磁盘</li></ul><h4 id="磁盘类型">磁盘类型</h4><ul><li>HDD: 机械硬盘</li><li>SSD: 固态硬盘</li><li>NVMe: 高速固态硬盘（/dev/nvme0n1）</li></ul><h3 id="2-磁盘分区管理">2. 磁盘分区管理</h3><h4 id="分区工具">分区工具</h4><ul><li><code>fdisk</code> - 传统分区工具（MBR）</li><li><code>parted</code> - 高级分区工具（支持GPT）</li><li><code>gdisk</code> - GPT分区工具</li></ul><h4 id="fdisk基本操作">fdisk基本操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/sdb</span><br><span class="line"><span class="comment"># 常用命令:</span></span><br><span class="line"><span class="comment"># n - 新建分区</span></span><br><span class="line"><span class="comment"># d - 删除分区</span></span><br><span class="line"><span class="comment"># p - 打印分区表</span></span><br><span class="line"><span class="comment"># w - 写入并退出</span></span><br><span class="line"><span class="comment"># q - 退出不保存</span></span><br></pre></td></tr></table></figure><h4 id="parted基本操作">parted基本操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">parted /dev/sdb</span><br><span class="line"><span class="comment"># 常用命令:</span></span><br><span class="line"><span class="comment"># mklabel gpt - 创建GPT分区表</span></span><br><span class="line"><span class="comment"># mkpart primary ext4 1MiB 10GiB - 创建分区</span></span><br><span class="line"><span class="comment"># print - 显示分区信息</span></span><br><span class="line"><span class="comment"># quit - 退出</span></span><br></pre></td></tr></table></figure><h3 id="3-文件系统管理">3. 文件系统管理</h3><h4 id="文件系统类型">文件系统类型</h4><ul><li>ext4: Linux默认文件系统</li><li>xfs: 高性能文件系统</li><li>swap: 交换分区</li><li>vfat: FAT32文件系统</li></ul><h4 id="创建文件系统">创建文件系统</h4><ul><li><code>mkfs.ext4 /dev/sdb1</code> - 创建ext4文件系统</li><li><code>mkfs.xfs /dev/sdb1</code> - 创建xfs文件系统</li><li><code>mkswap /dev/sdb2</code> - 创建交换分区</li><li><code>swapon /dev/sdb2</code> - 启用交换分区</li></ul><h4 id="文件系统检查">文件系统检查</h4><ul><li><code>fsck.ext4 /dev/sdb1</code> - 检查ext4文件系统</li><li><code>xfs_repair /dev/sdb1</code> - 修复xfs文件系统</li><li><code>tune2fs</code> - 调整ext文件系统参数</li></ul><h3 id="4-挂载管理">4. 挂载管理</h3><h4 id="挂载命令">挂载命令</h4><ul><li><code>mount /dev/sdb1 /mnt/data</code> - 挂载分区</li><li><code>umount /mnt/data</code> - 卸载分区</li><li><code>mount -a</code> - 挂载所有在fstab中的文件系统</li></ul><h4 id="etc-fstab配置">/etc/fstab配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设备        挂载点   文件系统  选项      备份 检查</span></span><br><span class="line">/dev/sdb1    /data    ext4     defaults  0    0</span><br><span class="line">UUID=xxxx    /backup  xfs      defaults  0    0</span><br></pre></td></tr></table></figure><h4 id="挂载选项">挂载选项</h4><ul><li>defaults: 默认选项（rw,suid,dev,exec,auto,nouser,async）</li><li>noatime: 不更新访问时间</li><li>nodiratime: 不更新目录访问时间</li><li>ro: 只读挂载</li><li>rw: 读写挂载</li></ul><h3 id="5-LVM逻辑卷管理">5. LVM逻辑卷管理</h3><h4 id="LVM概念">LVM概念</h4><ul><li>PV (Physical Volume): 物理卷</li><li>VG (Volume Group): 卷组</li><li>LV (Logical Volume): 逻辑卷</li></ul><h4 id="LVM创建流程">LVM创建流程</h4><ol><li>创建物理卷: <code>pvcreate /dev/sdb</code></li><li>创建卷组: <code>vgcreate vg_data /dev/sdb</code></li><li>创建逻辑卷: <code>lvcreate -L 10G -n lv_data vg_data</code></li><li>创建文件系统: <code>mkfs.ext4 /dev/vg_data/lv_data</code></li><li>挂载使用: <code>mount /dev/vg_data/lv_data /data</code></li></ol><h4 id="LVM管理命令">LVM管理命令</h4><ul><li><code>pvdisplay</code> - 显示物理卷信息</li><li><code>vgdisplay</code> - 显示卷组信息</li><li><code>lvdisplay</code> - 显示逻辑卷信息</li><li><code>vgextend</code> - 扩展卷组</li><li><code>lvextend</code> - 扩展逻辑卷</li><li><code>resize2fs</code> - 调整文件系统大小</li></ul><h3 id="6-磁盘配额管理">6. 磁盘配额管理</h3><h4 id="配额配置步骤">配额配置步骤</h4><ol><li>启用配额: <code>usrquota,grpquota</code> 挂载选项</li><li>创建配额数据库: <code>quotacheck -cug /mountpoint</code></li><li>启用配额: <code>quotaon /mountpoint</code></li><li>设置配额: <code>edquota username</code></li></ol><h4 id="配额管理命令">配额管理命令</h4><ul><li><code>quota</code> - 查看用户配额</li><li><code>repquota</code> - 报告配额使用情况</li><li><code>setquota</code> - 设置配额限制</li></ul><h3 id="7-磁盘性能监控">7. 磁盘性能监控</h3><h4 id="性能监控工具">性能监控工具</h4><ul><li><code>iostat</code> - I/O统计信息</li><li><code>iotop</code> - I/O使用情况top</li><li><code>hdparm</code> - 硬盘参数和性能测试</li><li><code>dd</code> - 磁盘读写性能测试</li></ul><h4 id="性能测试示例">性能测试示例</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写性能测试</span></span><br><span class="line"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=testfile bs=1G count=1 oflag=direct</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读性能测试</span></span><br><span class="line"><span class="built_in">dd</span> <span class="keyword">if</span>=testfile of=/dev/null bs=1G count=1</span><br></pre></td></tr></table></figure><h2 id="服务管理">服务管理</h2><h3 id="1-systemd基础">1. systemd基础</h3><h4 id="systemd简介">systemd简介</h4><ul><li>系统初始化系统</li><li>服务管理守护进程</li><li>提供系统状态快照</li><li>支持并行启动服务</li></ul><h4 id="核心概念">核心概念</h4><ul><li>单元(Unit): 系统资源抽象（服务、挂载点、设备等）</li><li>目标(Target): 单元组，类似运行级别</li><li>依赖关系: 服务启动顺序控制</li></ul><h3 id="2-服务管理命令">2. 服务管理命令</h3><h4 id="systemctl基础命令">systemctl基础命令</h4><ul><li><code>systemctl status service</code> - 查看服务状态</li><li><code>systemctl start service</code> - 启动服务</li><li><code>systemctl stop service</code> - 停止服务</li><li><code>systemctl restart service</code> - 重启服务</li><li><code>systemctl reload service</code> - 重载配置</li></ul><h4 id="服务启用和禁用">服务启用和禁用</h4><ul><li><code>systemctl enable service</code> - 启用开机启动</li><li><code>systemctl disable service</code> - 禁用开机启动</li><li><code>systemctl is-enabled service</code> - 检查启用状态</li><li><code>systemctl is-active service</code> - 检查活动状态</li></ul><h4 id="系统状态查看">系统状态查看</h4><ul><li><code>systemctl list-units</code> - 列出所有单元</li><li><code>systemctl list-unit-files</code> - 列出所有单元文件</li><li><code>systemctl list-dependencies</code> - 列出依赖关系</li><li><code>systemctl show service</code> - 显示服务属性</li></ul><h3 id="3-服务单元文件">3. 服务单元文件</h3><h4 id="单元文件位置">单元文件位置</h4><ul><li><code>/usr/lib/systemd/system/</code> - 系统安装的单元文件</li><li><code>/etc/systemd/system/</code> - 系统管理员创建的单元文件</li><li><code>/run/systemd/system/</code> - 运行时单元文件</li></ul><h4 id="单元文件结构">单元文件结构</h4><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=服务描述</span><br><span class="line"><span class="attr">After</span>=network.target</span><br><span class="line"><span class="attr">Requires</span>=network.target</span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="attr">Type</span>=simple</span><br><span class="line"><span class="attr">User</span>=username</span><br><span class="line"><span class="attr">ExecStart</span>=/path/to/command</span><br><span class="line"><span class="attr">Restart</span>=always</span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure><h4 id="常用配置选项">常用配置选项</h4><ul><li><strong>Type</strong>: simple, forking, oneshot, notify</li><li><strong>User/Group</strong>: 运行服务的用户和组</li><li><strong>ExecStart</strong>: 启动命令</li><li><strong>ExecStop</strong>: 停止命令</li><li><strong>Restart</strong>: 重启策略</li><li><strong>Environment</strong>: 环境变量</li></ul><h3 id="4-目标-Target-管理">4. 目标(Target)管理</h3><h4 id="系统目标">系统目标</h4><ul><li><code>multi-user.target</code> - 多用户文本模式</li><li><code>graphical.target</code> - 图形界面模式</li><li><code>rescue.target</code> - 救援模式</li><li><code>emergency.target</code> - 紧急模式</li></ul><h4 id="目标操作">目标操作</h4><ul><li><code>systemctl isolate target</code> - 切换到目标</li><li><code>systemctl get-default</code> - 获取默认目标</li><li><code>systemctl set-default target</code> - 设置默认目标</li><li><code>systemctl list-dependencies target</code> - 列出目标依赖</li></ul><h3 id="5-日志管理">5. 日志管理</h3><h4 id="journalctl命令">journalctl命令</h4><ul><li><code>journalctl</code> - 查看所有日志</li><li><code>journalctl -u service</code> - 查看指定服务日志</li><li><code>journalctl -f</code> - 实时跟踪日志</li><li><code>journalctl --since &quot;1 hour ago&quot;</code> - 时间范围查询</li><li><code>journalctl -p err</code> - 查看错误级别日志</li></ul><h4 id="日志过滤">日志过滤</h4><ul><li><code>journalctl _PID=1234</code> - 按进程ID过滤</li><li><code>journalctl _UID=1000</code> - 按用户ID过滤</li><li><code>journalctl -k</code> - 查看内核日志</li><li><code>journalctl --disk-usage</code> - 查看日志磁盘使用</li></ul><h3 id="6-定时任务管理">6. 定时任务管理</h3><h4 id="systemd定时器">systemd定时器</h4><ul><li>替代传统的cron</li><li>更精确的时间控制</li><li>更好的日志集成</li></ul><h4 id="定时器配置">定时器配置</h4><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># timer单元</span></span><br><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=定时任务描述</span><br><span class="line"></span><br><span class="line"><span class="section">[Timer]</span></span><br><span class="line"><span class="attr">OnCalendar</span>=*-*-* <span class="number">02</span>:<span class="number">00</span>:<span class="number">00</span></span><br><span class="line"><span class="attr">Persistent</span>=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=timers.target</span><br></pre></td></tr></table></figure><h4 id="传统cron">传统cron</h4><ul><li><code>/etc/crontab</code> - 系统crontab</li><li><code>/etc/cron.d/</code> - 额外cron配置</li><li><code>crontab -e</code> - 编辑用户cron</li><li><code>crontab -l</code> - 列出用户cron</li></ul><h3 id="7-服务故障排查">7. 服务故障排查</h3><h4 id="常见问题">常见问题</h4><ul><li>服务启动失败</li><li>依赖关系问题</li><li>权限配置错误</li><li>资源限制问题</li></ul><h4 id="排查工具">排查工具</h4><ul><li><code>systemctl status</code> - 查看服务状态</li><li><code>journalctl -u</code> - 查看服务日志</li><li><code>systemctl daemon-reload</code> - 重载配置</li><li><code>systemctl reset-failed</code> - 重置失败状态</li></ul><h2 id="后话">后话</h2><p>这个文档是刚开始学习时的记录。</p><p>后面经过一段时间的工作后，觉得能看明白日志，能排查问题才是最重要的。</p><p>可能是我作为开发人员的习惯吧，总觉得遇到错误得弄明白才行。</p><p>开发人员也有遇到线上问题的时候，这时候能看日志，能通过命令旁敲侧击查找问题的根源就很重要了。</p><p>能否处理线上事故，排查的手段是否丰富，这应该是高级开发和普通开发最大的差异点之一了。</p><p>就我个人来说，以前写Java也处理过不少线上问题，有自己的经验，但到运维这块，我发现遇到的网络问题明显更多一些…</p><p>所以就很头疼，硬着头皮学了不少东西，把网络这块的缺漏又补了一遍。</p><p>明明研究生的时候就又重学了一遍网络，没想到工作之后又得学，果然是学无止境。</p><p>我做现在的工作时总会想起多隆，解决一个个问题，处理好一件件事情，以后会不会也有机会成为像多隆一样的技术专家呢？</p>]]></content>
    
    
    <summary type="html">轮岗当了一段时间的运维，重新学了下linux。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="linux" scheme="https://tulancn.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>AI Coding使用记录-20250813</title>
    <link href="https://tulancn.github.io/2025/08/13/work/%E6%9D%82%E8%B0%88/AI-Coding%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95-20250813/"/>
    <id>https://tulancn.github.io/2025/08/13/work/%E6%9D%82%E8%B0%88/AI-Coding%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95-20250813/</id>
    <published>2025-08-13T03:31:09.000Z</published>
    <updated>2025-09-02T07:50:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>今年AI coding赛道一直挺火热。从25年2月左右我因为学校的项目开始使用cursor写前端，到目前在工作里用claude code之类的工具写业务，这中间也用了不少工具，体验有差异。这里记录下目前的体验。</p><h2 id="GitHub-Copilot-初版">GitHub Copilot(初版)</h2><p>单独把初版的Copilot拿出来说，还是因为它在当时确实太惊艳了。</p><p>最初版的copilot只有代码补全的能力，但仅仅靠着这个能力，就征服了一众开发者的心。</p><p>我刚开始使用的时候，copilot主要是可以补全一些变量名和写了一半的代码。</p><p>我在代码里输入前缀，它就会自动补全我的后续内容。</p><p>比如我输入下面这句话。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OrderVO order = new Order();</span><br></pre></td></tr></table></figure><p>当我输入Or后，代码编辑器的提示就出现了，会让我选择什么对象，并自动引入。</p><p>然后我按下空格，copilot自动帮我生成了一个变量名，我tab接收。</p><p>再接着我按下=，输入new，copilot就自动帮我生成后续的Order();。</p><p>整个流程非常顺畅。</p><p>使用copilot能大大减少程序员在IDE中进行代码复制粘贴的情况。</p><p>还有种用法是通过注释编写一些提示词，让copilot帮你写一些小的代码。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">// 生成订单号</span><br></pre></td></tr></table></figure><p>比如我在代码中写下注释，生成订单号，copilot就会自动根据上下文（本文件内）尝试补全。</p><p>这种类似于对话的方式，也能节省一定的开发时间。</p><p>总的来说，在初版的Copilot出现时，<strong>大家几乎一边倒的好评</strong>，绝大多数质疑还仅仅是集中于代码的隐私问题。</p><p>当时有博主发文称，已经不知道离开copilot怎么编码了。用了copilot之后，他的工作就变成了：搭建好框架，写好注释，然后停下来，等copilot帮他生成后续的代码。</p><p>或许后面AI Coding的一些问题，此时也初现倪端。</p><h2 id="通义灵码">通义灵码</h2><p>在阿里推出通义大模型后，通义灵码的插件也快速上线了，对标的就是Copilot。功能上也相似，提供代码补全。</p><p>公网版我试用之后，觉得提示的质量不及Copilot，于是弃用。</p><p>但后来公司采购了企业版的通义灵码，私有化部署并且上传了公司的代码库，之后又尝试用了一段时间。</p><p>私有化部署解决了企业内部使用代码补全插件的隐私问题。发展到这一步时，我觉得代码补全的功能已经算相当完善了。</p><p>比起Copilot，通义灵码最大的优势是快。毕竟没有墙，甚至是内网部署，补全的速度比Copilot要快非常多。</p><p>这段时间Copilot也陆续推出了一些工具，比如生成注释、生成单测之类的能力，通义灵码也跟进了，但我用的不多。</p><p>而这时候，claude才刚推出2.0，大家觉得是个gpt-4的平替，还没有意识到它后续的统治力。</p><p>这段时间，我们公司内部报告说代码补全生成的代码占到了我们公司新增代码的10%。</p><h2 id="代码补全的小总结">代码补全的小总结</h2><p>第一阶段的AI Coding，主要作用是代码补全。</p><p>我见过一些论调是代码补全的能力与IDE本身提供的关键字、提示有一些冲突。对于熟练使用IDE插件的人来说，这个补全的功能有些鸡肋。</p><p>从我自身的角度来说，我是觉得还算好用的。编程中有个说法是“心流”，代码补全插件能节省我编程时在文件间来回切换，复制粘贴的操作，能更加关注于代码本身，也就更加容易进入“心流”。</p><p>大多数人的评价应该是与我一致的：<strong>好用，对编程速度有一定的提升，但没有产生质变</strong>。</p><p>微软对Copilot的定位是一个编程的副驾驶，主要起辅助工作，编程的主要责任还是在用户。</p><p>这个定位相当准确，在人机交互上也是相当友好——光标停顿时自动进行补全。使用久了之后，我基本可以预测Copilot可以帮我补全哪些代码，我仅需要写好必要的内容，然后等它补全完毕，再按下tab就行。</p><h2 id="GitHub-Copilot-Chat">GitHub Copilot Chat</h2><p>在Copilot推出一段时间后，微软和Github又推出了Copilot Chat。</p><p>Copilot Chat像是一个<strong>过渡产品</strong>，它的作用是让用户在IDE中和LLM对话，询问一些技术问题。</p><p>本意可能是为了让程序员不需要另外切换窗口来复制代码，但实际使用时，挑选合适的代码文件也是个很麻烦的活。</p><p>产品性上，Copilot Chat有直接插入代码到文件中的能力。有一些用，但不多。</p><p>还有选中一段代码，直接贴到Copilot Chat中询问，也没太多用处。</p><p>但还是有些场景是比较适合的。代码补全只能覆盖到写代码的场景，但实际工作中，还会有写配置、Debug的情况，这种时候Copilot Chat更能发挥一些作用。spring boot工程有很多配置项，有些开源组件的配置一时想不起来也很正常，我这时候会打开Copilot Chat问一下，往往能获得准确的回答。</p><h2 id="通义灵码（企业版）">通义灵码（企业版）</h2><p>上面也说了我们公司采购了通义灵码，这里有几个比较有趣的事情。</p><p>企业版的通义灵码是支持定制企业logo的，但我们上的第一版还是通义灵码的logo，直到第二个版本才更新。所以所有人都知道这玩意儿是个套壳的。但我们的AI部还是厚着脸皮和领导汇报说是自己产出的代码插件生成的采纳率达到了多少多少…</p><p>企业版的通义灵码支持上传企业代码库。我们公司是用的自己的中台框架，通义灵码的提示有的时候确实无法提示到公司框架的API。按理说这里就得上传公司的代码和文档，方便通义灵码提示。但我们的AI部不知道哪根筋抽了，只上传了工具类，导致相当长一段时间公司框架的问题通义灵码都回答不上来，为此我们部门还被领导骂了（中台框架就是我们写的）。</p><p>通义灵码后来也有样学样搞了个对话框，还支持企业配置自己的提示词和指令。我们部门抽调过去的小哥配了个单测的指令，试图一键生成单元测试的代码。但最后使用效果不太好，主要是上下文缺失，生成的代码少了很多赋值操作。</p><h2 id="Chat插件总结">Chat插件总结</h2><p>在代码补全插件的基础上，把对话框也搬进IDE，能拓展一部分覆盖场景，但终究带来的提升还是有限。</p><p>现在回头看的话，当时的大模型可能已经能正常生成我们想要的代码了，问题在于筛选上下文的工作太麻烦，以至于大家不太愿意去做。</p><p>试想一下，我要生成一个service文件的单元测试，我得把这个文件涉及到的所有POJO都一并传递给LLM，才有可能生成我想要的代码。</p><p>所以，Chat插件就卡在了一个不上不下的地方。</p><p>那么解决方案呢？就是索引和工具，或者用个更加新潮的说法：agent。</p><h2 id="Cursor">Cursor</h2><p>Cursor在产品刚推出的时候我就有关注。</p><p>Cursor是从VS Code的仓库fork了一个自己的分支，因此可以使用VS Code的插件。这方式挺取巧的，但确实不赖。</p><p>一开始Cursor想和Copilot做区分，Copilot的定位是帮你补全目前光标所在为止的代码，Cursor的定位是预测你下一个光标要移动的位置。</p><p>这是个很神奇的体验。我刚改了上一行代码，然后Cursor就会自动提示是否要跳转到另外一行，按tab接收就会自动跳转过去，并进行新的补全和提示。用Cursor写前端项目的话，确实就一直是在tab tab tab。</p><p>但Cursor真正火起来，还是在Claude 3.5 sonnect推出之后。因为Cursor Composer配合Claude 3.5 sonnect的效果实在是太惊艳了。</p><p>Cursor Composer的功能很简单，你写需求和指令，它帮你生成对应的代码，然后你接受，则自动插入到仓库的文件中。</p><p>说白了就是帮你写代码。Cursor给LLM开发了各种工具，能索引代码片段送给LLM，也能把LLM生成的代码写入到文件。</p><p>Cursor Composer一开始用的模型都不够聪明，导致生成的代码充满了报错、异常。</p><p>写个小功能还不如自己来，那么为什么还要用模型来生成呢？</p><p>在AI Coding界，Claude 3.5 sonnect可以说就像是人类第一次学会了用火，此后就迎来了跨越式的发展。</p><p>在Claude 3.5 sonnect的加持下，Cursor Composer生成代码可用性大大提升。</p><p>我也就是这个时候开始使用Cursor的，绝大多数时候生成的代码都是可用的，如果不行大不了回退然后修改提示词重新生成一次。</p><p>整个开发流程完全变了，从我亲自写代码，变成了写需求和指令给Cursor，然后筛选下相关的文件，最后等它生成。</p><p>这就是Vibe Coding的魅力啊。</p><p>后续Cursor修改了代码生成的模式，改为提供agent模式，进一步简化了开发流程。</p><p>我甚至不再需要去做文件筛选的工作了，Cursor会主动寻找它需要的代码文件，读取到上下文中。</p><p>这时候写一份高质量提示词才是我最重要的工作，其次就是看懂Cursor的输出，并修改其中不正确的部分。</p><p>如果说要我评价此时的Cursor，应该说是<strong>如日中天，颠覆性的体验</strong>。</p><h2 id="Cursor-（锁区）">Cursor （锁区）</h2><p>好景不长，后来Cursor因为成本问题几次三番修改使用条款，不断缩减20刀订阅计划的使用次数。</p><p>最开始是用完了订阅的请求次数，还能用慢请求，大不了排队。</p><p>后面改成了用完了请求次数就只能用auto模式的请求。auto模式是由Cursor来帮你选择用什么模型生成代码。</p><p>最后又改，auto也限流了。</p><p>我正好在换工作，开发任务不多，也很少用Cursor了，限流对我的影响倒是没那么大。</p><p>但是有一天，Cursor锁区了。</p><p>于是我把它彻底埋了。</p><p>当初捧得有多高，现在摔得有多惨。</p><h2 id="后Cursor时代">后Cursor时代</h2><p>在Cursor锁区之后，我尝试寻找Cursor的替代品。</p><p>AI coding体验过之后，很难再接受手动编写大量的代码了。</p><p>那段时间我试了Cline、Roo Code、Claude Code。</p><p>模型上则是用了Kimi K2、GLM 4.5、Deepseek V3、Deepseek V3.1、Qwen3 Coder等。</p><p>该说不说，Claude 3.5 Sonnect是个坎。模型的能力过了这个坎，写的代码就能在实际中用了。</p><h2 id="Claude-Code">Claude Code</h2><p>Cursor无疑是带火了AI Coding赛道。这是目前大家肉眼可见能赚钱的地方。</p><p>但死活没想到的是，模型提供商自己入局了。</p><p>Claude Code就是Anthropic推出的代码工具，主打一个Agent。</p><p>这也是个颠覆性的产品，居然是命令行操作。</p><p>命令行的好处是能嵌入所有的IDE终端，VS Code、Cursor、IDEA等等，都能无缝再接入一个Claude Code。</p><p>作为一个产品，实在是过于超前了。以至于google光速抄了一个Gemini Cli出来并开源了。</p><p>但国内使用还是有些问题，比如账户和锁区。所以我是配合Claude Code Router转发了国内的模型来使用的。</p><p>虽然很可惜用不上最强的能力，但总体来说体验还是不错的，尤其是Cursor锁区的情况下。</p><p>Claude Code有个todo list的功能，应该说是相当优秀，会先列出需要执行的任务，然后依次执行。</p><p>后面cursor、roo code等其他工具也都跟进了todo list。</p><p>Cluade Code的计划模式是一个比较有特色的功能，shift + tab按两次就切换到plan mode，这个模式下给出的任务会先进行规划而不进行具体的代码实现，如果发现计划不对可以及时指出并修改。一个很好的实践是先用4.0进行规划，再切换3.5进行代码生成。</p><p>我个人很喜欢计划模式。因为很多时候其实需求描述出来我自己心里也没底，看到Claude Code帮我生成了具体的实现方案后，我再看其中的细节我才能确认它写的对不对。</p><p>Claude Code离谱的点在于，依托于它强大的底层模型，只要计划没什么问题，它最终实现出来的代码几乎是立刻就能拿来用的。</p><p>另外再大概聊聊使用的几个国产模型。</p><p>Kimi K2在这里的表现不太行，当我在计划模式里两次修改了计划后，它就开始前言不接后语了，拉黑。</p><p>Qwen3 Coder很棒，但真的是token杀手，给我三个问题干了25块钱，因此也被我拉黑。</p><p>Deepseek V3的表现过于平庸，也弃用。</p><p>GLM 4.5出乎我意料，还挺不错的。但问题是Claude Code的上下文是以256K为基准，而GLM 仅有128K，不算少但使用时多少还是有些不方便。</p><h2 id="Roo-Code">Roo Code</h2><p>对标Cursor的Composer功能，社区推出了Cline，一个开源的VS Code插件。</p><p>但由于Cline不太愿意合并社区的pr，因此又有人另外fork了Cline的仓库，推出了Roo Code。</p><p>我后面有不少功能是用Roo Code写的。</p><p>Roo Code有不少很亮眼的功能：上下文窗口显示、仓库索引、自定义模式、子任务模式。</p><p>对于小任务，我直接配合GLM 4.5先计划后实现。而较大的任务则可以使用Orchestrator模式拆分为多个子任务，每个子任务有独立的上下文窗口，从而在有限的上下文里实现更多的功能。</p><p>Orchestrator模式的潜力我觉得还没完全发挥出来，目前传递给子任务的上下文还是有缺失，很多时候父任务已经阅读过的内容在子任务中还得重新阅读一遍，这就导致整个流程会拉得很长，并且有相当多的token被浪费了。</p><h2 id="Github-Copilot（Agent）">Github Copilot（Agent）</h2><p>在Cursor锁区后，想用Claude就得费点功夫了。</p><p>有网友推荐我可以用Github Copilot，目前也是支持Claude 4.0的。于是我时隔半年再次开始使用Github Copilot。</p><p>有意思的是，这次我打开Copilot就看到一个Agent模式。试用了一下，体验也和Cursor类似。</p><p>毕竟有学生优惠，而且还能直连，所以后面也尝试用Copilot写了一些小功能。</p><p>Claude 4还是厉害，写出来的代码质量很高。</p><p>缺点就是使用上有些小功能比不上Cursor，而且任务执行总是会中断，但总体来说给人一种它很想取代Cursor，或者说是把Cursor作为直接竞争对手的感觉…</p><p>Copilot在IDEA中的Agent模式总是会卡死，因此我后面都切换到VS Code里去了。</p><h2 id="Vibe-Coding">Vibe Coding</h2><p>现在流行的概念叫Vibe Coding，倒是不清楚这名字怎么来的…但突然间都在说。</p><p>大概指的就是利用各种AI编程工具，仅用提示词来写代码，完成需求。</p><p>或许最终目标就是自动化编程吧，仅仅提下需求就能完成所有的实现工作。</p><p>我觉得这是个很困难的事情，事实上大部分人在一个东西做出来之前并不知道它到底长啥样，也是因此才有敏捷开发，快速迭代的概念出来。</p><h2 id="小小的总结">小小的总结</h2><p>话题回到最近用的几个编码工具。很显然，AI Coding的过程经历了几个阶段：代码补全、被动问答、主动搜索仓库问答、agent。</p><p>代码补全就是Github Copilot为代表的插件。主要是协助编码，效率提升在10%-20%。</p><p>被动问答则是Github Copilot Chat为代表的插件。主要能在IDE内进行问答，还能添加项目文件到对话框。编码效率没有提升多少，但debug之类的效率能有一定提升，算它总体30%吧。</p><p>主动问答是类似Cursor这类编码IDE，能建立仓库代码文件的索引，也有用向量数据库做的。这类的特点是会自动搜索相关的代码片段一起传给LLM。在被动问答的基础上减轻了开发者的提问负担，生成的代码有时候也可以直接使用了。</p><p>最后就是Agent模式。Agent不仅能使用工具，与之前所有的模式最大的差别在于，它具有规划的能力。Agent能拆解任务，并逐步执行，在每一步都选择合适的工具来完成任务。这让它最终产出的代码质量有了极大的提升。</p><p>那么，我们不妨把视角从AI Coding这赛道中抽离出来。当我们提供更加丰富的工具，打通了LLM访问其他业务数据的渠道，这种Agent的能力，是否会泛化到各行各业的工作中去呢？</p><p>我不好说，但唯一能确定的就是：</p><p><strong>后面可用的AI应用，只会是Agent，也只能是Agent</strong>。</p><h2 id="题外话">题外话</h2><p>纵观AI Coding的发展过程，最关键的是基础模型的进步。</p><p>这个进步方向有三个：</p><p>1、模型代码能力的进步。这决定了模型生成的代码是否可用，是否有错误。在最开始我使用Claude 3.5时，它生成的代码还常常有语法错误，需要反复修改。而到Claude 4.0之后，则很少出现这种语法错误了。</p><p>2、模型的任务规划能力和工具调用能力进步。这些是Agent使用工具的前置条件，Cline使用复杂的提示词也能做到类似的工具调用和规划能力，但是终究效果不及从模型训练时就添加相关训练数据来得好。</p><p>3、模型的上下文长度。这个在编码中意外地重要。代码文件是个很耗费token的玩意儿，上下文越长，越能记住有用的信息。128k的长度在现在已经很常见了，但128k的上下文在使用效果上还是有些落后。目前先进的模型上下文直接到256K，甚至是1M，这让模型能直接阅读完仓库内的所有文件，甚至比业务开发更了解业务代码。另外，多轮对话的过程中会有很多工具调用等，也会大量占用上下文窗口。就我使用下来，64K的上下文目前几乎是不可用的状态。</p><p>提到上下文，就还得提个上下文工程的概念。模型的上下文是有限的，并且不可能无限增长。目前我们给LLM提供了工具调用的能力，LLM能主动去获取外界的信息了。但是我们还是缺少控制上下文内容的能力，很多时候LLM在工具调用过程中浪费了不少上下文。</p><p>在Vibe Coding的过程中，我绝大多数时间是在与GLM 4.5这短小的128K上下文做斗争。</p><p>另外说一句，在上下文超过长度的50%时，大多数模型的输出效果会显著变差，目前用下来仅有Claude是还能正常遵循规则进行工具调用的，不知道是不是因为Anthropic专门把Claude Code的api拿去训练了。</p><p>也提一嘴百度。</p><p>AI Coding的模型中我唯独没用百度的模型，一方面是在LLM这个赛道上，Qwen真的是一路领先…另一方面还是百度有点烂泥扶不上墙。</p><p>大家总说百度起个大早赶个晚集，没想到在LLM居然也是一样的结果。GPT 3.5刚发布时，百度率先推出文心一言，大约有GPT 3.0的水平，此时国内其他厂还仅有GPT 2.5的水平。结果3年过去了，Qwen、deepseek、Kimi、智谱清言都有开源的优秀模型推出，反而是百度渐渐淡出了大家的视野。明明最早提出All in AI的也是百度，咋最后就又竞争不过了呢。</p><p>顺便一提，Agent是下一个风口这话我也是最早从Robin嘴里听到的，某种意义上百度还真是行业明灯啊。方向永远是对的，执行结果总是错的，也是没谁了。</p>]]></content>
    
    
    <summary type="html">截止目前2025年8月，体验了市面上比较火的一些AI Coding工具，写写自己的感受。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="AI Coding" scheme="https://tulancn.github.io/tags/AI-Coding/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB速览</title>
    <link href="https://tulancn.github.io/2025/06/25/study/MongoDB%E9%80%9F%E8%A7%88/"/>
    <id>https://tulancn.github.io/2025/06/25/study/MongoDB%E9%80%9F%E8%A7%88/</id>
    <published>2025-06-25T01:29:45.000Z</published>
    <updated>2025-07-04T02:40:21.011Z</updated>
    
    <content type="html"><![CDATA[<p>MongoDB是一个NoSQL数据库，并非如同传统数据库一样使用结构化的表来存储数据，在性能上有一定优势。</p><h2 id="存储格式">存储格式</h2><p>MongoDB 采用数据库（Database）、集合（Collection）和文档（Document）的三层结构：</p><ul><li><strong>数据库（Database）</strong>：多个集合的逻辑分组，每个数据库有独立的权限控制和物理文件。</li><li><strong>集合（Collection）</strong>：一组相关文档的集合，类似关系型数据库中的表，但集合内文档可具有不同结构。</li><li><strong>文档（Document）</strong>：数据的基本存储单位，由键值对组成，类似 JSON 对象，但支持更多数据类型（如日期、二进制数据）。</li></ul><p>用MySQL中的概念来对应：</p><table><thead><tr><th>MySQL</th><th>MongoDB</th></tr></thead><tbody><tr><td>Schema（库）</td><td>Database</td></tr><tr><td>Table（表）</td><td>Collection</td></tr><tr><td>Record（行）</td><td>Document</td></tr></tbody></table><p>与关系型数据库结构化的数据不同，MongoDB中的Document是一种更加灵活的结构，类似JSON。</p><ul><li><strong>数据模型</strong>：以 BSON 文档形式存储半结构化 / 非结构化数据，支持嵌套字段（如对话中的消息列表、用户元数据），模式灵活（无需预定义表结构）。</li><li><strong>存储优势</strong>：适合存储格式多变的聊天记录（如文本、多媒体附件、JSON 格式的对话元数据），支持高效的文档级读写。</li><li><strong>典型场景</strong>：存储用户对话的原始数据，如<code>&#123;user_id: &quot;u123&quot;, messages: [&#123;role: &quot;user&quot;, content: &quot;...&quot;, timestamp: ...&#125;, ...]&#125;</code>。</li></ul><h2 id="查询">查询</h2><p>MongoDB允许用户创建过滤器（Filter）进行查询，更新和删除。支持等于、小于、包含等运算符。</p><ul><li><strong>基础查询</strong>：支持丰富的文档查询（如按用户 ID、时间范围、消息类型过滤），内置<code>$text</code>索引支持简单文本搜索，但分词能力较弱（需配合第三方插件如 MongoDB Atlas Search）。</li><li><strong>复杂查询</strong>：聚合管道（<code>$lookup</code>、<code>$match</code>等）适合统计分析（如用户对话频次、消息长度分布），但全文搜索性能不如专业搜索引擎。</li></ul><p>示例代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建MongoDB客户端连接</span></span><br><span class="line">mongoClient = MongoClients.create(CONNECTION_STRING);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取数据库（如果不存在会自动创建）</span></span><br><span class="line"><span class="type">MongoDatabase</span> <span class="variable">database</span> <span class="operator">=</span> mongoClient.getDatabase(DATABASE_NAME);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取集合（如果不存在会自动创建）</span></span><br><span class="line">MongoCollection&lt;Document&gt; collection = database.getCollection(COLLECTION_NAME);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询所有文档</span></span><br><span class="line">System.out.println(<span class="string">&quot;所有用户:&quot;</span>);</span><br><span class="line"><span class="keyword">try</span> (MongoCursor&lt;Document&gt; cursor = collection.find().iterator()) &#123;</span><br><span class="line">    <span class="keyword">while</span> (cursor.hasNext()) &#123;</span><br><span class="line">        <span class="type">Document</span> <span class="variable">doc</span> <span class="operator">=</span> cursor.next();</span><br><span class="line">        System.out.println(<span class="string">&quot;  &quot;</span> + doc.toJson());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 条件查询</span></span><br><span class="line">System.out.println(<span class="string">&quot;\n年龄大于27的用户:&quot;</span>);</span><br><span class="line"><span class="keyword">for</span> (Document doc : collection.find(<span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;age&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$gt&quot;</span>, <span class="number">27</span>)))) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;  姓名: &quot;</span> + doc.getString(<span class="string">&quot;name&quot;</span>) + </span><br><span class="line">                     <span class="string">&quot;, 年龄: &quot;</span> + doc.getInteger(<span class="string">&quot;age&quot;</span>) + </span><br><span class="line">                     <span class="string">&quot;, 城市: &quot;</span> + doc.getString(<span class="string">&quot;city&quot;</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询单个文档</span></span><br><span class="line"><span class="type">Document</span> <span class="variable">user</span> <span class="operator">=</span> collection.find(<span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;张三&quot;</span>)).first();</span><br><span class="line"><span class="keyword">if</span> (user != <span class="literal">null</span>) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;\n找到用户张三: &quot;</span> + user.toJson());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 统计文档数量</span></span><br><span class="line"><span class="type">long</span> <span class="variable">count</span> <span class="operator">=</span> collection.countDocuments();</span><br></pre></td></tr></table></figure><h2 id="更新">更新</h2><p>MongoDB提供了<code>$push</code>操作符，可以直接在数组的末尾追加新的内容。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 更新单个文档</span></span><br><span class="line"><span class="type">Document</span> <span class="variable">filter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;张三&quot;</span>);</span><br><span class="line"><span class="type">Document</span> <span class="variable">update</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$set&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;age&quot;</span>, <span class="number">26</span>).append(<span class="string">&quot;email&quot;</span>, <span class="string">&quot;zhangsan_new@example.com&quot;</span>));</span><br><span class="line">collection.updateOne(filter, update);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 更新多个文档</span></span><br><span class="line"><span class="type">Document</span> <span class="variable">multiFilter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;age&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$gte&quot;</span>, <span class="number">30</span>));</span><br><span class="line"><span class="type">Document</span> <span class="variable">multiUpdate</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;$set&quot;</span>, <span class="keyword">new</span> <span class="title class_">Document</span>(<span class="string">&quot;status&quot;</span>, <span class="string">&quot;高级用户&quot;</span>));</span><br><span class="line"><span class="type">long</span> <span class="variable">modifiedCount</span> <span class="operator">=</span> collection.updateMany(multiFilter, multiUpdate).getModifiedCount();</span><br></pre></td></tr></table></figure><h2 id="安装">安装</h2><p>MongoDB有官方提供的云服务Atlas，除此之外还有社区版本可自行安装在本地环境中。</p><h2 id="分片与高可用">分片与高可用</h2><p>MongoDB可设置分片键，集群模式下可分片存储数据。支持高可用，可添加分片的副本，分片自动进行主从复制。新增分片时可自动迁移数据。</p><h2 id="其他关注点">其他关注点</h2><p>MongoDB并非强一致性数据库，集群模式仅保证最终一致性。主从间数据同步可能有延迟。</p><p>MongoDB在单表查询上基本可以做到与关系型数据库的功能完全一致，但它不提供连表查询的能力。</p><p>MongoDB的没有事务的概念，但提供了乐观锁和表锁来做并发控制。</p><h2 id="自测结果">自测结果</h2><p>测试使用JMH。连接本地的MongoDB，无网络开销。</p><p>创建10000条数据，进行各类操作的压测。测试条件与实际环境的差异较大，仅用于比较MongoDB中各类操作的相对速度差异。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Benchmark                                          Mode  Cnt      Score       Error  Units</span><br><span class="line">MongoDBBenchmark.aggregateConversationPatterns    thrpt    3    01.234 ±    37.890  ops/s</span><br><span class="line">MongoDBBenchmark.aggregateUserStats               thrpt    3   1406.205 ±   212.137  ops/s</span><br><span class="line">MongoDBBenchmark.findByComplexQuery               thrpt    3   2480.271 ±   752.953  ops/s</span><br><span class="line">MongoDBBenchmark.findById                         thrpt    3  19871.945 ±   745.196  ops/s</span><br><span class="line">MongoDBBenchmark.findByUserId                     thrpt    3   7179.610 ±   322.021  ops/s</span><br><span class="line">MongoDBBenchmark.findConversationsWithKeyword     thrpt    3  10134.823 ±  1724.197  ops/s</span><br><span class="line">MongoDBBenchmark.insertSingleMemory               thrpt    3  21558.957 ±  1471.634  ops/s</span><br><span class="line">MongoDBBenchmark.pullConversationTurn             thrpt    3  18906.034 ±  1834.565  ops/s</span><br><span class="line">MongoDBBenchmark.pushMultipleConversationTurns    thrpt    3   3232.437 ± 21046.933  ops/s</span><br><span class="line">MongoDBBenchmark.pushNewConversationTurn          thrpt    3   6643.531 ± 21310.978  ops/s</span><br><span class="line">MongoDBBenchmark.updateMemoryMetadata             thrpt    3  19002.191 ±  1145.903  ops/s</span><br><span class="line">MongoDBBenchmark.updateMultipleMemoriesBySession  thrpt    3   6960.245 ±  1844.975  ops/s</span><br></pre></td></tr></table></figure><p>聚合查询对话中的关键词的效率较低，仅211 ops/s。</p><p>其他操作大多使用主键进行更新、查询和删除，效率较高。</p><p>测试过程中push操作的几次迭代的ops分别为10000，8000, 6000，4000。</p><p>可见push随着操作次数的增多，性能逐渐下降，<strong>push操作变为瓶颈</strong>，在测试结果中体现为误差较大。</p><p>MongoDB在5.0之后提供了<strong>Time Series Collection</strong>，但需要集群模式下才能使用，目前无法进一步验证。</p><p>本地demo测试的结果有失真，但测试过程中确实不再观察到性能逐渐下降的情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Benchmark                                                    Mode  Cnt      Score      Error  Units</span><br><span class="line">MongoDBTimeSeriesBenchmark.aggregateConversationsByHourTS   thrpt    3    437.986 ±   32.994  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.aggregateUserActivityTS          thrpt    3     84.750 ±    7.145  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.batchInsertConversationsTS       thrpt    3    500.700 ±  867.575  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.findByTimeRangeTS                thrpt    3    317.839 ±  454.249  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.findConversationsByMemoryIdTS    thrpt    3   4928.739 ± 1019.191  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.insertSingleConversationRegular  thrpt    3  23881.689 ± 3528.365  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.insertSingleConversationTS       thrpt    3   6425.600 ± 4511.080  ops/s</span><br><span class="line">MongoDBTimeSeriesBenchmark.simulatedPushOperationRegular    thrpt    3  23796.839 ± 1890.437  ops/s</span><br></pre></td></tr></table></figure><h2 id="集群部署">集群部署</h2><p>官方部署文档：<a href="https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-shard-cluster/#std-label-sharding-procedure-setup">https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-shard-cluster/#std-label-sharding-procedure-setup</a></p><p>身份验证文档：<a href="https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-sharded-cluster-with-keyfile-access-control/">https://www.mongodb.com/zh-cn/docs/manual/tutorial/deploy-sharded-cluster-with-keyfile-access-control/</a></p><h3 id="部署说明">部署说明</h3><p>本次选用Mongodb的分片部署，使用密钥文件进行身份验证。</p><p>MongoDB的分片集群有三类子集群：Shard、Mongos、Config。</p><p>这三个程序其实都是MongoDB，只不过是以不同的模式启动。</p><img src="/2025/06/25/study/MongoDB%E9%80%9F%E8%A7%88/image-20250704104015740.png" class="" title="image-20250704104015740"><h4 id="Shard分片">Shard分片</h4><p>Shard为分片集群，存储实际的数据。</p><p>每个分片都需要做主备，组成副本集，主备节点间数据相同。</p><p>假设有两个分片，每个分片有一主两备，则最后共计有6个分片的实例。</p><p>开发测试环境可使用单个实例组成副本集。</p><h4 id="Mongos路由节点">Mongos路由节点</h4><p>Mongos为路由节点。</p><p>所有操作都打到Mongos节点，Mongos负责转发请求至对应的分片节点查询数据。</p><p>Mongos没有主备的概念，可随意添加或删除。</p><h4 id="Config配置节点">Config配置节点</h4><p>Config为配置节点，用于对Mongos节点间同步路由信息，需要做主备。</p><p>开发测试环境可使用单个节点。</p><h3 id="安装Docker">安装Docker</h3><p>本文档中使用Docker安装MongoDB的各个实例，这里对Docker的安装不多赘述。</p><h3 id="密钥生成">密钥生成</h3><p>生成一次，在同个集群内共用，复制后要继续设置文件的权限，太开放了也会导致起不来。</p><p>生成密钥的命令，并修改其权限，其中<code>/opt/mongo-keyfile</code>为文件路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">openssl rand -base64 756 &gt; /opt/mongo-keyfile</span><br><span class="line"></span><br><span class="line">chmod 400 /opt/mongo-keyfile</span><br><span class="line">chown 101:101 /opt/mongo-keyfile</span><br></pre></td></tr></table></figure><p>复制到其他服务器后，设置文件权限，命令同上：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 400 /opt/mongo-keyfile</span><br><span class="line">chown 101:101 /opt/mongo-keyfile</span><br></pre></td></tr></table></figure><h3 id="系统参数设置">系统参数设置</h3><p>启用 THP（主机）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo “always” | sudo tee /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo &quot;defer+madvise&quot; | sudo tee /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure><p>设置 khugepaged 参数（主机）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 0 | sudo tee /sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none</span><br></pre></td></tr></table></figure><p>持久化配置（主机）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo tee /etc/rc.local &lt;&lt; EOF</span><br><span class="line">#!/bin/sh -e</span><br><span class="line">echo &quot;defer+madvise&quot; &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo 0 &gt; /sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>输入EOF退出。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod +x /etc/rc.local</span><br></pre></td></tr></table></figure><p>永久修改max_map_count</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;vm.max_map_count=1677720&quot; | sudo tee /etc/sysctl.d/99-mongodb.conf</span><br></pre></td></tr></table></figure><p>应用配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure><h3 id="启动config">启动config</h3><p>创建docker卷用于持久化mongodb的数据。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume create mongodb-data</span><br></pre></td></tr></table></figure><p>放置密钥文件后，使用docker命令将其映射至镜像内部，并在启动命令上使用该密钥。启动命令为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">docker run --name mongodb-config-1 \</span><br><span class="line">-p 26000:27019 -v mongodb-data:/data/db \</span><br><span class="line">-v /opt/mongo-keyfile:/data/keyfile \</span><br><span class="line">-d mongodb/mongodb-community-server:latest \</span><br><span class="line">--keyFile /data/keyfile \</span><br><span class="line">--configsvr \</span><br><span class="line">--replSet configReplSet \</span><br><span class="line">--bind_ip 0.0.0.0</span><br></pre></td></tr></table></figure><p>其中 <code>/opt/mongo-keyfile</code>为宿主机的密钥文件路径，<code>--configsvr</code>是以config节点的模式启动MongoDB。</p><p>如果有多个config实例，则先启动多个实例后再进入下一步。</p><p>部署其他实例先也要调整系统参数和复制密钥文件，并且要修改密钥文件的权限，否则会启动失败。</p><p>注意，多个实例的<code>--replSet configReplSet</code>必须相同，密钥文件必须相同，否则在下一步初始化时会出错。</p><h3 id="初始化config">初始化config</h3><p>进入其中一个config实例的镜像内部，开始后续操作：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it mongodb-config-1 bash</span><br></pre></td></tr></table></figure><p>使用mongosh连接启动的MongoDB：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongosh --host localhost --port 27019</span><br></pre></td></tr></table></figure><p>连接后，输入以下命令组成config副本集，保证最外层的<code>_id</code>与启动命令中的<code>--replSet</code>对应：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id: &quot;configReplSet&quot;,</span><br><span class="line">  configsvr: true,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.31:26000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>假设有多个config实例，则在以上命令中的members数组内加入其他的config节点信息。示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id: &quot;configReplSet&quot;,</span><br><span class="line">  configsvr: true,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.31:26000&quot; &#125;,</span><br><span class="line">   &#123; _id : 1, host : &quot;192.168.0.32:26000&quot; &#125;,</span><br><span class="line">   &#123; _id : 2, host : &quot;192.168.0.33:26000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>以上的初始化命令仅需要在某个实例执行一次即可，不需要在所有config实例上都执行一遍。</p><p>举例，有三个Config实例C1、C2、C3，则仅需要在C1上进行一次初始化即可。</p><h3 id="创建管理员">创建管理员</h3><p>继续在mongosh界面操作，创建config集群的管理员账户。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">admin = db.getSiblingDB(&quot;admin&quot;)</span><br><span class="line">admin.createUser(</span><br><span class="line"> &#123;</span><br><span class="line">    user: &quot;mongoadmin&quot;,</span><br><span class="line">    pwd: &quot;@Scg0830&quot;, </span><br><span class="line">    roles: [ </span><br><span class="line">    &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,</span><br><span class="line">    &#123; role: &#x27;readWriteAnyDatabase&#x27;, db: &#x27;admin&#x27; &#125;,</span><br><span class="line">    &#123; &quot;role&quot; : &quot;clusterAdmin&quot;, &quot;db&quot; : &quot;admin&quot; &#125;,</span><br><span class="line">      ]</span><br><span class="line">  &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>后续连接时都需要验证用户名和密码，命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongosh -u mongoadmin -p @Scg0830 --authenticationDatabase &quot;admin&quot; --port 27019</span><br></pre></td></tr></table></figure><h3 id="启动分片">启动分片</h3><p>先在分片节点上调整系统参数和放置密钥文件，然后再进行后续操作。</p><p>创建docker卷：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume create mongodb-data</span><br></pre></td></tr></table></figure><p>启动命令，与config的启动命令类似：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">docker run --name mongodb-shard-1 \</span><br><span class="line">-p 28000:27018 -v mongodb-data:/data/db \</span><br><span class="line">-v /opt/mongo-keyfile:/data/keyfile \</span><br><span class="line">-d mongodb/mongodb-community-server:latest \</span><br><span class="line">--keyFile /data/keyfile \</span><br><span class="line">--shardsvr \</span><br><span class="line">--replSet shardReplSet1 \</span><br><span class="line">--bind_ip 0.0.0.0</span><br></pre></td></tr></table></figure><p>如果要启动同个分片的副本（备份），要保证启动命令中的<code>--replSet</code>相同，同个分片的多个副本使用相同的副本集名称。</p><p>如果要启动多个分片，修改启动命令中的<code>--replSet</code>，当前的副本集名称为shardReplSet1，可以修改为shardReplSet2或其他的名称。</p><p>每个分片实例启动前务必修改系统参数和复制密钥文件，并修改密钥文件的权限，否则无法启动。</p><h3 id="初始化分片">初始化分片</h3><p>对于每一个分片的副本集，都需要初始化，以便让所有的副本集能互相建立连接。</p><p>首先进入其中一个实例的docker内部：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it mongodb-shard-1 bash</span><br></pre></td></tr></table></figure><p>启动mongosh，连接镜像内的分片实例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongosh --port 27018</span><br></pre></td></tr></table></figure><p>输入以下命令初始化，保证最外层的<code>_id</code>与启动命令中的<code>--replSet</code>对应：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id : &quot;shardReplSet&quot;,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.85:28000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>如果有多个副本，则在members中添加其他的副本。示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">rs.initiate(</span><br><span class="line"> &#123;</span><br><span class="line">  _id : &quot;shardReplSet&quot;,</span><br><span class="line">  members: [</span><br><span class="line">   &#123; _id : 0, host : &quot;192.168.0.85:28000&quot; &#125;,</span><br><span class="line">   &#123; _id : 1, host : &quot;192.168.0.86:28000&quot; &#125;,</span><br><span class="line">   &#123; _id : 2, host : &quot;192.168.0.87:28000&quot; &#125;</span><br><span class="line">  ]</span><br><span class="line"> &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>注意，同一个分片的副本集，仅需要初始化一次。</p><p>不同分片则需要每个分片都初始化一次。</p><p>举例，有两个分片A和B，每个分片内有三个副本（A1、A2、A3、B1、B2、B3）组成副本集。则在A1上对A1、A2、A3进行初始化，在B1上对B1、B2、B3进行初始化。</p><h3 id="安装mongos">安装mongos</h3><p>使用yum安装mongos。</p><p>先添加仓库，创建文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch /etc/yum.repos.d/mongodb-org-8.0.repo</span><br></pre></td></tr></table></figure><p>然后在文件中添加以下内容并保存。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[mongodb-org-8.0]</span><br><span class="line">name=MongoDB Repository</span><br><span class="line">baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/8.0/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://www.mongodb.org/static/pgp/server-8.0.asc</span><br></pre></td></tr></table></figure><p>使用yum安装：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y mongodb-org-mongos</span><br></pre></td></tr></table></figure><h3 id="启动mongos">启动mongos</h3><p>先创建日志文件夹：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /var/log</span><br><span class="line">mkdir /var/log/mongodb</span><br></pre></td></tr></table></figure><p>复制密钥文件，并设置文件的权限，然后启动mongos：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongos --keyFile /opt/mongo-keyfile --configdb configReplSet/192.168.0.31:26000 --bind_ip 0.0.0.0 --logpath &quot;/var/log/mongodb/mongos.log&quot; --fork --port 27000</span><br></pre></td></tr></table></figure><p>注意，启动命令中会连接config集群，必须保证<code>--configdb</code>与config节点的副本集名称相同，IP一致。</p><h3 id="添加分片">添加分片</h3><p>如果本机没有mongosh，则先安装：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y mongodb-mongosh</span><br></pre></td></tr></table></figure><p>使用分片管理员的角色登录mongos，账号密码与在config集群上创建的一致。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongosh -u mongoadmin -p @Scg0830 --authenticationDatabase &quot;admin&quot; --port 27000</span><br></pre></td></tr></table></figure><p>添加分片：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh.addShard( &quot;shardReplSet/192.168.0.85:28000&quot;)</span><br></pre></td></tr></table></figure><p>分片有多个副本，则使用逗号分隔：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh.addShard( &quot;shardReplSet/192.168.0.85:28000,192.168.0.86:28000,192.168.0.87:28000&quot;)</span><br></pre></td></tr></table></figure><p>重复以上步骤把所有的分片都添加至mongos。</p><p>以上的分片信息会传至config节点并同步到所有的mongos中，后续有新的mongos加入也不需要重新添加分片信息。</p>]]></content>
    
    
    <summary type="html">新工作需要预研MongoDB，快速记录下了解到的信息。</summary>
    
    
    
    <category term="工作、生活、学习、其他" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C%E3%80%81%E7%94%9F%E6%B4%BB%E3%80%81%E5%AD%A6%E4%B9%A0%E3%80%81%E5%85%B6%E4%BB%96/"/>
    
    
    <category term="技术协议" scheme="https://tulancn.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>关于时代与我的碎碎念</title>
    <link href="https://tulancn.github.io/2025/05/20/life/%E5%85%B3%E4%BA%8E%E6%97%B6%E4%BB%A3%E4%B8%8E%E6%88%91%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
    <id>https://tulancn.github.io/2025/05/20/life/%E5%85%B3%E4%BA%8E%E6%97%B6%E4%BB%A3%E4%B8%8E%E6%88%91%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/</id>
    <published>2025-05-20T00:17:09.000Z</published>
    <updated>2025-09-27T02:42:38.748Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>[!WARNING]</p><p>2025年9月27日留：</p><p>过了4个月，回看这篇博客真的是无地自容，青春伤痛文学的人格居然闪回了。特意留着警醒自己，要脚踏实地，做实在事正确事。</p></blockquote><h2 id="从人力车到马车">从人力车到马车</h2><p>在技术这块，近两年最火的议题只有一个：AI。</p><p>围绕着新的风口，诸多需求、诸多岗位涌现，更别说国内有自上而下的命令下来，让所有的干部都学习以deepseek为代表的大语言模型。2025年春节，我回家的时候，感觉最奇怪的一点就是，公园里路边的大爷都能和你聊几句deepseek。我老爸也问我deepseek怎么装到手机上。信息的传播速度在国内展现出一种很独特的曲线。一开始没有人注意，当某个事件导致某个东西爆火后，会在一到两天内传到大部分人耳中。这或许就是自媒体时代的魅力。</p><p>AI并不是新东西，但AI真正让人感觉到有质变的点，就在ChatGPT-3.5上线之后。大约2022年末，ChatGPT出现，一开始大家只是当做一个AI聊天的游戏，并没有完全发掘其潜力。大部分人对其的评价是幻觉过于严重，胡编乱造的情况太多了。</p><p>而我个人认为第一个质变的点，是有人发现可以用类似讲故事的形式，让GPT来主动要求获取什么信息，这时候最初级的Function Call就出现了。</p><p>比如这样的一个对话：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">人：我这里有个工具能查询火星的天气。当有人问火星的天气怎么样，你应该用这个工具来获取信息，然后回答。使用工具的方式是回复：func call marsweather。如果你知道了，请回答好的。</span><br><span class="line">AI：好的。</span><br><span class="line">人：火星现在是什么天气？</span><br><span class="line">AI：func call marsweather</span><br><span class="line">人：下雨</span><br><span class="line">AI：目前火星的天气是雨天</span><br></pre></td></tr></table></figure><p>AI会自动通过上下文判断缺少什么数据，会主动要求获取什么信息，这是LLM表现出的一个特殊能力。</p><p>随后我们包装了Function Call的能力，后面甚至发展出了更多的实践标准，比如MCP。这大大增强了AI的能力边界。</p><p>第二个质变的点是RAG。有个黄金8000字法则，LLM对于最近的8000字记忆相对深刻，大部分时候会严格按照这8000字的要求来回答。</p><p>所以假设我们在这8000字中输入一些有时效性的信息，或是一些对回答有用的知识，可以让LLM在输出结果时大大增强准确性。举个例子，就是从闭卷考试变成了开卷考试。</p><p>RAG全名是检索增强生成。</p><p>首先是检索，我们的知识库很大，上下文很长，因此得先寻找和用户的提问最相关的内容。就像开卷考试我们看着题目去目录里找相关的页码。</p><p>在检索这一步，可以利用各种NLP的技术来确定文本的相关性。这里还有召回率等指标用于测试检索方法的准确性。</p><p>再深入一点说，这里的检索还有很多东西，比如可以提供用户的个人信息来增强生成结果的个性化能力；可以优化embadding模型来提高分片逻辑；生成知识图谱等；</p><p>但无论如何，检索的目标只有一个，就是找到相关的文本片段，然后一并提供给LLM。</p><p>LLM生成结果的这一步，可以理解为人脑思考、推理的过程，我们提供相关性更强的上下文，以提高结果的准确性或是质量。</p><p>大模型的幻觉问题，在目前RAG的机制下，已经很少了。目前更多的问题是原始的数据，也就是提供的文本片段可能是错误的虚假的。</p><p>在AI越发强大的情况，已经有相当一部分的工作可以被AI取代了。</p><p>程序员是脑力劳动的职业，但<strong>实际工作中的生产力会被限制在过时的人机交互技术</strong>上。编码是个体力活，设计画图也是，人总是一下子就能想到结果，但最麻烦的却是把想法变成现实。</p><p>以前有IDE，有提示补全，能减少一部分编码的重复工作，但依旧不够。</p><p>如今的AI开发工具，人需要手动说出自己的需求，AI会自动进行实现和编码。人在AI产出的基础上进行进一步提示或手动改写。</p><p>这确实相当程度上减少了编码的重复工作，在AI生成的结果有质量保证时，很多时候就是说需求然后tabtab或是点击接受。</p><p>很多人喜欢用马车和汽车的比喻来形容新事物产生时对生产力发展的影响。</p><p>但我觉得目前LLM对编程的影响还没到马车和汽车这级别，更像是人力车到马车。</p><p>以前程序员需要手敲代码，手动debug査资料。随着工作的进行，编码能力会自然提高。</p><p>就像种地的人，身体也会被锻炼到。</p><p>但到了LLM时代，手敲代码的机会逐渐减少，更多的时候程序员只是充当了LLM的一个助手。大部分工作是复制粘贴代码和错误信息，来回切换IDE和LLM的对话界面。</p><p>就像马车的车夫，重点在于怎么驾驭马，而不是拉车本身了。</p><p>随着工作的进行，程序员本身的能力成长相当有限。</p><p>此时，还想提升编码能力，可能就得专门锻炼了。就像不种地以后，想锻炼身体就得去健身房；程序员的工作有大量被LLM覆盖后，想提高编码能力也得专门锻炼。</p><p>为了适应这种从人力车到马车的变化，我也得转变观念了吧。</p><h2 id="未来是一片迷茫">未来是一片迷茫</h2><p>我看不到两年之后的事情。</p><p>这是我最近的一个想法。大到国际局势，小到身边的就业，我朋友的境况。这些事情中我能看到的最远的，也仅有两个月。</p><p>不知道什么时候就失去了长期规划。</p><p>实际上在刚毕业的时候还是很自信的，觉得自己可以在就业的前10年完成学历的提升，把工作换到老家，找一个女友，定居在大城市。</p><p>5年一过，这些都已经完成，但我却不知道下一步会是什么？</p><p>技术的潮流并没褪去，每年都有新的技术热点出现，大家不知道明年会不会出现什么新东西。大多团队年初的计划撑不过一个季度就直接推翻重来。</p><p>政治上，美国成了国际局势的搅屎棍，世界各地的摩擦走火也时有发生。俄乌的仗打了好些年，大家都想着会不会继续扩大化。</p><p>可能两年内台湾就收复了，可能接着中美竞争白热化，可能明天的黄金还会继续走高。</p><p>不管怎么说，这几年都是无法稳定的，迷茫才是常态。</p><p>而我能做的，就是相信自己的判断，一条道走到黑吧。</p>]]></content>
    
    
    <summary type="html">到云南的第一天，在民宿写下这篇博客，记录一些杂碎的想法。</summary>
    
    
    
    <category term="生活" scheme="https://tulancn.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="技术协议" scheme="https://tulancn.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>kafka文档阅读笔记</title>
    <link href="https://tulancn.github.io/2025/04/15/study/kafka%E6%96%87%E6%A1%A3%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>https://tulancn.github.io/2025/04/15/study/kafka%E6%96%87%E6%A1%A3%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2025-04-15T05:32:01.000Z</published>
    <updated>2025-04-20T06:05:21.758Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介">简介</h2><p>提到Kafka，第一印象是其中心化的设计，可靠的持久化和良好的生态。</p><p>最早Kafka设计是个日志系统。各个系统把日志发送到Kafka，然后被其他系统消费，进行后续处理。</p><p>最新的文档中，Kafka提到是event stream（事件流）平台。</p><blockquote><p>从技术角度讲，事件流是从数据库、传感器、移动设备、云服务和软件应用等事件源实时捕获数据，以事件流的形式存储这些事件流以供后续检索；实时以及事后处理和响应事件流；根据需要将事件流路由到不同的目标技术。因此，事件流确保了数据的持续流动和解释，以便在正确的时间、正确的地点提供正确的信息。</p></blockquote><p>Kafka的核心能力有三点：</p><ol><li><p>发布（写入）和订阅（读取）事件流，包括从其他系统持续导入/导出数据。</p></li><li><p>可靠地存储事件流，并持久化，满足对数据存储时间的需求。</p></li><li><p>处理实时或回顾性的事件流。</p></li></ol><p>这些在分布式系统中非常有用。</p><p>一个常见的场景是，一个系统只需要生成数据并把数据提交给Kafka即可，其他的系统则消费这些数据，进行其他的处理。</p><p>这是个典型的事件驱动架构，各个系统通过Kafka实现了良好的解耦。</p><h2 id="核心实现">核心实现</h2><p>Kafka有server和client之分，是由server与client组成的分布式系统。</p><p>server与client之间通讯使用TCP协议。</p><p>server就是Kafka节点，client则是业务节点。</p><p>server可以由多个节点组成集群，这个集群可以横跨多个机器、机房。</p><p>server中又分为broker和connect：</p><ul><li>broker：kafka的持久化节点，数据存到文件中。</li><li>connect：kafka的数据节点，类似client，会持续地生产数据或消费数据。算是Kafka生态的一部分。</li></ul><p>client可以往kafka提交或接收数据，或者说发布和订阅事件流。client有多种语言的SDK，允许集成到业务系统中。</p><h2 id="核心概念">核心概念</h2><h3 id="Event-事件">Event 事件</h3><p>或者说消息。事件有一个键、值、时间戳和可选的元数据头。</p><p>以下是一个示例事件：</p><ul><li>Event key: “Alice”</li><li>Event value: “Made a payment of $200 to Bob”</li><li>Event timestamp: “Jun. 25, 2020 at 2:06 p.m.”</li></ul><p>在消息队列中，所有的消息都被视为一个事件。</p><h3 id="Producer-和-Consumer">Producer 和 Consumer</h3><p>向Kafka发布事件的客户端被称为生产者。<strong>Producer</strong></p><p>从Kafka订阅事件，接收事件进行处理的客户端被称为消费者。<strong>Consumer</strong></p><p>在Kafka中，生产者和消费者完全解耦，互相之间没有任何依赖。</p><h3 id="Topic-主题">Topic 主题</h3><p>Event事件会被划分到一个Topic之下。类比文件系统，Topic类似文件夹，而Event则是文件夹中的文件。</p><p>对于一个主题，可以有任意个生产者写入事件，也可以有任意个消费者消费事件。</p><p>注意，这里的任意可以是0。因为Kafka会持久化消息到文件系统中，因此即便没有消费者来消费数据，生产者也可以无限地往Kafka推送数据，而不会产生数据背压。</p><p>这里还有一点要说明，消费者消费Kafka主题中的事件后，事件不会被删除。</p><p>Kafka提供了事件过期事件的配置，能控制事件的删除时机。</p><p>最后还有一点，Kafka的性能与数据大小无关。</p><h3 id="Partition-分区">Partition 分区</h3><p>分区的概念仅在分布式场景下会用到。分区的概念可以理解为是同一个主题下的多个消息队列。</p><p>一个主题可能消息过多，因此需要被划分到不同的分区中。同个主题的不同分区可以在不同的Kafka节点（Broker）中。</p><p>不同的Kafka节点可以存在于不同的地区、机房里。</p><p>生产者发布和消费者订阅时，是可以是直接针对主题发送的消息，也可以指定分区发送消息。</p><p>如果是针对主题发送的消息，Kafka会保证具有同样Event key的事件被划分到同一个分区中。以用户ID举例，Kafka会保证同个用户的事件始终在同个分区里，因此会一直被同样的消费者消费。这样保证了消息的局部有序性。</p><p>而通过指定分区进行消息发布和订阅，就能允许生产者和消费者并行处理同个主题下的数据。比如一个主题有2个分区，有两个消费者分别来处理分区1和分区2的数据，这样就能让消费的过程变成并行了。</p><p>此外，分区有Replica（副本），用来做容灾时很好用。</p><p>Kafka会自动把分区的数据分配到不同的Broker中，这样可以保证不同Broker都是均匀地处理数据。另外，这种设计让扩容变得简单了，当有新的Broker加入时，Kafka可以自动把部分分区迁移到新的Broker上。</p>]]></content>
    
    
    <summary type="html">这是阅读Kafka文档时记录的一些心得与关键点</summary>
    
    
    
    <category term="学习" scheme="https://tulancn.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="技术协议" scheme="https://tulancn.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>redis</title>
    <link href="https://tulancn.github.io/2025/04/08/study/redis/"/>
    <id>https://tulancn.github.io/2025/04/08/study/redis/</id>
    <published>2025-04-08T08:55:35.000Z</published>
    <updated>2025-04-08T13:05:08.598Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Redis基础概念">Redis基础概念</h2><p>Redis是一个开源的、基于内存的数据结构存储系统，常被用作数据库、缓存和消息中间件。</p><p>它支持多种数据结构，包括字符串（String）、哈希（Hash）、列表（List）、集合（Set）和有序集合（Sorted Set）等。每种数据结构都有其独特的操作命令和适用场景。</p><p>redis是个k-v数据库，在redis内部维护了一个哈希表。当有查询来的时候，会先查全局的表获取键值，然后基于键值的类型进行后续处理。</p><p>String就理解为用了一个全局的哈希表。</p><p>Hash就是在全局的哈希表中再建了一个哈希表，比如专门建立一个user表用于存用户信息。这种表查询的时候会有两次哈希，第一次是查键，第二次是查具体的表。</p><p>Set、List也是类似，这里省略了。</p><h2 id="Redis常用命令">Redis常用命令</h2><ul><li><strong>字符串操作</strong>：<code>SET</code> 用于设置键值对，<code>GET</code> 用于获取指定键的值，<code>INCR</code> 用于将键的值加 1（键值需为整数）。</li><li><strong>哈希操作</strong>：<code>HSET</code> 在哈希表中设置字段值，<code>HGET</code> 获取哈希表中指定字段的值，<code>HGETALL</code> 获取哈希表中所有字段和值。</li><li><strong>列表操作</strong>：<code>LPUSH</code> 从列表头部插入元素，<code>RPUSH</code> 从列表尾部插入元素，<code>LPOP</code> 移除并返回列表的第一个元素，<code>RPOP</code> 移除并返回列表的最后一个元素，<code>LRANGE</code> 返回列表中指定区间内的元素。</li><li><strong>集合操作</strong>：<code>SADD</code> 添加元素到集合，<code>SMEMBERS</code> 返回集合中的所有元素，<code>SISMEMBER</code> 判断元素是否存在于集合中，<code>SREM</code> 移除集合中的元素，还支持集合的交集（<code>SINTER</code>）、并集（<code>SUNION</code>）、差集（<code>SDIFF</code>）等运算。</li><li><strong>有序集合操作</strong>：<code>ZADD</code> 添加成员到有序集合并指定分数，<code>ZRANGE</code> 返回有序集合中指定区间内的成员（按分数从小到大排序），<code>ZREM</code> 移除有序集合中的成员。</li><li><strong>键操作</strong>：<code>DEL</code> 删除一个或多个键，<code>KEYS</code> 查找所有符合给定模式的键，<code>EXISTS</code> 检查给定键是否存在。</li></ul><h2 id="Redis数据结构使用">Redis数据结构使用</h2><ul><li><strong>集合（Set）</strong>：适用于去重、判断元素是否存在以及集合运算等场景，例如存储用户标签、共同好友等。使用Python的<code>redis-py</code>库操作集合时，可通过<code>sadd</code>、<code>smembers</code>等方法实现添加元素、获取所有元素等操作。</li><li><strong>列表（List）</strong>：可用于实现队列（先进先出，FIFO）、栈（先进后出，LIFO）等数据结构，如消息队列、任务队列等。使用<code>redis-py</code>库时，<code>lpush</code>、<code>rpush</code>等方法可实现列表元素的插入操作。</li></ul><h2 id="Redis本地连接方式">Redis本地连接方式</h2><p>远程连接走的TCP，这里省略。</p><ul><li><strong>TCP/IP连接</strong>：即使Redis服务器和应用程序在同一台机器上，使用TCP/IP连接时，数据会经过本地的网络协议栈，通过回环地址进行传输。在Python中，使用<code>redis-py</code>库通过TCP/IP连接本地Redis服务器时，可指定<code>host</code>和<code>port</code>参数。</li><li><strong>本地套接字（Unix Domain Socket）连接</strong>：应用程序与Redis服务器通过本地文件系统中的套接字文件进行通信，不经过网络协议栈，效率较高。在Python中，使用<code>redis-py</code>库可通过指定<code>unix_socket_path</code>参数来使用本地套接字连接Redis。</li></ul><p>本地的套接字连接还是要走网络的那一套，建立连接、监听之类的，所以性能上比JNI要低。</p><h2 id="Redis性能优化技巧">Redis性能优化技巧</h2><ul><li><strong>配置优化</strong>：合理设置<code>maxmemory</code>参数和内存淘汰策略；根据业务需求选择合适的持久化方式（RDB或AOF），并调整相关参数。</li><li><strong>数据结构优化</strong>：根据业务场景选择合适的数据结构，优化数据结构设计以减少内存占用。</li><li><strong>客户端优化</strong>：使用连接池管理客户端连接，减少网络往返次数，控制请求数据量。</li><li><strong>服务器优化</strong>：将Redis服务器运行在单核CPU上，绑定特定CPU核心；使用高性能存储设备，优化操作系统I/O调度算法。</li><li><strong>监控与优化</strong>：使用<code>INFO</code>、<code>MONITOR</code>等命令监控性能指标，分析并优化查询语句。</li></ul><h2 id="持久化">持久化</h2><p>RDB，固定时间把所有数据写入本地文件。</p><p>AOF，每次写操作都把数据写入文件。</p><p>可以使用AOF的特殊参数，来实现每隔多少时间把写操作写入文件中。</p><p>这种方式类似MySQL的binlog。</p><h2 id="Redis集群方案">Redis集群方案</h2><ul><li><strong>主从复制</strong>：主节点处理写操作并将数据异步复制到从节点，从节点处理读操作。优点是实现读操作负载均衡，提高读性能；缺点是主节点单点故障，可能存在数据丢失风险。</li><li><strong>Sentinel（哨兵）</strong>：在主从复制基础上，引入Sentinel进程监控节点状态。当主节点故障时，自动从从节点中选举新主节点。多个Sentinel节点组成集群，通过Gossip协议通信，提高监控可靠性。但配置和管理相对复杂，故障转移可能存在短暂服务中断和数据不一致情况。</li><li><strong>Redis Cluster</strong>：采用数据分片，将键空间划分为16384个哈希槽，每个节点负责一部分哈希槽。节点间通过内部二进制协议通信，使用哨兵机制进行故障检测和转移。支持水平扩展，客户端可连接任意节点，通过<code>MOVED</code>错误重定向到正确节点。</li><li><strong>Codis</strong>：由Codis Server、Codis Proxy和ZooKeeper等组件组成。Codis Server存储数据，Codis Proxy代理客户端请求，ZooKeeper存储集群配置信息。支持动态扩展和收缩集群，对客户端透明，但依赖ZooKeeper，性能可能有损耗。</li></ul><p>主从是最基础的方案，配合AOF很好理解。能在多读少写的场景实现很有效的集群。</p><p>Sentinel机制是在主从的基础上添加了高可用的机制，能在主节点故障时自动选举出新的主节点。</p><p>Redis Cluster则是数据分片存储的方案，类似分库分表，实现上也很像。</p><h2 id="相关通信协议">相关通信协议</h2><ul><li><strong>Gossip协议</strong>：是一种分布式算法，用于在节点之间传递信息。具有去中心化、简单、扩展性好、容错性强、性能高效等特点。通过节点间随机的信息交换实现最终一致性，常见的通信方式有Push、Pull、Push&amp;Pull。适用于对一致性要求不是非常严格，但对系统扩展性、容错性和性能有较高要求的场景。</li><li><strong>与其他协议对比</strong>：与Raft、Paxos、Zookeeper等协议相比，在一致性保证、性能、扩展性、故障容错性、复杂性、应用场景等方面存在差异。例如，Raft和Paxos保证强一致性，Gossip协议提供最终一致性；Zookeeper是分布式协调服务，而Gossip协议主要用于信息传播和状态同步。</li></ul><h2 id="客户端从Redis-Cluster获取数据的过程">客户端从Redis Cluster获取数据的过程</h2><p>客户端先计算键的哈希槽编号，随机连接集群中的一个节点并发送获取数据的命令。若该节点负责该哈希槽，则直接返回数据；若不负责，则返回<code>MOVED</code>错误，包含目标节点信息。客户端根据错误信息重定向到正确节点再次请求数据。</p><p>客户端可维护哈希槽到节点的映射表以减少重定向开销。</p><h2 id="Redis的单线程">Redis的单线程</h2><p>Redis是个事件驱动的架构。维护了一个事件队列，线程不断从事件队列中取出事件进行处理。</p><p>比如发送了命令，那么会自动进入事件队列，上一个事件结束时才会处理下一个事件，这样保证了事务的一致性。</p><p>那么如何保证性能？</p><p>首先大部分操作都是纯内存的操作，耗时极短，用时在纳秒和微秒级别。</p><p>最耗费时间的操作往往都是IO操作，redis使用了IO多路复用的技术。没有IO多路复用的话，收到请求时，监听线程发起进行读操作，然后会阻塞，直到IO设备把数据读取到了内存中才能进行后续处理。IO多路复用的情况下，监听线程发起读操作，然后检查是否真的能读，不能则通过epoll的机制，等待内核回调。线程就直接去找下一个可以处理的任务了。</p><p>当然4.0以后，Redis也是引入了多线程机制，可以做到异步删除和异步持久化。</p>]]></content>
    
    
    <summary type="html">工作中对redis用得不多，先标记一下。</summary>
    
    
    
    <category term="学习" scheme="https://tulancn.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="缓存" scheme="https://tulancn.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>我对MCP的理解</title>
    <link href="https://tulancn.github.io/2025/03/22/study/%E6%88%91%E5%AF%B9MCP%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>https://tulancn.github.io/2025/03/22/study/%E6%88%91%E5%AF%B9MCP%E7%9A%84%E7%90%86%E8%A7%A3/</id>
    <published>2025-03-22T13:30:56.000Z</published>
    <updated>2025-04-08T08:56:08.880Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>Model Context Portocal（MCP）真的是很火。自从这协议被提出以后，不少人觉得是一个未来的方向。</p><p>尤其是最近OpenAI也宣布要支持MCP，肉眼可见的在2025年这个协议会被人不断地提起。</p><p>2025是AI应用的大年，必然会有一批又一批的App或是软件转向拥抱AI的能力，而在这场转变中，MCP是不能绕开的一个话题。</p><h2 id="什么是MCP">什么是MCP</h2><p>在官方的介绍中，MCP被形容为大模型的type-c接口。</p><p>我觉得这概念过于抽象了，理解之后会觉得确实很有道理，但对于初学者来说这不能建立起一个直观的印象。</p><p>所以这里也想用自己的语言来组织一下我对其的理解。</p><p>目前最大的误解，就是MCP是一个标准化的Function Calling。</p><p>其实不然。</p><p>第一点，MCP是个应用层的协议，它和Function Calling完全不冲突。</p><p>第二点，函数调用是MCP中包含的能力的一部分，被称为tools。除了tools，还有其他很多功能。</p><img src="/2025/03/22/study/%E6%88%91%E5%AF%B9MCP%E7%9A%84%E7%90%86%E8%A7%A3/image-20250407162739388.png" class="" title="image-20250407162739388"><p>MCP协议还提供了prompt补全、提示词模版等能力，只不过目前客户端支持不是很到位，因此大家用的不多。</p><p>所以，为了直观理解MCP，我觉得应该先从调用方来说起。</p><p>MCP是给MCP客户端使用的，这里的MCP客户端并不等于是LLM，这点很重要。</p><p>以Claude客户端为例，我们在自己的电脑上启动Claude客户端时，客户端仅仅是提供了一个聊天界面，实际上LLM还是在云端。</p><p>这场景下，我们自己电脑上的Claude客户端是MCP Client。</p><p>假设有个工具调用触发了，我们走一下实际的调用链路。</p><p>用户在客户端询问Claude，今天XXX的天气怎么样。请求会发送到Claude的服务器，Claude判断需要调用工具来获取天气的情况，此时它会发起Function Calling，这个Calling会原路返回到我们本地的客户端。</p><p>我们的客户端上会显示一条提示信息：Claude请求调用天气查询工具，是否同意？</p><p>我们点击同意，接着我们本地的Claude客户端就会发送一个MCP调用给MCP服务器，获取到最新的天气信息，然后把这个天气信息作为一个新的请求发送给Claude。</p><p>这时候，Claude才获取到最新的天气信息，此时它会组织语言重新把结果返回给客户端。</p><p>最后我们的客户端上才会显示我们最开始问题的回复：今天XXX的天气是晴天。</p><p>显然，MCP并没有取代Function Calling。</p><h2 id="MCP的价值在哪">MCP的价值在哪</h2><p>为什么我说MCP是AI应用开发绕不过的一个协议呢。</p><p>还是以我之前写过的一个玩具项目举例，我给Qwen写过一个Function Calling。</p><p>当时需要我做什么呢？</p><p>首先，我得编写一个功能，然后作为一个开放的接口在公网暴露出来。</p><p>然后我要把这个接口通过Qwen提供的工具注册方式，把这个接口注册到Qwen里。</p><p>最后还要进行功能的调试。</p><p>整个流程下来非常繁杂，因为我作为一个开发AI应用的人，我承担了太多的责任。</p><p>比如我得负责把工具包装成接口，还得专门写一个提示词来描述这个工具。</p><p>比如我得进行功能的调试，模型的调试极其麻烦。</p><p>同时，我写好的工具，大概率以后想复用时，还得写一套代码来实现把工具传递给AI。</p><p>这还不算其中认证之类的事情，实在是过于麻烦了。</p><p>但有了MCP之后呢？</p><p>对应的功能我可以包装为MCP的Server，然后用MCP Client的SDK快速实现功能调用和传输给AI。</p><p>以后我想复用功能，我只需要继续用MCP Client的SDK写一下调用就行了，不需要再去动MCP Server的代码。</p><p>简单来说，MCP的价值就在于提供了一个良好的职责划分。</p><p>MCP Server负责提供具体的工具，同时也是Server来负责提供工具描述之类的信息。</p><p>MCP Client负责转发AI的工具调用等，同时也可以使用MCP协议提供的Sampling等能力实现一些客户端的其他功能。</p><p>LLM模型的提供商负责提供Function Calling即可。</p><p>你看，负责开发具体功能的，也负责提供了给模型的接入文档；负责开发客户端的，只需要关心怎么写胶水代码来拼凑功能。</p><p>这样就解决了AI应用最大的痛点，开发成本高昂。</p><p>有相当多的软件，也可以发布自己的MCP Server来实现无缝变身AI应用了。</p><p>试想一下，假设美团提供了MCP服务，那么是不是真的就可以做到，我们在手机的语音助手里说一句：我要点杯咖啡，然后语音助手自动帮我们利用MCP去查询美团上的信息，然后下单支付呢？</p><p>这时候回头看看官方说的那句，MCP就是type-c接口，是不是有点味道了呢？</p>]]></content>
    
    
    <summary type="html">MCP肉眼可见地火了，这次聊聊MCP。</summary>
    
    
    
    <category term="学习" scheme="https://tulancn.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="技术协议" scheme="https://tulancn.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>canvas-editor使用记录</title>
    <link href="https://tulancn.github.io/2025/03/21/work/front/canvas-editor%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/"/>
    <id>https://tulancn.github.io/2025/03/21/work/front/canvas-editor%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/</id>
    <published>2025-03-21T13:06:31.000Z</published>
    <updated>2025-04-07T09:08:07.034Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介">简介</h2><p>主页：<a href="https://hufe.club/canvas-editor-docs/">https://hufe.club/canvas-editor-docs/</a></p><p>canvas-editor是个基于canvas/svg的富文本编辑器。</p><p>使用下来，比较优秀的点有：</p><p>1、页面类似word，并且开箱即用。</p><p>2、提供了非常多扩展的接口。</p><p>3、数据保存非常方便。</p><p>当前，也有些缺点：</p><p>1、文档不够详细，很多接口仅仅是说明了有这个接口，具体的用法都没讲。</p><p>2、事件回调的机制说明不够清晰。也算是个文档的问题。</p><p>3、没有Vue或Reactor的开箱即用包。</p><h2 id="空的回调事件">空的回调事件</h2><p>在实现工具栏时，发现了一个很抽象的事情。</p><p>官方的工具栏中，假设我选中一些文字然后加粗，工具栏会正常把加粗的按钮置为已经点击的状态。</p><p>而在我实现的工具栏中，每次点击工具栏的按钮后，会出现一个空的回调事件，把工具栏的状态置回没有点击的状态。</p><p>最后询问了官方，也翻了下对方的代码。</p><p>发现是因为官方的工具栏用的事件不是click，而是鼠标按下的事件。</p><p>我用click，所以点击的时候出现了失焦，因此有个空的回调事件出来。</p><h2 id="Word插件样式">Word插件样式</h2><p>官方的实现中，word的导入导入功能有非常严重的样式丢失。</p><p>最后是我自己写了一个导入的功能，把word解析为xml然后转化为canvas-editor的json格式。</p><p>目前导出还没实现，但大概率也得手动写一个导出了。</p><h2 id="任何操作都会被记录">任何操作都会被记录</h2><p>发现对文档的操作都会被记录。</p><p>这导致了我们用AI添加一些文字内容到文档时，明明正常执行完了，但点击回退又会回到填了一半的情况。</p><p>比如我们润色时会高亮原文，那么润色完了点击回退，就会回到原文被高亮的状态。</p><p>最后发现可以在操作时加一个参数来让本次操作不被记录。</p>]]></content>
    
    
    <summary type="html">canvas-editor是个很优秀的国产开源富文本编辑器，这里记录下我的使用。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="前端" scheme="https://tulancn.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>路由权限问题导致的一次离奇Bug</title>
    <link href="https://tulancn.github.io/2025/03/21/work/%E6%9D%82%E8%B0%88/%E8%B7%AF%E7%94%B1%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E6%AC%A1%E7%A6%BB%E5%A5%87Bug/"/>
    <id>https://tulancn.github.io/2025/03/21/work/%E6%9D%82%E8%B0%88/%E8%B7%AF%E7%94%B1%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E6%AC%A1%E7%A6%BB%E5%A5%87Bug/</id>
    <published>2025-03-21T11:13:04.000Z</published>
    <updated>2025-03-21T12:03:57.566Z</updated>
    
    <content type="html"><![CDATA[<h2 id="起因">起因</h2><p>最近重新写了一个项目，本地运行时一直没什么问题，但是部署到服务器上时出现了打开前端页面一片空白的情况。</p><img src="/2025/03/21/work/%E6%9D%82%E8%B0%88/%E8%B7%AF%E7%94%B1%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%80%E6%AC%A1%E7%A6%BB%E5%A5%87Bug/image-20250321191917050.png" class="" title="image-20250321191917050"><p>大概表现就是如图中的情况，打开控制台看到有三个请求，分别是获取index.html，获取js和css，但是响应中是一片空白。</p><h2 id="环境">环境</h2><p>部署是在校内的服务器，外网无法访问。</p><p>前后端都部署在同一个服务器上，都使用docker构建镜像后部署。</p><p>前端是在docker中进行打包，并且装了nginx来渲染页面。</p><h2 id="排查">排查</h2><h3 id="查看nginx配置">查看nginx配置</h3><p>遇到这个情况，我第一反应是路由转发有问题，导致前端一直在请求什么东西卡死了。</p><p>所以去翻了下nginx的配置，确实发现路由转发还写的是老的服务器。</p><p>笑死，太简单了。</p><p>修改config文件，git commit，git push，然后重新部署镜像。</p><p>结果还是一模一样。</p><p>看来并不是转发的问题。</p><h3 id="查看nginx日志">查看nginx日志</h3><p>没辙，只能去翻下docker日志。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs [container]</span><br></pre></td></tr></table></figure><p>由于做了日志映射，nginx的日志会打印在docker的日志里。</p><p>翻了下有一条报错，是没获取到logo文件。</p><p>笑死，被我找到了。</p><p>于是改了下logo的读取方式，保证能读到logo文件。</p><p>git commit，git push，然后重新部署镜像。</p><p>打开页面，发现还是不行。</p><p>不信邪，再翻了下日志，已经没这个报错了。</p><p>看来也不是logo文件读不到的问题。</p><h3 id="查看docker脚本">查看docker脚本</h3><p>再去看了下docker的脚本，可能是端口映射的问题。</p><p>查看后发现也没什么问题。</p><p>但是想了想，也许是网络问题，修改了启动命令，加上了<code>--network=host</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --rm --network=host your_image curl http://localhost:8000</span><br></pre></td></tr></table></figure><p>这样docker会直接使用宿主机的网络配置，也就是没有端口映射这一说了。</p><p>某些情况下这样性能会好一些。</p><p>但改了之后还是没解决。</p><h3 id="查看docker内部文件">查看docker内部文件</h3><p>在看看nginx的运行日志吧。</p><p>先进入docker的镜像内部，这里用shell，因为镜像没装bash，不然用bash更方便些。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it [container] sh</span><br></pre></td></tr></table></figure><p>找了下nginx的日志，发现没什么异常。</p><p>再找了下前端的静态文件，也没看出来什么问题。</p><p>不信邪，试试在docker内ping了一下后端，发现也能ping通。</p><p>那看来网络是没什么问题了。</p><h3 id="查看本地打包的文件">查看本地打包的文件</h3><p>本地打包后的文件，我试着用serve来运行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npx serve -s dist</span><br></pre></td></tr></table></figure><p>运行后打开localhost，发现页面是正常的。</p><p>看来本地文件没问题。</p><h3 id="在服务器上打包">在服务器上打包</h3><p>重新登录服务器，在服务器上用npx serve来运行后端的文件。</p><p>提示没有npx。</p><p>行吧，那先安装npm。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install npm</span><br></pre></td></tr></table></figure><p>再执行，说node版本太低，只有12。</p><p>那再升级node。先装个nvm。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash</span><br></pre></td></tr></table></figure><p>然后让nvm生效。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.nvm/nvm.sh</span><br></pre></td></tr></table></figure><p>最后nvm安装node 18，再切换到18。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvm install 18</span><br><span class="line">nvm use 18</span><br></pre></td></tr></table></figure><p>用node的命令查了下，确实是18了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure><p>终于完事，再用npx serve启动。</p><p>发现打开是404。</p><p>？？？</p><p>看了下是服务器上没build后的静态文件。</p><p>行，那先安装。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install</span><br><span class="line">npm run build</span><br></pre></td></tr></table></figure><p>在本地用浏览器打开，居然也是一片空白。</p><p>？？？</p><p>至少复现了是吧。</p><p>看来不是网络问题，就是前端打包后的静态文件有问题。</p><p>脑袋里面灵光一闪，重新在本地起了下前端，这次不用localhost，用本机的IP来访问。</p><p>发现也是空白。</p><p>这下在本地复现了。</p><h3 id="询问AI">询问AI</h3><p>成功复现至少是成功了90%。</p><p>目前看下来，关键点在与用localhost能正常访问，而使用其他的IP则不行。</p><p>问了下AI，可能是什么原因。</p><p>提示说可能是cros，也可能是使用的命令不对，还有可能是防火墙问题。</p><p>都试了下，还是没解决问题。</p><h3 id="回退版本">回退版本</h3><p>最后无奈之下，开始回退版本。</p><p>用git命令回退到之前的版本，看看是哪个提交导致了目前的问题。</p><p>首先回退到之前改了logo的那次提交，发现不行。</p><p>再回退到这个提交的前一个。</p><p>启动，居然正常显示了？</p><p>ok，锁定是这个提交的改动有问题。</p><p>于是逐个逐个回退文件的改动。</p><p>回退到修改主页重定向的时候，页面正常显示了。</p><p>好，找到问题了。</p><h2 id="修复">修复</h2><p>分析一下，是路由守卫和主页重定向有冲突。</p><p>当时让未登录的用户会重定向到一个文档管理页面，而这个文档管理页面被路由守卫了，需要用户进行登录才可访问。</p><p>一来一去，死循环了，于是页面就卡死了。</p><p>那么为什么用localhost可以正常访问？</p><p>因为有浏览器缓存，会保持用户的登录状态。而其他的路由没有缓存，需要重新登录，于是就会进入死循环。</p><p>修改了这个逻辑，添加了一个未登录也可访问的落地页，让用户先在这个页面登录。</p><p>修改后重新构建，已经能正常渲染了。</p><h2 id="结论">结论</h2><p>重新看下来，debug的过程就是要对整个部署流程、前端渲染过程有一定的了解。</p><p>我还是有些依赖个人的经验，导致我直接从最大可能的地方入手，进行排查。</p><p>当然也确实一下子就找到了一个问题（虽然和最终的问题无关）。</p><p>但仔细想想，主要也是对前端不熟悉，很多时候就缺少了些验证手段。</p><p>这次都是现査工具现用的。</p><p>不过这样解决问题，才能让人有所成长吧？</p>]]></content>
    
    
    <summary type="html">这两天遇到了一个很奇怪的Bug，最后的错误原因也令人啼笑皆非，这里记录下排查过程。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="前端" scheme="https://tulancn.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>SSE协议和流式输出</title>
    <link href="https://tulancn.github.io/2025/03/09/work/front/SSE%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA/"/>
    <id>https://tulancn.github.io/2025/03/09/work/front/SSE%E5%8D%8F%E8%AE%AE%E5%92%8C%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA/</id>
    <published>2025-03-09T03:17:03.000Z</published>
    <updated>2025-03-21T11:16:40.807Z</updated>
    
    <content type="html"><![CDATA[<h2 id="流式输出">流式输出</h2><p>大多数的聊天机器人都会用到流式输出。为什么一定要用这能力呢？</p><p>任何的LLM的回答都是逐字逐句生成的，因此使用同步调用一次获取所有的消息，会造成长时间的阻塞。</p><p>尤其是DeepSeek R1这类推理模型，在给出正式的回答前还有大段大段的思考文本，这让用户的等待时间更加长了。</p><p>同时，一个请求的超时时间过长会带来其他副作用，比如用同步调用很难判断是LLM服务挂掉了还是单纯生成内容很长所以一直没回答。</p><p>因此，为了提升用户体验，减少后端一些不必要的麻烦，流式输出在目前的AI应用中越来越重要了。</p><h2 id="SSE-Server-Sent-Events-协议">SSE (Server-Sent Events) 协议</h2><h3 id="SSE协议概念">SSE协议概念</h3><ul><li>SSE（Server-Sent Events）是一种服务器推送技术，允许服务器向客户端发送事件流</li><li>它建立在HTTP协议上，使用标准的HTTP连接，但允许服务器持续向客户端推送数据</li><li>SSE连接是单向的（只能服务器向客户端发送数据），与WebSocket不同（WebSocket是双向通信）</li><li>SSE适用于实时通知、实时日志、聊天应用等场景</li></ul><h3 id="SSE协议技术特点">SSE协议技术特点</h3><ul><li>使用标准HTTP连接，不需要特殊协议或端口</li><li>自动重连功能，断开连接后会自动尝试重新连接</li><li>使用纯文本传输，每条消息格式为<code>data: 消息内容\n\n</code></li><li>支持事件ID和事件类型，便于客户端处理不同类型的消息</li><li>比WebSocket更简单，更容易实现，但功能稍弱</li></ul><h3 id="技术选型">技术选型</h3><p>后端使用的是<code>FastAPI</code>，本身就有很好的流式输出支持。</p><p>前端则是使用了<code>@microsoft/fetch-event-source</code>库，因为这个库允许修改请求头的内容，方便做鉴权。</p><h3 id="项目中SSE的应用">项目中SSE的应用</h3><ol><li><strong>后端实现（FastAPI）</strong><ul><li>使用<code>FastAPI</code>的<code>StreamingResponse</code>实现流式响应</li><li>通过异步生成器<code>serialize_generator</code>生成SSE数据流</li><li>标准SSE格式: <code>data: JSON数据\n\n</code></li><li>使用<code>time.sleep(0.05)</code>控制响应速率，避免客户端接收过快导致丢包</li></ul></li><li><strong>前端实现（Vue 3 + TypeScript）</strong><ul><li>使用<code>@microsoft/fetch-event-source</code>库处理SSE连接</li><li>在<code>frontend/src/utils/request.ts</code>中封装了<code>sseRequest</code>函数</li><li>支持请求头设置、身份验证、错误处理和连接状态管理</li><li>通过<code>parseSSEMessage</code>函数解析接收到的SSE消息</li></ul></li></ol><h2 id="打字机">打字机</h2><h3 id="为什么要做打字机效果">为什么要做打字机效果</h3><p>由于网络波动，后端的推送并不是匀速到达客户端的。如果前端仅仅是收到一条消息就拼接到前端的文本上，那么最终效果就会显得很呆。</p><p>通过在前端添加一个缓冲队列，来让字符匀速显示，会让前端的展示效果显著提升。</p><p>就是俗话说的&quot;质感&quot;。</p><h3 id="核心功能">核心功能</h3><ul><li>实现了文字逐字打印的动画效果</li><li>支持动态调整打字速度</li></ul><h3 id="技术实现">技术实现</h3><ul><li>使用TypeScript实现类封装</li><li>采用缓冲区设计模式存储待显示的文本</li><li>使用定时器控制打字速度</li><li>提供丰富的回调函数支持，如<code>onComplete</code>、<code>onPause</code>等</li></ul><h2 id="总结">总结</h2><p>整体逻辑其实很简单，SSE+前端打字机。</p><p>前端本身就是响应式的，所以代码实现其实不麻烦，直接往文本框里拼接字符就行，甚至有点简单。</p><p>但不管怎么说，SSE协议在AI应用中目前使用应该是最为广泛的，几乎所有项目都得走这个流程。</p>]]></content>
    
    
    <summary type="html">最近在项目中用到了SSE协议，这里简单写下怎么接入的。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="技术协议" scheme="https://tulancn.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%8F%E8%AE%AE/"/>
    
  </entry>
  
  <entry>
    <title>我也是全栈</title>
    <link href="https://tulancn.github.io/2025/02/28/work/%E6%9D%82%E8%B0%88/%E6%88%91%E4%B9%9F%E6%98%AF%E5%85%A8%E6%A0%88/"/>
    <id>https://tulancn.github.io/2025/02/28/work/%E6%9D%82%E8%B0%88/%E6%88%91%E4%B9%9F%E6%98%AF%E5%85%A8%E6%A0%88/</id>
    <published>2025-02-28T14:07:08.000Z</published>
    <updated>2025-03-10T13:49:45.421Z</updated>
    
    <content type="html"><![CDATA[<h2 id="经历">经历</h2><p>如果说我是什么时候有这个想法，那我觉得最早应该要追溯到大一的时候了。</p><p>当时刚入学，正在军训。我们有一次思想测验，当时年级里有同学搭了一个网站供我们考试。</p><p>刚上大学的我对这操作惊为天人。</p><p>后来从别人那了解到，这些东西在大二的时候基本都会教。</p><p>可惜，事实是直到大三我都不知道他们是怎么搭建的这网站。</p><p>接着就是实习，才开始对软件开发有了些概念。了解了前端、后端，各种开发语言，各种基础概念。也算是开始学以致用了。</p><p>毕业之后，我开始工作。</p><p>还记得上班的第一天，部门最大的领导过来有个谈话的环节。</p><p>海航总问我们，你们有什么目标吗？</p><p>没人回应。</p><p>稍稍沉默之后，我鼓起勇气回答道：“我想做全栈。”</p><p>我觉得这就是我开始有做全栈的决心的时候。</p><p>时光飞逝，我不断加深着后端的技能。数据库，运维部署，监控，开发框架，缓存，流量治理，网络通讯，这些点在我工作的这些年里我也慢慢加深了解。</p><p>唯独前端一直没什么进展。</p><p>我一直就是维持在有个前端项目，可以在我本地运行起来的这么个程度。</p><p>第一次转机出现在第二年年末，我去做低码平台的项目。</p><p>当时前端资源紧缺，很多细节让前端来改实在是有些慢了。我就看了下vue2的语法，还有前端的基础入门，就上手改一下样式和bug之类的。</p><p>当时算是有了个基本的了解，大概前端是怎么个运行逻辑是知道了。</p><p>第二次转机出现在上研究生之后，我参与了一个学校的项目，主攻前端。得益于大模型的发展，学习速度非常快。</p><p>再加上有cursor之类的编程工具协助，我很快就能独立开发出非常美观的前端界面了。</p><p>当然我也是看了些课程，以便了解前端的基础语法。这里主要是ts和vue3不懂，看了下尚硅谷的b站课程。效率不是很高，但我觉着也算是懂了不少吧。</p><p>上学之后也有些其他的经历，比如用python做数分的项目，尝试写了些微信小游戏和小程序。</p><p>就我个人而言，我觉得自己确实也算是真正成为一个合格的全栈开发了。</p><p>能独立完成前端、后端、移动端、数据库和运维部署的所有工作，作为打工人已经没什么太多可求的了。</p><p>我有段时间的QQ签名改成了一人成军，意思就是形容全栈可以一个人完成所有的开发工作。</p><p>写代码确实是很有意思的事情。</p><p>接触的东西多了以后，我开始有个想法：软件开发的各类工具只是表象，底层有两个东西，一是技术思维，二是业务知识。</p><p>技术思维有两种，一是直觉性的，看到一个东西就能反应过来应该怎么做，二是思考后得出的。</p><p>变为全栈之后，对我的技术直觉有了显著的提升。大多数的功能或架构，都能说上几句话，或者是在短短的时间内了解和掌握了。</p><p>我常常过于信任直觉性的思维，二忽视思考的结论，这是不对的。</p><p>业务知识是对具体业务场景的了解。技术总是趋向于无限增长的，总想得到最优解。但业务不是，业务知识充斥着边界和特例。这些边界和特例会反过来限制技术，让技术在到达某个界限后，就趋向于停止。</p><p>只有业务发展了，才会对技术有需求。否则技术发展更多的是一种学习研究性质的工作，不是用来解决具体问题的，没有落地的地方。</p><p>技术应该有前瞻性，但不应该过度，否则会对其他的资源造成挤压。</p><h2 id="前后的对比">前后的对比</h2><p>然后再聊聊我学了前端之后的理解。</p><p>前端我理解中更像是用代码在布设各种陷阱，设置好了之后等用户点击触发，再改变页面的逻辑。前端的数据来源之一是用户，用户在某个组件填写的内容，得直到点击发送按钮时才会用上。</p><p>后端则是从收到请求之后，运行各种复杂逻辑进行计算。</p><p>区别在于后端不需要布设多个组件进行组件的联动，后端收到的用户请求中就是所有的信息，其他信息得从数据库或其他持久化数据源用获取。后端更多的是数据的流转和计算。</p><p>这其实解释了为什么前端总是响应式的，前端的回调逻辑远多于后端。</p><h2 id="未来发展">未来发展</h2><p>现在讲究大前端，会写web，适当学一下就能写移动端和桌面端。</p><p>挺好笑的就是前端现在有点TS一统天下的味道了，而TS的语法总觉得和Java或者Python一个味道。</p><p>或者说未来大家的编程语言都会变成越来越像吧。</p><p>就像Java缺少了很多语法糖，而Python则充斥着各种语法糖，Go学了Python，也搞了很多类似的语法。</p><p>现在Java 21出来了，也在往这方向靠。</p><p>新时代的编程语言似乎在趋向于统一，都在往高级编程语言的方向进化。这也是这么多年来，无数程序员编码过程中的实践而产生的经验了。</p><p>编程语言这东西没必要卡这么死，大家到最后其实都差不多。</p><p>搞全栈不太好的地方就是样样都会，但很难样样都精通。以后可能最好还是走中间人或者管理的方向会比较好，毕竟啥都懂的人也是少数，要取长补短嘛。</p>]]></content>
    
    
    <summary type="html">最近突然发现自己已经可以算是全栈了，想回顾一下自己的心路历程。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>聊聊AI工具和学习</title>
    <link href="https://tulancn.github.io/2025/02/15/study/%E8%81%8A%E8%81%8AAI%E5%B7%A5%E5%85%B7%E5%92%8C%E5%AD%A6%E4%B9%A0/"/>
    <id>https://tulancn.github.io/2025/02/15/study/%E8%81%8A%E8%81%8AAI%E5%B7%A5%E5%85%B7%E5%92%8C%E5%AD%A6%E4%B9%A0/</id>
    <published>2025-02-15T11:54:17.000Z</published>
    <updated>2025-03-10T13:54:25.192Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>上次nlp的project被同学宣传了一下，后来有人来交流，就被拉去给老师做项目了。</p><p>名义上是当了student assistant，工资也是按照这个待遇来。80港币一小时，说实话还不少。</p><p>项目是关于一个AI论文的平台，希望能借用AI工具来对论文进行编写、修改和润色。功能倒是挺简单的，我觉得主要难点还是在设计和实现上。</p><h2 id="难点">难点</h2><p>我觉得第一个难点是人力的缺失，更准确地说是协作的方式。虽说我后来又找了3个人来，组成了6人小队，但还是觉得人手不够，做事不够快。</p><p>从数量上来说，这点人肯定是够了，但我觉得暂时没找到很好的协作方式。换句话说，也就是没能把这6个人的能力全部发挥出来。</p><p>这也是很痛苦，没什么办法的事情，毕竟项目管理本就是一个很困难的事情。</p><p>第二个难点应该是设计的问题。目前没有产品经理的角色，实际上很多功能的设计上是缺失了有人把关。甚至更严重的是，我们所有人都是身兼多职，既要看产品怎么样，又要看怎么实现。</p><p>这种体验倒是和初创团队差不多了。</p><p>没有专业的设计团队，难免会导致功能上可能少东少西，甚至交互上也会很反人类。</p><p>第三个难点在于测试和验收。目前也没有测试人员，功能的验收是没有人把关的。做得怎么样，怎样算好，有没有bug，这些大家在做完之后都没有反馈的渠道。</p><p>没有结果的反馈，也就很难进一步提高了。</p><p>第四个难点在于缺少标准的制定。管理团队最重要的就是制定标准，标准是协作的基础。人并不可靠，但完善的标准可以让人变可靠。这话对AI也同理。目前我们后台日志打印的方式、异常的抛出、前端的请求方式都没有统一的标准制定出来。这些得尽快解决了。</p><h2 id="预期">预期</h2><p>聊完难点，不妨畅想一下预期。</p><p>我理想中的团队，应该是抱有热情、持续产出、愿意钻研的。他们每天都能提交一定的代码，推进一定的工作。定时上线开会，有问题及时沟通。大胆指出目前工作中不合逻辑的地方，并且提出改进意见。</p><p>显然目前还达不到。</p><h2 id="使用AI工具开发">使用AI工具开发</h2><p>前面感觉都扯远了，这里回到正题，再聊聊AI工具和学习。</p><p>这里的AI工具，应该说特指cursor这类编程工具了。</p><p>比较好笑的是，我居然是这次项目中负责写前端的人。可实际上我并不懂前端，ts基础语法都没认真学过。</p><p>但目前看下来，我甚至都不算是拖后腿的那个人。</p><p>感谢cursor，让我有了这种体验。</p><p>前端我也不是没学，也花了点时间看了下尚硅谷的Vue3前端入门教程。只不过暂时还没看完罢了。</p><p>我觉得过段时间可以把尚硅谷的项目完整做一下，还是挺有意义的。</p><p>整体编写项目前端的过程，让我觉得最重要的还是知道目标，然后提出自己的需求。</p><p>AI工具已经非常智能，只要在输入指令的时候带上那么一点点技术的关键词，基本上就可以帮你实现各种需求了。</p><h2 id="使用AI工具学习">使用AI工具学习</h2><p>但凡事皆有代价。使用AI工具来开发，其实很大程度上属于是用长期的提高和理解，换取暂时的成果。</p><p>使用cursor我写了相当多的代码，但代价就是我还是觉得自己对Vue3一窍不懂，不能写代码。</p><p>感觉是离了cursor不会写代码了。</p><p>这种体验很差，短期看到有美观的页面生成确实让人多巴胺快速分泌，有满足感。</p><p>这种感觉一旦过去，充斥心头的是一种迷茫和空虚。</p><p>频繁使用AI只会让自己变得没有长进。你增长的只有使用AI的能力，而不是做事情的能力。</p><p>这也让我觉得有些恐慌。</p><p>也是第一次有了AI是不是会取代我的工作的焦虑感。</p><p>最讽刺好笑的事情也是在这。如果现在想要快速学习新的知识，借助AI工具也是最快的。</p><p><strong>如果你愿意在每次生成代码之后，让AI工具解释一下它为什么这么写，它会是最好的导师。</strong></p><p>我觉得现在学一个新技术，最难的还是不知道roadmap。</p><p>而AI打破了这个知识搜集的过程，大部分时候它是可以提供一些可靠的roadmap，让你知道自己应该先学什么，后学什么。</p><p>我个人比较喜欢的路径是，先quick start看到成果，然后逐步深入其中的每一个步骤，理解其原理。</p><p>凭借多年的技术直觉，我觉得很多时候自己还是可以问出一些很有用的问题，从而获得最合理的AI答复。</p><p>动手学习确实比单纯听讲要好得多。</p><h2 id="总结">总结</h2><p>最近是接了一个项目，遇到了不少困难。</p><p>然后我也开始写前端了，在编写的过层中我大量使用了AI。</p><p>这让我思考为什么要用AI，AI的能力边界在哪。</p><p>我决定以后要慎重使用AI，在使用完之后多问一句为什么，从而实现在实践的过程中提高自己的技术水平。</p>]]></content>
    
    
    <summary type="html">最近在跟着老师做项目，尝试梳理下自己的一些想法。</summary>
    
    
    
    <category term="学习" scheme="https://tulancn.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习总结" scheme="https://tulancn.github.io/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>股市投机的原则</title>
    <link href="https://tulancn.github.io/2024/12/13/life/%E8%82%A1%E5%B8%82%E6%8A%95%E6%9C%BA%E7%9A%84%E5%8E%9F%E5%88%99/"/>
    <id>https://tulancn.github.io/2024/12/13/life/%E8%82%A1%E5%B8%82%E6%8A%95%E6%9C%BA%E7%9A%84%E5%8E%9F%E5%88%99/</id>
    <published>2024-12-13T08:49:54.000Z</published>
    <updated>2025-03-10T13:55:47.433Z</updated>
    
    <content type="html"><![CDATA[<h2 id="A股的底层逻辑是博弈">A股的底层逻辑是博弈</h2><p>这是对A股市场中股价波动的解释。在A股市场中，几乎没有人是通过分红的复利来实现财富增长和价值投资的。</p><p>那么，所谓的政策利好其实也只是给赌徒们指明了一个方向：下一波我们炒这个。</p><p>各类大资金做局，通过政策指引等方式制造热点，让散户和其他游资集中到某个股票中，然后大资金们出手给小资金，小资金出售给散户。</p><p>这里分两种情况来讨论：</p><p>第一种：新热点出现导致某个版块普涨。某些政策出台后，会对某些版块产生明显的利好。这时候短线资金会集中到这个版块中，不同资金会随机寻找版块中的某个股票买入，导致版块中的股票呈现出不同的涨幅。</p><p>某些股票涨幅大，那么就会吸引更多的散户和其他大资金来买入，最终表现就是封板。</p><p>一个版块中可能有多支股票都是涨停的，那么第二天就会继续在这些股票中寻找能继续封版的股票，也就是所谓的一进二，二进三等。</p><p>假如有其他的热点出现，可能这些昨天涨停的票今天都会跌。</p><p>假如市场上的其他人不认账，那这些票可能今天也会继续跌下去。</p><p>还有种可能是其他人继续追高，在昨天形势较好的股票中选择某几个继续大量买入，这时候就会出现连板。</p><p>连板中，会有些票会掉队，因为市场上参与的资金是有限的，击鼓传花的游戏在某一个时刻会因为没有其他人来买而结束。</p><p>资金会集中向头部的股票，直到头部的股票价格过高，没有人愿意再买了。</p><p>如果热点足够吸引人，还会有补涨。就是头部的连板票带动了市场中其他版块的活跃资金也参与到本版块中，其他的活跃资金可能因为前排的连板票买不到而选择去买入同版块还没炒起来的股票。这种被其他资金选择的票可能也会连板，并且在头部的连板票破板时，成为市场上资金新的宠儿。</p><p>头部的连板票，一般称为龙头；补涨的票，称为补涨龙。还有些票，一直随着版块在偷偷涨，但没有涨停，这种称为中军，一般是市值较大的白马股。</p><p>第二种：版块的资金回流。龙头崩了之后，势必会带动大量的资金一起抛售，这时候股价跌停都是正常的。</p><p>但是在跌停时，可能有资金认为这票还能涨，于是在低位进行接盘。当有足够多的资金认为还能涨时，就会出现弱转强，也就是资金的回流。</p><p>比如昨天龙头跌停，预期是今天继续跌停。但是实际上开盘是正，并且股价起飞，那么就可以认为有人觉得这票还能涨。如果弱转强的共识足够，那么就能把本来短板的龙头重新抬起来继续涨。</p><p>弱转强是非常常见的，同时也是相当有效的赚钱手段。</p><p>这里讲了两种博弈的方式，其实简单概括，就是先信卖给后信。</p><h2 id="设立止损目标">设立止损目标</h2><p>在赚钱时，也应该设立止损目标，比如利润回撤到3%就清仓。</p><p>无论如何，少赚总比不赚好。如果利润回撤了，就说明肯定有更好的清仓时机，应该去思考什么时候清仓更合适，而不是死扛把利润都亏空了。</p><p>在亏钱时，也要设立止损目标。止损是个麻烦事儿，大部分人总会妄想自己后面可以重新赚回来。但止损时应该想的是自己为什么当时会去买入这个股票，说明需要优化买入时机。</p><h2 id="不做自己不了解的行业">不做自己不了解的行业</h2><p>自己不了解的行业，可能会导致决策失误，进而导致亏钱。</p><p>只做自己了解的行业是对自己负责。</p><h2 id="不做太小的票">不做太小的票</h2><p>如果一个票的市值过小，可能随意一个游资都能在这票坐庄。</p><p>庄股是最恶心的，上涨和下跌没有任何规律可言。</p><h2 id="尽量做股性活跃的票">尽量做股性活跃的票</h2><p>股性活跃，指的是这个版块有利好时，大部分资金都会首先选择买入这个股票。这种股票在长期活跃的版块都有存在。</p><p>可以说大家可能对老龙都有记忆吧，每次有利好都优先把以前连板过的票拉出来再炒一次。</p><h2 id="少碰kdj在20-80之间的票">少碰kdj在20-80之间的票</h2><p>kdj指标说明了短期一支股票的超买和超卖的情况。如果一个股票的kdj在20-80之间，大概率说明这票最近没什么人在炒。</p><p>没人炒的票持有了也很难获得大量收益。</p><h2 id="遵循自己的规则">遵循自己的规则</h2><p>设立自己的交易规则，严格遵守规则，并在复盘时适时调整规则。</p><p>交易时间一定要按照自己的交易规则来进行交易，东买一个西买一个总有一天赚的都要亏回去。</p><p>如果一次交易是亏钱的，说明交易规则有问题，想办法调整并避免以后还出现类似的问题。这种态度才是正确的。</p>]]></content>
    
    
    <summary type="html">股海浮沉，总结了几条对自己有帮助的原则，希望自己能继续遵守。</summary>
    
    
    
    <category term="生活" scheme="https://tulancn.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="投资" scheme="https://tulancn.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>NLP的project复盘</title>
    <link href="https://tulancn.github.io/2024/11/22/study/NLP%E7%9A%84project%E5%A4%8D%E7%9B%98/"/>
    <id>https://tulancn.github.io/2024/11/22/study/NLP%E7%9A%84project%E5%A4%8D%E7%9B%98/</id>
    <published>2024-11-22T06:57:31.000Z</published>
    <updated>2025-03-10T13:56:09.342Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>这是第一门需要协作的大作业，过程中着实暴露了很多问题。我觉得是需要复盘来明确这些问题，以免在下次的作业中再有类似的情况发生。</p><p>项目要求是利用大模型的技术，结合课上所学的NLP相关知识，来开发一个对话模型。最终这个系统能做到让用户通过自然语言来查询某个领域的数据。</p><h2 id="过程">过程</h2><h3 id="第一次会议">第一次会议</h3><p>一开始可能是大家还不熟，我作为脸皮最厚的主动出来破冰。</p><p>这就像无领导小组讨论第一件事就是选领导；分布式等价节点一致性算法第一件事就是选主节点；Project第一个跳出来的人也会成为组织的核心。</p><p>之后就基本围绕着我的思路，开始选题，分配预研任务。我确定了一下开会的频率和任务的大致分配方向，以及日常的沟通方式，代码提交的仓库，保证这个项目推进必要的一些因素都已具备，第一次会议就算结束。</p><p>打算是分三周，第一周预研，第二周产出第一个demo，第三周产出最终的。</p><h3 id="第二次会议之前">第二次会议之前</h3><p>我这边主要是要预研RAG的基础框架和前端界面。</p><p>说实在的我也没多上心，粗看了一下AnythingLLM，跑了下本地模型发现展示的效果还可以。然后接入本地模型、通义千问和其他的一些模型试了下，认为这个框架基本可用，就算完事了。</p><p>数据爬取的任务倒是做得还可以，能拉到三个网站的数据。</p><p>需求分析决定了后续的提示词怎么写，这部分最终产出不是很标准，但也算有模有样，可以列入工作内容的一部分。</p><h3 id="第二次会议">第二次会议</h3><p>原先预订是第二次会议前要有产出的demo，所以第二次的会议上我就展示了一下AnythingLLM。其他的一些沟通已经没多少印象了，大概就是确定要做什么之后，直接进入模型微调的阶段了。</p><h3 id="第三次会议">第三次会议</h3><p>原先预定是在第二周产出一个demo，但是用AnythingLLM这个demo产出比我想得要快太多了…</p><p>然后第二周的目标在周二就算提前完成，摸了会儿鱼一直拖到第三周才进行第三次会议。</p><p>这第三次会议上演示了一下纯使用AnythingLLM的成果，客观来说包装一下作为汇报用的结果还真可以。</p><p>不过还是想着再做些事情，于是会后我又花了点时间去写了下插件。</p><h3 id="第三次会议后">第三次会议后</h3><p>由于我也没怎么写过python的工程，先花了点时间看了下python的工程结构。</p><p>插件开发需要模型支持，就想着先把模型从AnythingLLM搬到了阿里云的百炼平台上，花了一个小时吧。</p><p>看了下模型怎么自定义插件的文档，本来还想找找阿里云有没有提供案例，结果发现没有。</p><p>那没辙，先理解再说。</p><p>翻了下就是自己部署一个web服务，然后提供OpenAPI 3.0的接口文档和一个告知模型在什么情况下需要调用插件的prompt。那就简单了，实际的功能代码有现成的，我只需要把这些能力集成到web服务里就行。</p><p>于是开始翻怎么用python写web服务，发现有个quart的框架，快速写了demo，结论是可行。</p><p>找了下阿里云有免费的试用服务器，租了一个4核8G的服务器，ping了它的公网IP，通了。那这服务器也好说。</p><p>部署服务到云服务器，一调用发现不通。怀疑是权限问题，去控制台找了下权限控制的功能，开通端口，再调用通了。这部署也算完成。</p><p>用AI生成了OpenAPI 3.0的接口文档，接着写prompt，最后在百炼上创建一个插件，这样就算集成了。</p><p>调试了一下大模型调用插件的效果，发现还不错，至此完成了插件的功能。</p><p>最终的效果给同组的同学展示了一下，都说很可以。给他们开通了子账号的权限，每个人都能调整模型的prompt和看到最终的效果。</p><p>随后的时间就是准备pre和最终的report。</p><h2 id="复盘">复盘</h2><h3 id="问题分析暴露了思维的差异">问题分析暴露了思维的差异</h3><p>简单分析一下，在模型侧，要通过一些手段来让模型了解某个领域的数据。那么很自然就会想到专家模型，想到微调，接着答案就呼之欲出——RAG。</p><p>对，其实能做到RAG，这个项目基本已经完成了。</p><p>那么就涉及到数据来源的问题，这里就出现了第一次的思维差异。我倾向于额外添加插件的能力，能让模型获取到更具有时效性的信息。而其他人似乎并没有意识到这个能力的必要性，认为这个能力优先级不高，能先处理好RAG就可以了。</p><p>其次就是这个选题的方向是什么，大家一开始都没什么点子，于是我提出用头脑风暴的方式来发散思维。最终确定是做一个关于招聘信息的助手。</p><p>到最后，我干脆直接拉出日程表，列了下整个工作的日程和计划，也拟定了一些里程碑目标出来。大家也没多说什么，一下子就同意了。</p><h3 id="工作方式的妥协">工作方式的妥协</h3><p>如果是企业中接到一个项目，可能我第一反应是确定好日程计划，然后拉人开会，对齐拉通保证大家思维的一致性，留好联系方式，有什么问题及时调整。</p><p>但是实际在这个project的执行过程中，一来大家都挺陌生，不知道对方几斤几两；二来工具不齐，想做项目管理多多少少有些麻烦。最后只能妥协，用腾讯文档作为项目管理的一环，github作为配置库，以及任务分配全靠自觉。</p><p>所幸大家都还算给面子，仗着年纪大脸皮厚大家还算愿意听我讲话。</p><p>还有就是远程办公，在微信群沟通确实效率过于低下了，我个人会更喜欢用远程会议的方式来快速沟通。而且大家也不是集中在一处专心做这个project，互相之间配合和协调也是个问题。</p><p>最终妥协的成果，就是把任务提前分隔成较为独立的子任务，每个人认领其中一部分。然后我作为最终的统筹，收集各个成员的产出，并拼凑为一个较为合理的产物。</p><p>就我个人而言，这些都不算什么工作量，但是对于其他人而言可能会有些困难，毕竟没什么管理经验。所以我来担任也算是比较合理的。</p><h3 id="留好成长的空间">留好成长的空间</h3><p>整个过程中一直在强调要沟通，每个人的提交都能让其他人在本地运行。本意是想让每个人都参与进来，能看到project的当前的效果。</p><p>但第一个迭代这个事情做得不是很好。所以第二个迭代我就全面上云，让每个人都能参与进来。</p><p>我觉得一个项目的推进过程中，项目中的每个人都应该是有所成长的。作为领导，一定会注意经验的复用和下属的培养。</p><p>对于这个project来说，就是要给愿意学的人，留好空间，把想学的东西放在每个人随时都能够得到的地方。</p>]]></content>
    
    
    <summary type="html">管理亦是一门妥协的艺术。不要以企业的标准来要求学生。</summary>
    
    
    
    <category term="学习" scheme="https://tulancn.github.io/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="学习总结" scheme="https://tulancn.github.io/tags/%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>回炉重造是种什么样的感觉？</title>
    <link href="https://tulancn.github.io/2024/11/20/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/"/>
    <id>https://tulancn.github.io/2024/11/20/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/</id>
    <published>2024-11-20T05:32:12.000Z</published>
    <updated>2025-03-10T13:55:54.636Z</updated>
    
    <content type="html"><![CDATA[<h2 id="就读体验">就读体验</h2><p>整体来说，在polyu的就读体验还算不错。</p><p>各种流程都会有较为详细的指引。比如入学、选课、课程的考试之类的日常流程，都有邮件会提醒，邮件中会有很详细的说明，足够每个人完成这些。</p><p>每个学生也都会收到不少附赠的资源，比如学生的云电脑有两块免费的4090ti可用。在学校想训练自己的大模型，或是做一些微调都足够用了。</p><p>同学倒是也都挺实在的。毕竟排名是港三之外吧，挺少见到本科985的同学，遇到的985也大多是转方向来读计算机的。像我这种工作4年再来读书的确实是少数的少数。这也导致了遇到的同学大多很佛系，不太在意成绩，大多是一个能过就行的态度。某种意义上倒也挺符合对港留子的刻板印象的。</p><p>虽说绝大部分人都是抱着一个拿到学位就算成功的态度，但同学中也有少数比较卷的，大部分是local，目标都是继续深造读博。</p><p>学校的课也不算太水，NLP、AI concept和Big Data都会介绍目前最前沿的技术。对于我这种没接触过AI算法的人来说，确实有点头大。不过也算学到了新东西，倒也不亏。</p><p>本科毕业之后，可能大家都已经有了自己的规划。对于读书这事，目的也各不相同。</p><p>这港硕的一年，就像是把一群各有自己想法的人聚集到了一块儿，每次遇到陌生同学，聊几句就会发现对方过着和你截然不同的人生。</p><p>从我个人角度，满分100，我给港理工打90。10分扣在不是港三，但这事也怨我，早点申请可能也就到港三去了。</p><h2 id="回炉重造的成果">回炉重造的成果</h2><p>挨过了社会的毒打，重新回到校园，以为会是狼入羊群嘎嘎乱杀，结果是发现牛混到了羊群里，居然要重新学怎么吃草。</p><p>技术栈差别很大，真的很大。我原本是搞工程方向的人，但是研究生也不得不去学算法，学AI的技术了。</p><p>大模型的风确实刮到了各种地方，现在是个学科只要挂上机器学习的名头就能变成一个新学科，一个新方向。</p><p>风来了，那么也只能顺着风的方向去飞。借着学校的课程，我也开始在AI这块入了个门。</p><p>到NLP的小组作业，也算是小小地喷发了一会儿。</p><p>我久违地写了点代码，然后把服务部署到了阿里云的云服务器上，最后接入通义千问大模型。搞出来的效果让同组的人都惊呆了。</p><p>其他组大多是在大模型的上层做了RAG，但我的思路是在RAG之外要给模型提供插件来获取实时信息，否则这个项目的成果完全不可用。</p><img src="/2024/11/20/life/%E5%9B%9E%E7%82%89%E9%87%8D%E9%80%A0%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E6%84%9F%E8%A7%89%EF%BC%9F/image-20241121203740450.png" class="" title="image-20241121203740450"><p>做完的时候有种感觉，就是自己好像确实学了不少新玩意儿。</p><p>这次回炉重造，最初的目标就是能开拓一些新的知识点，希望能学python，学数据分析，学AI训练，学会写前端。</p><p>我觉得还是有些进步的，至少python会写了，数分也入门了，大模型的训练、微调也会了。目前还差点前端，打算是考试期间学点微信小程序的前端，先入门一下。</p><p>也慢慢明白自己擅长和不擅长的地方，对未来的规划也更加明确了。</p><p>回炉重造初显成效。</p><h2 id="看过猪跑很重要">看过猪跑很重要</h2><p>我当时下定决心要读研究生，这句话对我影响很大：“看过猪跑很重要”。</p><p>应该是阿里的毕玄在一次采访中说的。大概意思是公司的业务发展中，总会随着业务量出现各种新的问题。这时候能了解其他人的解法，是非常有参考价值的。</p><p>拿阿里来说，当时国内没有什么公司能作为参考，他们会去找谷歌的案例。但是找到的案例可能是10年前的，对于当时的业务量，足以够用。</p><p>而业务快速成长，遇到的困难也越来越多。到某一天，突然发现谷歌也没处理过现在阿里遇到的问题了。那这时候怎么办？</p><p>唯有自己解决了？</p><p>非也。这时候，答案在学术界。</p><p>时代变化，公司可能已经成长为巨头，此时不能直接照抄人家的答案，你也得作为开拓者参与最前沿的技术。</p><p>这时候各种国际会议、学术论文会进入你的视野，从学术角度找方案来落地才是最切实可行的。为什么说&quot;看过猪跑很重要&quot;，学习的知识来源是实践，而模仿是实践中效率最高的方式。</p><p>公司的业务变化，模仿的对象也要变化。当接近了金字塔的顶尖，所有人都不得不参与到名为学术的圈子里。</p><p>而这时候，你也得产出一些成果，可能是学术会议上的论文、各种分享会上的演讲，你也会变成别人眼中奔跑的猪。</p><p>我想读研究生，就是希望能先打个基础，以后做到这个程度的时候不会有短板。</p><h2 id="回炉重造的感受">回炉重造的感受</h2><p>自由、时间充裕、需要自控力。这三点是我最大的想法。</p><p>不用上班之后确实时间很多，也很自由，但是想做些什么有意义的事情，得靠自控力。</p><p>我每年都有立个目标和年末总结的习惯。</p><p>今年的目标，有两个：上学和变全栈。上学算是完成了，全栈还需要一点点时间，不过我相信我绝对没什么问题。</p><p>当时脑袋里萌发出读研的想法，我觉得这个决定可能会影响我一生，于是我马上订了去广州的高铁去找中介，并且立马签了合同。</p><p>现在已经初现倪端，我接触的技术范围大大超过了工作时。</p><p>我始终觉得方法比实际的努力更重要，因此我学习更注重学会学习方法，走通学习新知识的路，而不是学会这个知识本身。</p><p>在这方面，研究生读得还挺值得的。</p>]]></content>
    
    
    <summary type="html">港硕第一学期即将结束，赶due的期间摸鱼写个博客。</summary>
    
    
    
    <category term="生活" scheme="https://tulancn.github.io/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="杂谈" scheme="https://tulancn.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>秋招的总结</title>
    <link href="https://tulancn.github.io/2024/11/01/work/%E6%9D%82%E8%B0%88/%E7%A7%8B%E6%8B%9B%E7%9A%84%E6%80%BB%E7%BB%93/"/>
    <id>https://tulancn.github.io/2024/11/01/work/%E6%9D%82%E8%B0%88/%E7%A7%8B%E6%8B%9B%E7%9A%84%E6%80%BB%E7%BB%93/</id>
    <published>2024-11-01T07:08:20.000Z</published>
    <updated>2025-03-10T13:57:29.416Z</updated>
    
    <content type="html"><![CDATA[<h2 id="经历">经历</h2><p>最开始是准备简历和找招聘信息，这部分就略过不谈。</p><p>麻烦的还是面试的准备，前期刷了leetcode的hot100，然后搞了一份80字面试宝典一点点看。</p><p>这些处理完已经到9月中旬了，这才慢慢投了一些厂子。</p><p>到十月国庆假期之后，才有一些笔试邀请过来。这时候已经是第二批次的秋招了，说实话互联网大厂的希望不大。</p><p>不过我也投了一个国企，还意外做了个行测。没怎么准备这种题目，说实话还是挺有意思的，感觉像智商测试。</p><p>等了一个月，到十月末，是华为给了面试的机会。</p><p>推荐人说粤港澳的面试安排有些混乱，想着在香港的同学线下跑去面试也不方便，也干脆给我安排走线上了。</p><p>一面在下午4点。</p><p>一开始是自我介绍，然后面试官挑项目经历问了些问题。</p><p>问了JNI是什么，为什么项目要用到JNI。回答提了一下Java的特性，JNI的用法和原理。</p><p>接着就继续从项目挑技术点问，中途话题被我带到了信创，就聊了不少信创的事情，感觉快变成纯聊天了。</p><p>一面大概是被安排了要问基础的问题，聊了一会儿之后面试官一拐话题说要继续问基础。</p><p>手撕挺简单的，给两个二进制字符串求和。这里我一边念题目一边说想法，然后再实现。</p><p>调试的时候出了一个bug，我说了一句Java不能多值返回就是麻烦，听到面试官笑了。</p><p>最后让我解释了一下调试时出现的问题原因，一面就结束了。</p><p>二面延后到了6点。</p><p>因为有些推迟了，面试官上来说直接做道题吧。</p><p>是一道分割整数数组的题，要求分割成三个数组，顺序不能变，数组和依次增大。问有几种解法。</p><p>还是一样，一边念题目一边说想法。写完面试官问了下几个优化的点。</p><p>然后就开始问项目，应该是想了解应聘者的技术思维吧。每个技术都问了下为什么这么做，有没有优化空间。</p><p>倒是都答上来了，有些比较复杂的回答就先把场景说明清楚。</p><p>中间提了项目中一些比较新奇的技术点，面试官也挺感兴趣的，就聊了挺久。</p><p>比较刁钻的就是问了下kafka有什么缺点。我一开始说不上来，就先扯了一句说它不信创，有些客户觉得可能影响项目的信创认证。然后才从技术角度回答了一下，主要是从不去中心化，对zk的强依赖（新版本用kraft去掉了），以及做消息防丢之后性能比较差这三个方面来说。</p><p>二面也顺利结束。</p><p>三面主管面是在9点。</p><p>上来主管先道歉，说拖了这么久，我说没关系。</p><p>跳过了项目拷打，主管说有工作经历相信技术上不会有问题。</p><p>先问为什么要重新去深造，会不会在华为工作以后也因为深造而离职。说上了研究生之后就像泄了气的皮球，没什么继续读书的兴趣。</p><p>接着问为什么选华为，我说我家里人都是花粉。面试官直接笑出声。</p><p>然后比较正式地回答是聊了下之前工作时做信创的经历，比较认可华为云自下而上从硬件层开始做信创的方案，认为公司有意愿去做其他公司不敢做的事，愿意在基础产品上投入。</p><p>举了个例子，之前在华为的服务器做压测，性能指标一直上不去。最后把JDK从openjdk换成华为的毕昇JDK，触发了软硬件协同，性能指标就一下子提上去了。</p><p>最后是关于压力，让我举个抗压的例子。先举了一个，不满意，然后再举。我说我为了读研究生考了7次雅思，第6次的时候崩溃大哭，但是收拾好心情继续去考了，最后终于过了。面试官边笑边说可以了。</p><p>反问环节，我说华为云内部是否很重视信创，给了肯定的回答。</p><p>结束时主管说希望还能再见到我，心理有预感已经过了。</p><p>晚上11点45准时收到面试的评价。</p><p>总体来说面试体验挺好的，虽然有些小插曲，但华为的员工们态度都很不错。</p><p>华为的面试之后，也就没有其他的面试流程了，秋招的拼搏阶段也算画上了句号。</p><h2 id="复盘">复盘</h2><p>如果要想一下还有什么能提高的，我觉得首先是自我介绍。</p><p>我发现很难在一两分钟内把自己所做过的所有事情都讲明白，一方面是经历比较丰富，一方面也是自己挑不到重点。</p><p>所以自我介绍还是得磨一磨，围绕项目把技术亮点重点说明，简单的经历就汇在一起用一句话带过。</p><p>第二个是下次春招要提前投递，这次秋招吃了不少的亏，主要是没有提前进行投递，导致没赶上9月的一批岗位。</p><p>最后是算法题，倒不是写不出来，就是我写得有点慢，这得再写一些题目才行。</p><h2 id="杂谈">杂谈</h2><p>仔细想想其实没面几家，算不上海投，算不上准备很充分，但大部分时候我也不就是这样轻轻松松就上了么。</p><p>就我个人而言，找工作这事情目前还不是特别急的一件事，秋招主要也是想打打基础。这么想的话就算这次最终结果不尽人意，可能也是可以接受的吧。</p>]]></content>
    
    
    <summary type="html">总结下这次秋招，没投几个简历，没费多大劲。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="找工作" scheme="https://tulancn.github.io/tags/%E6%89%BE%E5%B7%A5%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>大模型技术到底带来了什么</title>
    <link href="https://tulancn.github.io/2024/10/19/work/%E6%9D%82%E8%B0%88/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%88%B0%E5%BA%95%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88/"/>
    <id>https://tulancn.github.io/2024/10/19/work/%E6%9D%82%E8%B0%88/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%88%B0%E5%BA%95%E5%B8%A6%E6%9D%A5%E4%BA%86%E4%BB%80%E4%B9%88/</id>
    <published>2024-10-19T08:33:05.000Z</published>
    <updated>2025-03-10T13:56:48.151Z</updated>
    
    <content type="html"><![CDATA[<h2 id="正文">正文</h2><p>时间到2024年，以LLM为首的AI热潮似乎开始冷却。但是工具已经开始普及，大部分人已经开始尝试和AI一起工作。</p><p>我首先想提的是国内大模型的水平。目前接触下来，国产的AI在下限方面基本已经满足了我们的日常生活需要。也就是说，平时一些简单的任务已经可以让AI去完成，大部分问题都能收到一个令人满意的回答。对于大部分人的日常工作来说，已经足够。</p><p>如果要用一个角色来形容AI目前的水平，我觉得是一个知识面很广，能力很强，在经过适当调教能很好地完成任务的实习生。</p><p>这其实已经对我的日常工作方式有相当强烈地冲击了。举例来说，平日有些费时费力的总结报告，现在可以让AI来填写。一些技术文档全篇很长，而我需要知道的又只是其中的一个小点，那就可以让AI快速阅读之后我对其提问来获取答案。这种场景下，我的需求和问题都很明确，答案也有现成的，只是让AI在特定范围内进行一个快速的搜索，像是把LLM当做一个非常强大的搜索引擎，这种时候就非常好用。</p><p>还有种场景是内容的格式改写，比如数据改写为JSON格式。人工做很费力，但是AI能听懂指令快速生成结果。这就很好用。</p><p>那么工作的重点就变了。以前我的重点是把任务人工完成，要出力；现在我的重点是理清思路，转化为AI可以完成的任务，然后让AI先做一遍，我再检查一遍。这种思路确实就和分配任务给实习生是一样的。</p><p>所以，这就引出了LLM最适合的工作场景之一：<strong>重复性的、有明确工作规范和成果验收的工作</strong>。</p><p>另外，与AI协作的时候，很多人会感觉自己的能力也提高了。有一种场景，比如需要写一些自己平时不擅长的代码，像是后端程序员刚开始接触一门新的语言。这时候程序员可能是知道要做什么，但是苦于不知道怎么实现，因此需要一些额外的时间去学习。有了AI之后，这个学习成本降低了非常多，并且没有让人排斥的搜寻资料的过程。很多时候，我们要做的就是打开LLM输入界面，然后写出需求，等到LLM的回答，然后开始干活。得益于技术水平的提高，现在的LLM基本都很聪明，它们的回答大多数时候都是有用的。</p><p>感觉自己能力的提高后，会让人变得自信，然后就愿意去做一些以前不能做的事情。</p><p>但究其根本，不是人的能力提高了，而是<strong>学习的成本降低</strong>了。</p><p>这就是LLM最适合的第二个工作场景：<strong>快速让人在一个知识领域达到入门水平</strong>。</p><p>经过一些调教，我相信LLM在教育这方面大有可为。</p><p>然后我就要提GitHub Copilot。作为代码提示工具，有了LLM加持后，它聪明得让人欣喜。有人评价是，有了Copilot之后，编码的方式就变成了：写好注释，写好框架代码，然后停下来，等待Copilot填充。这确实是我的真实写照。</p><p>我觉得这就是大模型带来的最大影响：<strong>评价一个问题的难易程度，是取决于它有多少的部分能被LLM执行</strong>。</p><p>在一个任务中，我们总是倾向于让LLM做更多，而自己做更少。为什么这么说？第一个原因，LLM执行任务非常快，快到人类无法比拟的程度了；第二个原因，LLM执行任务的成本极低，几乎相当于没有成本。</p><p>但我们遇到的问题在最初往往并不是LLM可以直接解决的问题，因此我们要把问题转化为一个个LLM可以执行的最小单元。这考验了一个人思考问题、拆解问题和描述问题的能力，而显而易见的结论就是，这种能力越强的人，与LLM协作的能力也越强。</p><p>反过来，这其实也让我们每个人先专注于分析问题，而不是埋头就做。某种意义上来说，也算是反哺自身，让人去思考得更深入。</p><p>那么，我可以抛出一个命题：<strong>与大模型协作的能力越强，这个人的工作能力就越强</strong>。就像上文说的，一个人只有能分析拆解好问题，才能更好地让LLM完成工作。巧合的是，你把前面这句话中的LLM换成同事、下属也是一样成立的。原先AI部的同事就和我说过，常带实习生，或者手下有几个人的技术骨干，往往用Copilot也特别顺手。</p><p>在肉眼可见的未来，大家的工作中必定绕不开LLM，那么今早培养好自己相关的能力，可能也是条出路吧。</p><h2 id="总结">总结</h2><p>目前在工作和学习中，与大模型协作是非常常见的场景。</p><p>LLM的工作成本低，工作速度快，因此很适合进行一些重复性强、严格控制输入输出的工作。</p><p>LLM的语料资源丰富，能有效降低知识的学习门槛。</p><p>未来，人的工作能力可能很大程度上取决于他和AI配合能力的高低。</p>]]></content>
    
    
    <summary type="html">时至今日，LLM对我日常的工作和学习已经产生的极大的影响。聊聊我的思考。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="工作总结" scheme="https://tulancn.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>面试笔记-Java基础</title>
    <link href="https://tulancn.github.io/2024/10/16/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Java%E5%9F%BA%E7%A1%80/"/>
    <id>https://tulancn.github.io/2024/10/16/work/tips/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0-Java%E5%9F%BA%E7%A1%80/</id>
    <published>2024-10-16T07:04:36.000Z</published>
    <updated>2025-03-10T14:00:22.699Z</updated>
    
    <content type="html"><![CDATA[<h2 id="语法基础">语法基础</h2><h3 id="Java语言特点">Java语言特点</h3><p>一次编译处处运行，天然具有跨平台的能力。只要不用JNI。</p><p>开源社区资源丰富，活跃。</p><p>适合企业级开发，多方面：有Spring为主流的开源框架，大型项目的构建和维护的成本较低。语言的规范性强。</p><h3 id="基本类型和包装类型">基本类型和包装类型</h3><p>byte、char、boolean、short、int、float、long、double</p><p>基本类型不是对象，包装类型是对象。使用时有自动的拆装箱机制。但编码过程中如果可以用基本类型的建议还是用基本类型。</p><p>区别在于对象是有对应的Class类，这些类信息会记录在JVM的ClassLoader中。对象有对象头。</p><p>字节码的方法签名，基本类型是BCJFI之类的大写字母，对象是L加全限定类名。</p><h3 id="instance-of">instance of</h3><p>检测对象是否是某个类型的实例。可以用来检测对象是否实现了某个接口。</p><p>HashMap中有使用到，用来检测当前节点的实现是链表还是红黑树。</p><h3 id="重写和重载">重写和重载</h3><p>重写建议加@Override注解，标明该方法是重写方法。</p><p>重写发生在子类重写了父类的同名且参数完全一致的方法，或者是实现了某个接口的方法。有重写就一定是有extend或者impliment。</p><p>重载是同名方法用不同的参数实现。同名方法的方法签名是不一样的。</p><h3 id="equals和">equals和==</h3><p>==是比较两个变量所指向的内存地址是否相同，其实是个指针操作。基本类型就相当于值比较。</p><p>equals是Object类的一个方法，Object类中的实现就是==。一般不同的类会有不同的实现，String的实现就是逐个比较字符值是否相等。</p><h3 id="四种引用">四种引用</h3><p>强引用：使用最多的引用，默认就是强引用。</p><p>软引用：缓存会用。可能会被回收，优先级在弱引用之后。</p><p>弱引用：young GC时必定会回收。</p><p>虚引用：这个引用不会影响GC，需要有其他引用方式指向这个对象。</p><h3 id="Cleaner">Cleaner</h3><p>Cleaner机制用到了虚引用。Cleaner继承了虚引用，GC后，所有的cleaner会被回收到一个pending队列，reference handler线程会调用这个pending队列中的对象，会检测下是不是Cleaner对象，是的话就直接调用Cleaner的clean方法。</p><h3 id="Exception和Error">Exception和Error</h3><p>都是Throwable的实现类。</p><p>运行时异常不用显式地catch。被检查异常需要catch或向上抛出。</p><p>Error是非常严重的错误，可能宕机。但是不需要显式抛出。</p><h2 id="数据结构">数据结构</h2><h3 id="HashMap">HashMap</h3><p>线程不安全。</p><p>put：hash之后找到数组中的对应位置，如果为空直接塞；不为空说明哈希冲突，检查一下当前的数据结构，按照数据结构来添加这个对象，可能是替换也可能是新增。</p><h3 id="LinkedList">LinkedList</h3><p>双向链表，线程不安全。</p><h3 id="阻塞队列">阻塞队列</h3><p>阻塞队列的经典实现：ArrayBlockQueue，LinkedBlockQueue</p><p>用了大小堆的priority queue</p><p>阻塞队列的锁就是线程池的锁。所以阻塞队列的性能也一定程度上决定了线程池的性能。举例：Disruptor、参考Disruptor实现了自己的阻塞队列。</p><p>阻塞队列可以当做对象池来用。</p><h2 id="JVM">JVM</h2><h3 id="JVM内存模型">JVM内存模型</h3><p>线程独占的：栈，本地方法栈，程序计数器</p><p>线程共享的：堆，方法区</p><p>栈：存储局部变量，操作栈，动态链接，方法出口。调用一个方法时入栈，方法返回出栈。</p><p>本地方法栈：Native方法的栈</p><p>程序计数器：当前程序执行的字节码位置。也就是打印异常堆栈时看到的执行到第几行出错。执行到native方法时，程序计数器清空，因为不是在执行字节码了。</p><p>堆：存储对象实例，线程共享。会垃圾回收。</p><p>方法区：虚拟机加载的类信息，常量，静态变量，JIT优化后的代码。总之就是些全局的信息。</p><h3 id="内存可见性">内存可见性</h3><p>也就是为什么要volatile关键字。</p><p>线程执行时，会拷贝一份线程间的共享变量至线程的工作内存。拷贝的数据可能已经被其他线程修改了，导致执行结果错误。</p><p>volatile会在共享变量修改时，强制同步一份副本至所有涉及到的线程的工作空间。</p><h3 id="类加载和卸载">类加载和卸载</h3><p>加载字节码文件到内存-&gt;验证并解析为Class类，创建静态变量执行静态代码块-&gt;实例化-&gt;GC</p><h3 id="三种加载器">三种加载器</h3><p>JAVA_HOME/lib: Bootstrap ClassLoader</p><p>JAVA_HOME/lib/ext: Extension ClassLoader</p><p>Application ClassLoader</p><h3 id="双亲委派">双亲委派</h3><p>加载器加载一个类时，先委托给父类加载器。父类无法加载才会自己加载。</p><p>主要是为了避免同一个类被多个加载器重复加载。已经避免Java的核心类被修改。</p><h3 id="回收算法G1">回收算法G1</h3><p>高频率回收，减少每次的停顿。</p><p>分老年代和年轻代。分块region，年轻代和老年代都由若干个分块组成。</p><p>年轻代使用并行的复制和收集算法。</p><p>mix-GC会回收一部分老年代。</p><p>标记清除算法：STW进行初始标记，确实GC root可直达的对象，伴随一次young GC。然后GC线程和应用线程并行进行并发标记，尽可能标记出存活对象，使用SATB记录对象的引用关系。最终标记，STW，修改并发标记的错误。然后多线程进行GC。</p><h3 id="ZGC">ZGC</h3><p>低延时垃圾收集器。</p><h3 id="Full-GC">Full GC</h3><p>当老年代满时会进行，耗时长。需要避免。</p><h3 id="对象分配原则">对象分配原则</h3><p>新对象优先在eden区，如果大于survivor的二分之一就认定为大对象，直接晋升老年代。</p><p>对象没存活过一次young GC，年龄+1，到达一定年龄（默认15）就晋升老年代。</p><p>Survivor区中同年龄对象的总和大小超过一半，这个年龄以及这个年龄以上的对象进入老年代。</p><h3 id="对象的创建过程">对象的创建过程</h3><p>先去常量池找类信息，然后加载类信息，找不到就报ClassNotFound。</p><p>为对象分配内存，将除了对象头之外的内存块初始化为0。</p><p>设置对象头。</p><h3 id="对象结构">对象结构</h3><p>对象头12字节，数组16字节。</p><p>对象信息，基础类型直接在对象内存存储。</p><p>Java会自动排列对象中的Field顺序以更好地满足8字节对齐。</p><h3 id="对象头的内容">对象头的内容</h3><p>4字节的hashcode</p><p>2字节的分代年龄</p><p>1字节偏向锁</p><p>1字节锁标志</p><p>4字节的对象类型指针，指向Class类信息</p><p>数组的话还有4字节的数组长度</p><h3 id="常见的调优工具">常见的调优工具</h3><p>jps：展示所有的java进程</p><p>jstat：查看虚拟机运行状态</p><p>jmap：主要用于dump</p><p>jstack：生成线程快照</p><p>jinfo：实时查看和修改JVM参数</p><p>MAT：dump文件分析</p><p>visualVM：自带可视化界面</p><p>arthas：阿里开源的运行时诊断工具</p><h2 id="多线程">多线程</h2><h3 id="怎么创建线程">怎么创建线程</h3><p>只有new Thread()才算创建了一个新线程。其他的方式比如实现Runnable接口Callable接口之类的都没有新线程产生。</p><p>Runnable接口Callable接口本质是一个task，需要提交给线程才能执行。</p><h3 id="如何停止一个线程">如何停止一个线程</h3><p>最佳是用退出标志，完成当前方法后当前线程终止。</p><p>推荐调用interrupt，会抛出interrupt异常。</p><p>stop可以强行终止，不推荐。</p><h3 id="notify和notifyAll有什么区别">notify和notifyAll有什么区别</h3><p>notify可能死锁，notifyAll不会。</p><p>假如有多个线程正在wait，会要求notify唤醒的任意一个线程可以处理接下来的逻辑，否则就会死锁。</p><p>如果无法正确处理，则应该继续notify下一个，并让自己进入wait状态。</p><p>notifyAll唤醒所有线程，但是争抢锁还是无序的。</p><h3 id="sleep和wait有什么区别">sleep和wait有什么区别</h3><p>sleep在线程类中，wait在Object类。</p><p>sleep不释放锁，会让出cpu。</p><p>wait会释放锁，并且让出cpu。调用wait后，会释放线程持有的所有对象锁，然后进入对象的等待区。只有针对此对象调用notify或notifyAll后，才会获取对象锁进入运行状态。</p><h3 id="volatile">volatile</h3>]]></content>
    
    
    <summary type="html">Java基础是纯纯的八股文了，但还是要过一遍。</summary>
    
    
    
    <category term="工作" scheme="https://tulancn.github.io/categories/%E5%B7%A5%E4%BD%9C/"/>
    
    
    <category term="面试" scheme="https://tulancn.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
</feed>
